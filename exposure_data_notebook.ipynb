{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO50HA/TI9FEGMvYt33fFuV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArgyChris/ExerciseAugmenta/blob/main/exposure_data_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Augmenta exercise,\n",
        "## Author: Argyrios Christodoulidis, 29/06/2023\n",
        "## Cloud computing environment for model building, evaluation, testing, and extraction:\n",
        "\n",
        "The following notebook includes the following sections:\n",
        "\n",
        "1.   Computing environment set up\n",
        "2.   External data loading, preprocessing, and preparation\n",
        "3.   Model environment set up\n",
        "4.   Model experimentation: training of different models, hyperparameter tuning\n",
        "5.   Model evaluation\n",
        "6.   Model and Scaler saving and extraction\n",
        "\n",
        "\n",
        "###Brief description:\n",
        "The general flow of the work includes setting up the packages, then performing some checks for the computing environment, following that, data loading and normalization takes place. The main computations follow with model building, hyperparameter tuning, and the core model training that requires allocated GPU resources to run. Finally, the choosen trained model is tested, and then together with the Scaler that was used for normalization are both extracted to a local folder.       "
      ],
      "metadata": {
        "id": "LTrmJp0YX73u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Section 1: Computing environment set up\n",
        "\n",
        "The models are build on keras, so the relevant imports of tensorflow and keras modules takes place here. The imports are done using the built-in magic command %."
      ],
      "metadata": {
        "id": "UJofskGAfND8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMqG8RnBcPen",
        "outputId": "b5cafa59-1c2f-4a8b-84a8-d83856d3c674"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-33ed3e92adb2>:22: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        }
      ],
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "    IS_COLAB = True\n",
        "except Exception:\n",
        "    IS_COLAB = False\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "\n",
        "if not tf.test.is_gpu_available():\n",
        "    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
        "    if IS_COLAB:\n",
        "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ezOJNJ2c4KE",
        "outputId": "e84033f4-1390-4da3-8751-9f1e22228ae2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Section 2: External data loading, preprocessing, and preparation\n",
        "\n",
        "The google colab location is mounted and the exposure_dataset.csv is loaded using pandas.\n",
        "\n",
        "A global scaler that performs z-normalization (0 mean, 1 standard deviation) is used to normalize the data along the columns. Later on we will extract the scaler to use it during inference.\n",
        "\n",
        "The preparation involves the data spliting to training, validation, and testing sets. We choose 60% of the total number of sequences for training and the rest for validation and testing sets.\n",
        "\n"
      ],
      "metadata": {
        "id": "xi1vqBSS43D2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fhj7kAGPd_51",
        "outputId": "615b5b88-1400-45be-b0c5-95b79672af18"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Data loading\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/exposure_dataset.csv'"
      ],
      "metadata": {
        "id": "Ei6FsCP-eWHq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data reading\n",
        "import pandas as pd\n",
        "df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "dv5c-pZrfBiH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNonL9ardizw",
        "outputId": "d764b7ec-c1c1-4a85-9b68-6e3d9403839a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       pixel_value  sensor_value  exposure\n",
            "0         7.701034   2175.587020  0.022000\n",
            "1         5.815941   2181.119258  0.023100\n",
            "2         7.024709   2275.419955  0.024255\n",
            "3         9.315637   2236.333785  0.025468\n",
            "4         5.564641   2177.587197  0.026741\n",
            "...            ...           ...       ...\n",
            "24995   111.383149  20047.104237  0.578237\n",
            "24996   112.070445  19955.801369  0.607149\n",
            "24997   110.426177  20027.076572  0.637506\n",
            "24998   118.124573  20051.621709  0.669381\n",
            "24999   114.848397  20048.122759  0.702850\n",
            "\n",
            "[25000 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Data normalization: Apply global scaler, z-normalization for 0 mean and 1 std, keep the scaler for inverse and inference\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(df)\n",
        "df_normalized = scaler.transform(df)\n",
        "\n",
        "#Setting the sliding window size of the data/model, this can act as hyperparameter\n",
        "n_steps = 167\n",
        "num_sequences = len(df_normalized) - n_steps  # Number of sequences to create\n",
        "series_reshaped = []\n",
        "\n",
        "for i in range(num_sequences):\n",
        "    sequence = df_normalized[i:i + n_steps].copy()\n",
        "    series_reshaped.append(sequence)\n",
        "\n",
        "series_reshaped = np.array(series_reshaped)\n"
      ],
      "metadata": {
        "id": "FHjYC9G6YqMw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 2b: Testing if we can use the Scaler for reconstructing back to the original data"
      ],
      "metadata": {
        "id": "TJ7tZIf7694_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "series_reshaped.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djYarVo7cYOR",
        "outputId": "2d20b03c-3813-48dd-d22a-a969ef607469"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24833, 167, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "series_reshaped[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wdg157sjZ73c",
        "outputId": "eee8e695-6c95-440a-cde5-caf1edb55360"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.18097746, -1.73654999, -0.50282449])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_original = scaler.inverse_transform(series_reshaped[0][0].reshape(1, -1))\n",
        "print(sequence_original)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkGqvna7aYi0",
        "outputId": "ac771172-f663-4a8e-a346-bd149729a378"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7.70103375e+00 2.17558702e+03 2.20000000e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = df.iloc[0][:]\n",
        "print(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0maofS_KaH76",
        "outputId": "0f609110-2b51-4387-8815-7e230ab34de6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pixel_value        7.701034\n",
            "sensor_value    2175.587020\n",
            "exposure           0.022000\n",
            "Name: 0, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "series_reshaped.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxViDItqntwQ",
        "outputId": "1a455d25-a286-4560-f71d-946ee0eb13ac"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24833, 167, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "series_reshaped[0, :, -1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ER47X7zxtdjL",
        "outputId": "a8e9997a-b7fd-4b39-b222-201ed791c7ad"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-5.02824488e-01, -5.02634787e-01, -5.02435601e-01, -5.02226455e-01,\n",
              "       -5.02006853e-01, -5.01776270e-01, -5.01534159e-01, -5.01279941e-01,\n",
              "       -5.01013013e-01, -5.00732738e-01, -5.00438450e-01, -5.00129447e-01,\n",
              "       -4.99804994e-01, -4.99464319e-01, -4.99106609e-01, -4.98731014e-01,\n",
              "       -4.98336640e-01, -4.97922547e-01, -4.97487749e-01, -4.97031211e-01,\n",
              "       -4.96551846e-01, -4.96048513e-01, -4.95520013e-01, -4.94965089e-01,\n",
              "       -4.94382418e-01, -4.93770613e-01, -4.93128219e-01, -4.92453704e-01,\n",
              "       -4.91745464e-01, -4.91001812e-01, -4.90220978e-01, -4.89401101e-01,\n",
              "       -4.88540231e-01, -4.87636317e-01, -4.86687208e-01, -4.85690643e-01,\n",
              "       -4.84644250e-01, -4.83545537e-01, -4.82391889e-01, -4.81180558e-01,\n",
              "       -4.79908660e-01, -4.78573168e-01, -4.77170901e-01, -4.75698521e-01,\n",
              "       -4.74152522e-01, -4.72529222e-01, -4.70824758e-01, -4.69035071e-01,\n",
              "       -4.67155899e-01, -4.65182769e-01, -4.63110982e-01, -4.60935606e-01,\n",
              "       -4.58651461e-01, -4.56253108e-01, -4.53734839e-01, -4.51090655e-01,\n",
              "       -4.48314263e-01, -4.45399051e-01, -4.42338078e-01, -4.39124056e-01,\n",
              "       -4.35749334e-01, -4.32205875e-01, -4.28485244e-01, -4.24578581e-01,\n",
              "       -4.20476584e-01, -4.16169488e-01, -4.11647037e-01, -4.06898464e-01,\n",
              "       -4.01912462e-01, -3.96677160e-01, -3.91180093e-01, -3.85408172e-01,\n",
              "       -3.79347655e-01, -3.72984113e-01, -3.66302393e-01, -3.59286587e-01,\n",
              "       -3.51919991e-01, -3.44185066e-01, -3.36063394e-01, -3.27535638e-01,\n",
              "       -3.18581495e-01, -3.09179644e-01, -2.99307701e-01, -2.88942161e-01,\n",
              "       -2.78058344e-01, -2.66630335e-01, -2.54630927e-01, -2.42031548e-01,\n",
              "       -2.28802200e-01, -2.14911385e-01, -2.00326029e-01, -1.85011405e-01,\n",
              "       -1.68931050e-01, -1.52046677e-01, -1.34318086e-01, -1.15703065e-01,\n",
              "       -9.61572925e-02, -7.56342318e-02, -5.40850181e-02, -3.14583438e-02,\n",
              "       -7.70033566e-03,  1.72455728e-02,  4.34387768e-02,  7.09416409e-02,\n",
              "        9.98196482e-02,  1.30141556e-01,  1.61979559e-01,  1.95409462e-01,\n",
              "        2.30510861e-01,  2.67367329e-01,  3.06066621e-01,  3.46700877e-01,\n",
              "        3.89366846e-01,  4.34166114e-01,  4.81205345e-01,  5.30596537e-01,\n",
              "        5.82457289e-01,  6.36911079e-01,  6.94087558e-01,  7.54122862e-01,\n",
              "        8.17159930e-01,  8.83348852e-01,  9.52847220e-01,  1.02582051e+00,\n",
              "        1.10244246e+00,  1.18289550e+00,  1.26737121e+00,  1.35607069e+00,\n",
              "        1.44920515e+00,  1.54699633e+00,  1.64967708e+00,  1.75749185e+00,\n",
              "        1.87069737e+00,  1.98956317e+00,  2.11437225e+00,  2.24542179e+00,\n",
              "        2.38302380e+00,  2.52750592e+00,  2.67921214e+00,  2.83850367e+00,\n",
              "        3.00575978e+00,  3.18137869e+00,  3.36577855e+00,  3.55939841e+00,\n",
              "        3.76269925e+00,  3.97616514e+00,  4.20030432e+00,  4.43565046e+00,\n",
              "        4.68276391e+00,  4.94223303e+00,  5.21467561e+00,  5.50074032e+00,\n",
              "        5.80110826e+00,  6.11649460e+00,  6.44765025e+00,  6.79536369e+00,\n",
              "        7.16046280e+00,  7.54381686e+00,  7.94633863e+00,  8.36898649e+00,\n",
              "        8.81276674e+00,  9.27873600e+00,  9.76800373e+00,  1.02817348e+01,\n",
              "        1.08211525e+01,  1.13875411e+01,  1.19822490e+01])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "series_reshaped[0, :, -1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Imt7KSF6AX8m",
        "outputId": "e36bdf8c-dcea-4e98-e20b-5dfcb279ac5c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(167,)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 2c: Data split to training, validation, and testing"
      ],
      "metadata": {
        "id": "AgkYxxryqPf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the data into training and remaining data\n",
        "X_train, X_remain, Y_train, Y_remain = train_test_split(\n",
        "    series_reshaped[:, :, :2],  # Features (first 2 columns)\n",
        "    series_reshaped[:, :, -1],  # Target (the last columns)\n",
        "    test_size=0.4,           # 40% for remaining data (train + validation)\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# # Split the remaining data into validation and test sets\n",
        "X_val, X_test, Y_val, Y_test = train_test_split(\n",
        "    X_remain,               # Features from remaining data\n",
        "    Y_remain,               # Target from remaining data\n",
        "    test_size=0.5,          # 50% for validation and test (20% each)\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "kSvO3lKpr1Qn"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5fGF5yVtPcr",
        "outputId": "99e1746d-55ed-432b-8bb2-e35fd9e110ce"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14899, 167, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTdNm7_YvAh9",
        "outputId": "bfaab4e1-9da0-46ca-cd39-8768663e7326"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.0692425 , -0.37518874],\n",
              "       [-1.07154252, -0.3702273 ],\n",
              "       [-1.1037413 , -0.39348853],\n",
              "       [-1.05431479, -0.35145856],\n",
              "       [-1.06706416, -0.36540774],\n",
              "       [-1.06177089, -0.38683299],\n",
              "       [-1.03619775, -0.36267405],\n",
              "       [-1.04046006, -0.37472504],\n",
              "       [-1.03743932, -0.36804305],\n",
              "       [-0.98698415, -0.37026705],\n",
              "       [-1.03043035, -0.34748391],\n",
              "       [-1.03422605, -0.39020674],\n",
              "       [-1.04378108, -0.37168461],\n",
              "       [-0.99448211, -0.37958139],\n",
              "       [-1.03545368, -0.36549297],\n",
              "       [-0.98155257, -0.36365063],\n",
              "       [-0.99373943, -0.37037018],\n",
              "       [-0.98337   , -0.37655631],\n",
              "       [-0.92432491, -0.3595847 ],\n",
              "       [-0.97532162, -0.35696694],\n",
              "       [-0.9633396 , -0.36099346],\n",
              "       [-0.94460194, -0.3631183 ],\n",
              "       [-0.94478953, -0.37376097],\n",
              "       [-0.94290559, -0.37816721],\n",
              "       [-0.89442658, -0.37240502],\n",
              "       [-0.9276949 , -0.35764662],\n",
              "       [-0.90368014, -0.36447507],\n",
              "       [-0.89869835, -0.37547811],\n",
              "       [-0.88328926, -0.36777842],\n",
              "       [-0.81579585, -0.36823519],\n",
              "       [-0.88074263, -0.37948763],\n",
              "       [-0.8559482 , -0.36172014],\n",
              "       [-0.83580487, -0.34372836],\n",
              "       [-0.84768662, -0.36923319],\n",
              "       [-0.81115226, -0.37104927],\n",
              "       [-0.80842587, -0.36424417],\n",
              "       [-0.78584511, -0.36776259],\n",
              "       [-0.81219298, -0.37569334],\n",
              "       [-0.75475795, -0.35693406],\n",
              "       [-0.73613313, -0.35872015],\n",
              "       [-0.76660649, -0.36694896],\n",
              "       [-0.77947785, -0.36794728],\n",
              "       [-0.72484618, -0.36350506],\n",
              "       [-0.73590133, -0.36662579],\n",
              "       [-0.73232265, -0.37659557],\n",
              "       [-0.70414797, -0.37009172],\n",
              "       [-0.73994555, -0.35789445],\n",
              "       [-0.64988512, -0.34441882],\n",
              "       [-0.62623284, -0.369852  ],\n",
              "       [-0.60709922, -0.35293299],\n",
              "       [-0.63621741, -0.36960434],\n",
              "       [-0.63626513, -0.3791763 ],\n",
              "       [-0.60272764, -0.35900865],\n",
              "       [-0.56466422, -0.37811284],\n",
              "       [-0.53734293, -0.37309428],\n",
              "       [-0.54599858, -0.37685913],\n",
              "       [-0.49039271, -0.37619084],\n",
              "       [-0.46029385, -0.36502369],\n",
              "       [-0.5198571 , -0.37439406],\n",
              "       [-0.47053619, -0.36940747],\n",
              "       [-0.44765457, -0.34202302],\n",
              "       [-0.44984261, -0.3540252 ],\n",
              "       [-0.37634704, -0.35505897],\n",
              "       [-0.38029965, -0.35326926],\n",
              "       [-0.37784195, -0.34935808],\n",
              "       [-0.34027686, -0.36895881],\n",
              "       [-0.2779133 , -0.34957314],\n",
              "       [-0.33583252, -0.36296978],\n",
              "       [-0.20989644, -0.37607019],\n",
              "       [-0.23767315, -0.36281059],\n",
              "       [-0.18668147, -0.3752236 ],\n",
              "       [-0.16985806, -0.36325858],\n",
              "       [-0.1346289 , -0.35262757],\n",
              "       [-0.14298425, -0.34378167],\n",
              "       [-0.09171562, -0.35506093],\n",
              "       [-0.07311714, -0.37385188],\n",
              "       [-0.04963147, -0.34109819],\n",
              "       [-0.05210768, -0.37106504],\n",
              "       [ 0.00868553, -0.37189716],\n",
              "       [ 0.10233877, -0.35431402],\n",
              "       [ 0.12832554, -0.34397399],\n",
              "       [ 0.11900427, -0.36066736],\n",
              "       [ 0.20439487, -0.36223414],\n",
              "       [ 0.19079402, -0.36158597],\n",
              "       [ 0.21378821, -0.36579448],\n",
              "       [ 0.28643051, -0.36501575],\n",
              "       [ 0.27034596, -0.35431045],\n",
              "       [ 0.36164299, -0.35985707],\n",
              "       [ 0.3778381 , -0.35993376],\n",
              "       [ 0.40187937, -0.3561428 ],\n",
              "       [ 0.49024214, -0.36430402],\n",
              "       [ 0.49982343, -0.3463943 ],\n",
              "       [ 0.54692348, -0.36506698],\n",
              "       [ 0.61871427, -0.35818177],\n",
              "       [ 0.67835181, -0.36618055],\n",
              "       [ 0.72911095, -0.35199233],\n",
              "       [ 0.7700789 , -0.3544528 ],\n",
              "       [ 0.75719368, -0.35432118],\n",
              "       [ 0.85071307, -0.34976077],\n",
              "       [ 0.84727691, -0.35341762],\n",
              "       [ 0.95417493, -0.37653045],\n",
              "       [ 1.03795109, -0.36375277],\n",
              "       [ 1.09693737, -0.36043607],\n",
              "       [ 1.13453664, -0.3552161 ],\n",
              "       [ 1.1964344 , -0.36097161],\n",
              "       [ 1.27508399, -0.36375766],\n",
              "       [ 1.31786816, -0.35632183],\n",
              "       [ 1.41249136, -0.36978106],\n",
              "       [ 1.43073592, -0.3476653 ],\n",
              "       [ 1.51200793, -0.35601031],\n",
              "       [ 1.5538727 , -0.36676619],\n",
              "       [ 1.66954595, -0.35017361],\n",
              "       [ 1.6723325 , -0.35783304],\n",
              "       [ 1.72486734, -0.36164835],\n",
              "       [ 1.72486734, -0.34480356],\n",
              "       [ 1.72486734, -0.35489878],\n",
              "       [ 1.72486734, -0.34618774],\n",
              "       [ 1.72486734, -0.3309975 ],\n",
              "       [ 1.72486734, -0.37017248],\n",
              "       [ 1.72486734, -0.36112554],\n",
              "       [ 1.72486734, -0.34622876],\n",
              "       [ 1.72486734, -0.35911818],\n",
              "       [ 1.72486734, -0.33908279],\n",
              "       [ 1.72486734, -0.34888656],\n",
              "       [ 1.72486734, -0.37129735],\n",
              "       [ 1.72486734, -0.36201375],\n",
              "       [ 1.72486734, -0.34061914],\n",
              "       [ 1.72486734, -0.3622318 ],\n",
              "       [ 1.72486734, -0.35019828],\n",
              "       [ 1.72486734, -0.34744278],\n",
              "       [ 1.72486734, -0.34777478],\n",
              "       [ 1.72486734, -0.3298614 ],\n",
              "       [-1.09033853, -0.35112112],\n",
              "       [-1.09811268, -0.34925451],\n",
              "       [-1.08074794, -0.35463114],\n",
              "       [-1.0718126 , -0.36654582],\n",
              "       [-1.07451872, -0.34842512],\n",
              "       [-1.06402979, -0.36141389],\n",
              "       [-1.07599731, -0.35083977],\n",
              "       [-1.11607778, -0.33944382],\n",
              "       [-1.11402289, -0.34546941],\n",
              "       [-1.04941084, -0.35110449],\n",
              "       [-1.0675487 , -0.33484278],\n",
              "       [-1.09436241, -0.3517608 ],\n",
              "       [-1.02987609, -0.35287615],\n",
              "       [-1.05964737, -0.35024885],\n",
              "       [-1.06839104, -0.35091432],\n",
              "       [-1.01758677, -0.34684973],\n",
              "       [-0.9595215 , -0.35439701],\n",
              "       [-1.0377333 , -0.36178111],\n",
              "       [-1.04274568, -0.36121487],\n",
              "       [-0.98386771, -0.3453752 ],\n",
              "       [-0.97172447, -0.33811038],\n",
              "       [-0.98608928, -0.35065478],\n",
              "       [-1.04496554, -0.35989849],\n",
              "       [-0.9480219 , -0.33696926],\n",
              "       [-0.97154754, -0.33435507],\n",
              "       [-0.91711306, -0.34185992],\n",
              "       [-0.9717679 , -0.3470208 ],\n",
              "       [-0.98859937, -0.34129409],\n",
              "       [-0.91502177, -0.33458748],\n",
              "       [-0.91970074, -0.33170045],\n",
              "       [-0.94323199, -0.35315995],\n",
              "       [-0.9102269 , -0.36538853],\n",
              "       [-0.90075732, -0.34514635],\n",
              "       [-0.91327318, -0.33173561],\n",
              "       [-0.8381398 , -0.35503228]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eII4nxuC_kLP",
        "outputId": "cded38a9-5634-45b7-b6b5-b72d893377a9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.50153416, -0.50127994, -0.50101301, -0.50073274, -0.50043845,\n",
              "       -0.50012945, -0.49980499, -0.49946432, -0.49910661, -0.49873101,\n",
              "       -0.49833664, -0.49792255, -0.49748775, -0.49703121, -0.49655185,\n",
              "       -0.49604851, -0.49552001, -0.49496509, -0.49438242, -0.49377061,\n",
              "       -0.49312822, -0.4924537 , -0.49174546, -0.49100181, -0.49022098,\n",
              "       -0.4894011 , -0.48854023, -0.48763632, -0.48668721, -0.48569064,\n",
              "       -0.48464425, -0.48354554, -0.48239189, -0.48118056, -0.47990866,\n",
              "       -0.47857317, -0.4771709 , -0.47569852, -0.47415252, -0.47252922,\n",
              "       -0.47082476, -0.46903507, -0.4671559 , -0.46518277, -0.46311098,\n",
              "       -0.46093561, -0.45865146, -0.45625311, -0.45373484, -0.45109066,\n",
              "       -0.44831426, -0.44539905, -0.44233808, -0.43912406, -0.43574933,\n",
              "       -0.43220588, -0.42848524, -0.42457858, -0.42047658, -0.41616949,\n",
              "       -0.41164704, -0.40689846, -0.40191246, -0.39667716, -0.39118009,\n",
              "       -0.38540817, -0.37934766, -0.37298411, -0.36630239, -0.35928659,\n",
              "       -0.35191999, -0.34418507, -0.33606339, -0.32753564, -0.31858149,\n",
              "       -0.30917964, -0.2993077 , -0.28894216, -0.27805834, -0.26663034,\n",
              "       -0.25463093, -0.24203155, -0.2288022 , -0.21491138, -0.20032603,\n",
              "       -0.1850114 , -0.16893105, -0.15204668, -0.13431809, -0.11570306,\n",
              "       -0.09615729, -0.07563423, -0.05408502, -0.03145834, -0.00770034,\n",
              "        0.01724557,  0.04343878,  0.07094164,  0.09981965,  0.13014156,\n",
              "        0.16197956,  0.19540946,  0.23051086,  0.26736733,  0.30606662,\n",
              "        0.34670088,  0.38936685,  0.43416611,  0.48120534,  0.53059654,\n",
              "        0.58245729,  0.63691108,  0.69408756,  0.75412286,  0.81715993,\n",
              "        0.88334885,  0.95284722,  1.02582051,  1.10244246,  1.1828955 ,\n",
              "        1.26737121,  1.35607069,  1.44920515,  1.54699633,  1.64967708,\n",
              "        1.75749185,  1.87069737,  1.98956317,  2.11437225,  2.24542179,\n",
              "        2.3830238 ,  2.52750592, -0.50282449, -0.50263479, -0.5024356 ,\n",
              "       -0.50222646, -0.50200685, -0.50177627, -0.50153416, -0.50127994,\n",
              "       -0.50101301, -0.50073274, -0.50043845, -0.50012945, -0.49980499,\n",
              "       -0.49946432, -0.49910661, -0.49873101, -0.49833664, -0.49792255,\n",
              "       -0.49748775, -0.49703121, -0.49655185, -0.49604851, -0.49552001,\n",
              "       -0.49496509, -0.49438242, -0.49377061, -0.49312822, -0.4924537 ,\n",
              "       -0.49174546, -0.49100181, -0.49022098, -0.4894011 , -0.48854023,\n",
              "       -0.48763632, -0.48668721])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Naww_3SSvGQA",
        "outputId": "d94eaf42-9117-4471-99c1-1f0f6c674738"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4967, 167)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xak_zIovgkA",
        "outputId": "97f40ac7-04b1-48cf-c9bc-41881668acf2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4967, 167, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 3: Model environment set up"
      ],
      "metadata": {
        "id": "XA6cu4Po7lsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "piNVHmw_nuR1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "t5sRbpuxvjk7"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 3b: Visualization plot function"
      ],
      "metadata": {
        "id": "qkjuyLTA7tmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_learning_curves(loss, val_loss):\n",
        "    plt.plot(np.arange(len(loss)) + 0.5, loss, \"b.\", label=\"Training loss\")\n",
        "    plt.plot(np.arange(len(val_loss)) + 1, val_loss, \"r-\", label=\"Validation loss\")\n",
        "    plt.gca().xaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))\n",
        "    plt.legend(fontsize=14)\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.grid(True)"
      ],
      "metadata": {
        "id": "WafoSAr6dT7N"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 4: Main model training section. Setting the models, the hyperparameters, the regularizers, the tuning.\n",
        "\n",
        "First we set the early stopping, a regularization technique, to monitor the validation loss, and stop the training if there is no improvement.\n",
        "\n",
        "We performed experiments using models that have been proposed to work on sequences, the Deep RNNs and LSTMs.\n",
        "\n",
        "In keras, the model building is abstracted at a high degree so we only have to set up the number of units, the fully connected or dense layer and its output, 1 single value that represents the exposure time in our case, the number of sequential layers, the type of loss function, the optimizer, a possible dropout for extra regularization, and finally the number of training epochs.\n",
        "\n",
        "As a first exploratory step we tried different settings. For the best architecture, or the one that looked more promising, we considered the dropout and the number of units as hyperparameters, and we used Optuna toolkit to find the best values for the hyperparamters. Having the values we expanded our training to more epochs."
      ],
      "metadata": {
        "id": "EvPw0X4O73-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor = 'val_loss')"
      ],
      "metadata": {
        "id": "KTem84_cv6W4"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Deep Recurrent Neural Network\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "DRNN = keras.models.Sequential([\n",
        "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 2]),\n",
        "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(1))\n",
        "])\n",
        "\n",
        "DRNN.compile(loss=\"mape\", optimizer=\"adam\")\n",
        "history_RNN = DRNN.fit(X_train, Y_train, epochs=20,\n",
        "                    validation_data=(X_val, Y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SKAOYGuWMCR",
        "outputId": "0b081520-e48e-4716-c7c4-f12a8c12722e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "466/466 [==============================] - 162s 333ms/step - loss: 26.0172 - val_loss: 14.9333\n",
            "Epoch 2/20\n",
            "466/466 [==============================] - 152s 327ms/step - loss: 12.9604 - val_loss: 11.4247\n",
            "Epoch 3/20\n",
            "466/466 [==============================] - 156s 335ms/step - loss: 10.1469 - val_loss: 9.5753\n",
            "Epoch 4/20\n",
            "466/466 [==============================] - 153s 328ms/step - loss: 9.1747 - val_loss: 7.8983\n",
            "Epoch 5/20\n",
            "466/466 [==============================] - 156s 336ms/step - loss: 7.9599 - val_loss: 8.3231\n",
            "Epoch 6/20\n",
            "466/466 [==============================] - 155s 333ms/step - loss: 7.4239 - val_loss: 6.8605\n",
            "Epoch 7/20\n",
            "466/466 [==============================] - 153s 327ms/step - loss: 6.7452 - val_loss: 5.9295\n",
            "Epoch 8/20\n",
            "466/466 [==============================] - 156s 334ms/step - loss: 6.3825 - val_loss: 5.9327\n",
            "Epoch 9/20\n",
            "466/466 [==============================] - 155s 333ms/step - loss: 5.9241 - val_loss: 6.0644\n",
            "Epoch 10/20\n",
            "466/466 [==============================] - 154s 331ms/step - loss: 5.8436 - val_loss: 5.0996\n",
            "Epoch 11/20\n",
            "466/466 [==============================] - 152s 326ms/step - loss: 5.7943 - val_loss: 4.8052\n",
            "Epoch 12/20\n",
            "466/466 [==============================] - 152s 325ms/step - loss: 5.2991 - val_loss: 4.8219\n",
            "Epoch 13/20\n",
            "466/466 [==============================] - 152s 325ms/step - loss: 5.2515 - val_loss: 5.9395\n",
            "Epoch 14/20\n",
            "466/466 [==============================] - 157s 337ms/step - loss: 4.9008 - val_loss: 4.7196\n",
            "Epoch 15/20\n",
            "466/466 [==============================] - 149s 320ms/step - loss: 5.3728 - val_loss: 4.7080\n",
            "Epoch 16/20\n",
            "466/466 [==============================] - 154s 330ms/step - loss: 4.8820 - val_loss: 4.5092\n",
            "Epoch 17/20\n",
            "466/466 [==============================] - 154s 331ms/step - loss: 4.6186 - val_loss: 4.0835\n",
            "Epoch 18/20\n",
            "466/466 [==============================] - 159s 341ms/step - loss: 4.7734 - val_loss: 5.2652\n",
            "Epoch 19/20\n",
            "466/466 [==============================] - 150s 322ms/step - loss: 4.7769 - val_loss: 5.5989\n",
            "Epoch 20/20\n",
            "466/466 [==============================] - 152s 327ms/step - loss: 4.3799 - val_loss: 4.0824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deep LSTM model\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "DeepLSTM = keras.models.Sequential([\n",
        "    keras.layers.LSTM(80, return_sequences= True, input_shape=(167,2)),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.LSTM(40, return_sequences= True),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.LSTM(30, return_sequences= True),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(1))\n",
        "])\n",
        "\n",
        "DeepLSTM.compile(loss=\"mape\", optimizer=\"adam\")\n",
        "history_DeepLSTM = DeepLSTM.fit(X_train, Y_train, epochs=20,\n",
        "                    validation_data=(X_val, Y_val), callbacks = [es] )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8IPCSR_v_CZ",
        "outputId": "a4c919e1-ed2a-48db-d976-6749b54a340e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "466/466 [==============================] - 22s 30ms/step - loss: 15.8311 - val_loss: 6.8480\n",
            "Epoch 2/20\n",
            "466/466 [==============================] - 16s 34ms/step - loss: 7.8886 - val_loss: 6.2141\n",
            "Epoch 3/20\n",
            "466/466 [==============================] - 12s 25ms/step - loss: 6.3631 - val_loss: 4.6678\n",
            "Epoch 4/20\n",
            "466/466 [==============================] - 11s 23ms/step - loss: 5.4097 - val_loss: 3.5787\n",
            "Epoch 5/20\n",
            "466/466 [==============================] - 9s 20ms/step - loss: 4.8565 - val_loss: 3.1898\n",
            "Epoch 6/20\n",
            "466/466 [==============================] - 10s 22ms/step - loss: 4.3963 - val_loss: 3.3163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_learning_curves(history_DeepLSTM.history[\"loss\"], history_DeepLSTM.history[\"val_loss\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "pooKBPolyZEH",
        "outputId": "832cfae5-ce72-4a84-de69-4a89bad0ff19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Long-Short Term Memory model\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "number_of_LSTM_units = 20 #hyperparameter\n",
        "model8 = keras.models.Sequential([\n",
        "    keras.layers.LSTM(number_of_LSTM_units, return_sequences=True, input_shape=[None, 2]),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(1))\n",
        "])\n",
        "\n",
        "model8.compile(loss=\"mape\", optimizer=\"adam\")\n",
        "history_LSTM_50_epochs = model8.fit(X_train, Y_train, epochs=50,\n",
        "                    validation_data=(X_val, Y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzFX72AryGmg",
        "outputId": "c0ebdc2c-6c41-40c4-f218-29f935f77048"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "466/466 [==============================] - 8s 12ms/step - loss: 19.8777 - val_loss: 10.4889\n",
            "Epoch 2/50\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.5824 - val_loss: 5.6868\n",
            "Epoch 3/50\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.1557 - val_loss: 4.7604\n",
            "Epoch 4/50\n",
            "466/466 [==============================] - 6s 13ms/step - loss: 4.5394 - val_loss: 4.1591\n",
            "Epoch 5/50\n",
            "466/466 [==============================] - 7s 14ms/step - loss: 4.0969 - val_loss: 3.8760\n",
            "Epoch 6/50\n",
            "466/466 [==============================] - 7s 15ms/step - loss: 3.8545 - val_loss: 3.8185\n",
            "Epoch 7/50\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 3.6399 - val_loss: 3.4721\n",
            "Epoch 8/50\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 3.4600 - val_loss: 3.7495\n",
            "Epoch 9/50\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 3.3749 - val_loss: 3.4113\n",
            "Epoch 10/50\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 3.1968 - val_loss: 3.3033\n",
            "Epoch 11/50\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 3.1643 - val_loss: 2.9641\n",
            "Epoch 12/50\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 2.9972 - val_loss: 3.1343\n",
            "Epoch 13/50\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 2.9049 - val_loss: 2.7440\n",
            "Epoch 14/50\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 2.8406 - val_loss: 2.7578\n",
            "Epoch 15/50\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 2.7224 - val_loss: 2.6843\n",
            "Epoch 16/50\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 2.6859 - val_loss: 2.4750\n",
            "Epoch 17/50\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 2.6226 - val_loss: 2.4885\n",
            "Epoch 18/50\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 2.6431 - val_loss: 2.9241\n",
            "Epoch 19/50\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 2.6373 - val_loss: 2.3788\n",
            "Epoch 20/50\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 2.5518 - val_loss: 2.5207\n",
            "Epoch 21/50\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 2.4801 - val_loss: 2.5540\n",
            "Epoch 22/50\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 2.4693 - val_loss: 2.5421\n",
            "Epoch 23/50\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 2.4745 - val_loss: 2.2582\n",
            "Epoch 24/50\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 2.3946 - val_loss: 2.4071\n",
            "Epoch 25/50\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 2.4743 - val_loss: 2.4442\n",
            "Epoch 26/50\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 2.3859 - val_loss: 2.3496\n",
            "Epoch 27/50\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 2.3898 - val_loss: 2.2210\n",
            "Epoch 28/50\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 2.3879 - val_loss: 2.3653\n",
            "Epoch 29/50\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 2.3154 - val_loss: 2.0946\n",
            "Epoch 30/50\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 2.3063 - val_loss: 2.1855\n",
            "Epoch 31/50\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 2.2450 - val_loss: 3.0589\n",
            "Epoch 32/50\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 2.2629 - val_loss: 2.7200\n",
            "Epoch 33/50\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 2.1922 - val_loss: 2.2181\n",
            "Epoch 34/50\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 2.2231 - val_loss: 2.0573\n",
            "Epoch 35/50\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 2.2219 - val_loss: 2.0099\n",
            "Epoch 36/50\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 2.1601 - val_loss: 2.4061\n",
            "Epoch 37/50\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 2.2184 - val_loss: 2.0445\n",
            "Epoch 38/50\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 2.1286 - val_loss: 1.9946\n",
            "Epoch 39/50\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 2.1444 - val_loss: 1.9488\n",
            "Epoch 40/50\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 2.1583 - val_loss: 2.6423\n",
            "Epoch 41/50\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 2.1121 - val_loss: 2.1852\n",
            "Epoch 42/50\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 2.1160 - val_loss: 2.2214\n",
            "Epoch 43/50\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 2.1130 - val_loss: 2.0878\n",
            "Epoch 44/50\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 2.0964 - val_loss: 2.8429\n",
            "Epoch 45/50\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 2.0549 - val_loss: 2.1021\n",
            "Epoch 46/50\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 2.0519 - val_loss: 2.0126\n",
            "Epoch 47/50\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 2.0588 - val_loss: 1.9828\n",
            "Epoch 48/50\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 2.0456 - val_loss: 1.9660\n",
            "Epoch 49/50\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 2.0504 - val_loss: 2.4582\n",
            "Epoch 50/50\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 2.0621 - val_loss: 2.1655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_learning_curves(history_LSTM_50_epochs.history[\"loss\"], history_LSTM_50_epochs.history[\"val_loss\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "3Y4cYEu_zacr",
        "outputId": "b46c89d3-978a-4f94-fb0f-c6c22add4746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAksAAAG5CAYAAACeD3CNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB3DUlEQVR4nO3deXxM1/sH8M9MlkkiEiIRiSxCrCGWoihiCWJfaq+WVmurpUX77UZQVX5UF0pLlVZpbaF2iSW2qn0tShCyL8gm2yRzfn9MM4yZTCbrLD7v12teMveee+/zTCYzj3PPPVcihBAgIiIiIq2khg6AiIiIyJixWCIiIiLSgcUSERERkQ4sloiIiIh0YLFEREREpAOLJSIiIiIdWCwRERER6WBp6ABMnUKhQGxsLCpXrgyJRGLocIiIiEgPQgikp6fD3d0dUqnuviMWS6UUGxsLT09PQ4dBREREJRAVFQUPDw+dbVgslVLlypUBKF9sBweHEu9HLpcjNDQU3bt3h5WVVVmFZxSYm+kx17wA5maKzDUvgLkZUlpaGjw9PVXf47qwWCqlglNvDg4OpS6W7Ozs4ODgYJRvqtJgbqbHXPMCmJspMte8AOZmDPQZQsMB3kREREQ6sFgiIiIi0oHFEhEREZEOLJaIiIiIdGCxRERERKQDiyUiIiIiHTh1ABGRkZLL5cjPzy9We0tLS2RnZxdrO2NnrnkBzK2sWVhYlMs0BUZXLJ09exa//PILjhw5gsjISFSrVg1t2rTB/PnzUa9ePbW2N27cwPvvv48TJ07A2toavXv3xtKlS+Hi4qLXsXbu3Ik5c+bg+vXrqF69Ot58803MmjULlpZG97IQ0QskLS0NycnJyMnJKdZ2QgjUqFEDUVFRZnX7JXPNC2Bu5UEmk8HZ2blUcx8+z+iqgkWLFuHkyZMYMmQI/P39ER8fj+XLl6NFixb4+++/0bhxYwBAdHQ0OnbsCEdHRyxYsAAZGRlYsmQJrl69ijNnzsDa2lrncfbt24cBAwagU6dOWLZsGa5evYr58+cjMTERK1eurIhUiYg0pKWlISYmBvb29nB2doaVlZXeXzQKhQIZGRmwt7cv8l5XpsRc8wKYW1kSQkAulyM1NRUxMTEAUGYFk9EVS9OnT8fGjRvVip1hw4ahSZMmWLhwIX777TcAwIIFC/DkyROcP38eXl5eAIDWrVujW7duWLduHcaNG6fzODNnzoS/vz9CQ0NVPUkODg5YsGABpk2bhgYNGpRThkREhUtOToa9vT08PDyK/b9xhUKB3Nxc2NjYmNUXr7nmBTC3smZra4vKlSsjOjoaycnJZVYsGd1vpl27dhq9QnXr1oWfnx9u3LihWrZt2zb06dNHVSgBQGBgIOrVq4fNmzfrPMb169dx/fp1jBs3Tu2U26RJkyCEwNatW8soGyIi/cnlcuTk5MDR0dHsTskQVRSJRAJHR0fk5ORALpeXyT6NrmdJGyEEEhIS4OfnBwCIiYlBYmIiWrZsqdG2devW2Lt3r879Xbx4EQA0tnd3d4eHh4dqvTY5OTlq4wjS0tIAKD/kSvNLKdj22X1ERwMRERL4+goUcUNko6YtN3NhrrmZa16AceeWnZ0NIQQsLCygUCiKvb0QQvVvSbY3VuaaF8DcyouFhQWEEDrH/RXnM8AkiqUNGzYgJiYG8+bNAwDExcUBANzc3DTaurm54dGjR8jJyYFMJtO6v6K2j42NLTSWL7/8EnPnztVYHhoaCjs7u6KTKUJYWNh//3phxYpmEEICiURg0qRL6NbtQan3b0gFuZkjc83NXPMCjDM3S0tL1KhRA0+ePClVMZeenl6GURkPc80LYG5lLTc3F1lZWTh69Cjy8vK0tsnMzNR7f0ZfLN28eRPvvvsu2rZti9GjRwMAsrKyAEBrMWRjY6NqU1ixVNT2Bb1F2nz88ceYPn266nlaWho8PT3RvXv3Up0blcvlCAsLQ7du3ZCQYIVBgywhhLIbXggJfvihGWbMaGySPUzP5mbMd54uCXPNzVzzAow7t+zsbERFRcHe3l71WVYcQgikp6ejcuXKZnUaz1zzAphbecnOzoatrS06duxY6N+Sru/65xl1sRQfH4/evXvD0dERW7duhYWFBQDlAC4AWrvXsrOz1dpoU9T2uraVyWRaiywrK6sy+eC1srJCZKQVnu+xzM+X4P59K/j4lPoQBlNWr5ExMtfczDUvwDhzy8/Ph0QigVQqLdGA2IJTHQX7MBfmmhfA3MqLVCqFRCLR+XdenL9/o/3NpKamomfPnkhJScH+/fvh7u6uWldw+qzgdNqz4uLi4OTkVGivkj7bP3ssQ6hbF3j+fWVhAfj6GiYeIiKiF5lRFkvZ2dno27cvbt26hd27d6NRo0Zq62vWrAkXFxecO3dOY9szZ86gWbNmOvdfsP757WNjYxEdHV3k9uXNwwNYtUpZIAHKf3/8ESZ5Co6IyNhJJBJ06tSpVPsIDw+HRCLBnDlzyiSmslCrVi3UqlXL0GGYBaMrlvLz8zFs2DCcOnUKW7ZsQdu2bbW2e/XVV7F7925ERUWplh06dAi3bt3CkCFDVMvkcjlu3ryp1ovk5+eHBg0aYNWqVWpTsK9cuRISiQSDBw8uh8yKZ+xYIDISOHJE+e/YsYaOiIio/EgkkkIfFhYWqFq1KiwsLFTLiCqS0Y1ZmjFjBnbu3Im+ffvi0aNHqkkoC4waNQoA8Mknn2DLli3o3Lkzpk2bhoyMDCxevBhNmjTBm2++qWofExODhg0bYvTo0Vi3bp1q+eLFi9GvXz90794dw4cPx7Vr17B8+XK8/fbbaNiwYYXkWhQPD/YmEdGLITg4WGPZN998g9TUVMyePVt1hXN5FEo3btwo9dXMrVu3xo0bN+Ds7FxGUZExMbpi6dKlSwCAXbt2YdeuXRrrC4olT09PHD16FNOnT8dHH32kujfcV199pXO8UoE+ffogJCQEc+fOxZQpU+Di4oJPPvkEs2fPLtN8iIioaNpOX61btw6pqakIDg5GWloaHBwcymWgcFncscHOzo53fjBjRncaLjw8HEKIQh/P8vPzw4EDB/DkyRM8fvwYv/32G1xdXdXa1KpVC0IItV6lAgMGDMDFixdVl+t+/vnnRnd1DBFReYiOVp7mj442dCTFExkZCYlEgjFjxuDGjRsYOHAgqlWrBolEgsjISADA9u3bMWLECPj6+sLOzg6Ojo7o0KEDtm3bpnWf2sYsjRkzBhKJBPfu3cN3332HBg0aQCaTwdvbG3PnztWYZLGwMUsF44YyMjIwbdo0uLu7QyaTwd/fv9C7RURGRmLYsGFwcnKCvb09AgICcOzYMcyZMwcSiQTh4eEleelUnjx5guDgYDRo0AA2NjZwcnJC7969cfLkSY222dnZ+Oqrr9C0aVM4OjqiUqVKqFWrFoYOHYrLly+r2ikUCvz0009o3bo1nJycYGtrCy8vLwwfPrzU8RoDo+tZIiKi8rVmDTBuHKBQKK+8XbXK9MZFRkREoE2bNmjSpAnGjBmDhw8fqm6V9fHHH8Pa2hrt27eHm5sbkpKSsHPnTgwePBjfffcdpkyZovdxPvjgAxw9ehR9+vRBjx49sGPHDsyZMwe5ubn44osv9NqHXC5H9+7d8fjxY7z66qvIzMzEH3/8gaFDh2Lv3r1o06aNqm1MTAzatWuHuLg4BAUFoXnz5vj333/RrVs3dOnSpXgvkhbZ2dno0qULzpw5gxYtWuC9995DQkICNm3ahAMHDuD3339XG/c7evRobN68Gf7+/njzzTchk8kQFRWFI0eO4OzZs2jatCkA5Wv+f//3f6hTpw5Gjhypuj/b8ePHcejQoTKJ3aAElUpqaqoAIFJTU0u1n9zcXLFjxw6Rm5tbRpEZD+Zmesw1LyGMO7esrCxx/fp1kZWVVaLt8/PzxePHj0V+fn6hbaKihJBKhQCePiwslMuNjbe3twCglte9e/cEAAFAzJ49W+t2d+7c0ViWnp4umjRpIhwdHcWTJ0/U1gEQAQEBastGjx4tAAgfHx8RGxurWp6UlCSqVKkiKleuLHJyclTLjxw5IgCI4OBgrTn0799frf3BgwcFANG9e3e139moUaMEAPHFF1+o7WfNmjWqvI8cOVLoa/b8sb29vdWWzZ07VwAQr732mlAoFKrlFy5cENbW1qJKlSoiLS1NCCFESkqKkEgk4qWXXhJ5eXlq+8nLyxOPHz9WPXdychLu7u5qr23B7y0pKUmveMuSPn9Lxfn+NrrTcEREVH5u34aWSW+BiAjDxFNSNWrUwKeffqp1Xe3atTWW2dvbY8yYMUhNTcXZs2f1Ps6sWbPUbo3l7OyM/v37Iz09Hf/++6/e+/n666/VbhLftWtXeHt7q01hk5OTgy1btqB69eqYMWOG2vZvvvkm6tevr/fxCvPLL7/AysoKCxcuVBss37x5c4wePRopKSnYsWMHAOXpSSEEbGxsNMaKWVhYoEqVKmrLrK2tVZNHP8vJyanUcRsaiyUioheIuUx627RpU7Xi41mJiYmYPn06GjZsCDs7O9V0AwUFiK77fz7vpZde0ljm8d9lyikpKXrto0qVKvDRcvsFDw8PtX38+++/yMnJQcuWLTUuVJJIJGjXrp3ecWuTlpaGu3fvwtfXV5XDszp37gzg6YVWDg4O6NWrF06ePIkWLVpgwYIF+Ouvv7Tet3D48OGIjIxE48aNMWvWLBw+fFh1azFzwGKJiOgFYi6T3j5/MU+BR48eoVWrVvj6669RrVo1jB07Fp999hmCg4PRv39/ANpvdVUYbff8tLRUDvd9dp4+XRwdHbUut7S0VBsoXnCvsurVq2ttX1jO+irYf2H7KehBe/aeaVu2bMGnn36K1NRUfPrpp3jllVfg7OyM9957T+1GtN9++y0WL14Ma2trzJ8/H127doWzszMmTpyI5OTkUsVtDFgsERG9YMxh0tvC5ltas2YNHjx4gM8//xwnTpzAsmXL8Pnnn2POnDlqA6mNUUFhlpiYqHV9QkJCmey/sP3Ex8ertQOUUyLMnz8fd+/exd27d7FmzRrUr18f3377Ld5//31VO0tLS8ycORP//PMPYmJisHHjRrRv3x5//PGHasofU8ZiiYjoBeThAXTqZHo9SkW5c+cOAKh6kZ51/Pjxig6nWOrXrw+ZTIbz589r9H4JIXDq1KlS7d/BwQG1a9dGREQEYmJiNNYXXOJf2C2/fHx88NZbb+Ho0aOwt7fHzp07tbZzd3fHiBEjsG/fPtSuXRuHDh0y+VNyLJaIiMhseHt7AwBOnDihtnzjxo3Yu3evIULSm0wmw+DBg5GQkIBvvvlGbd2vv/6KmzdvlvoYo0ePhlwux8cff6w2d+GVK1ewbt06ODo6YsCAAQCApKQkXLt2TWMfjx8/Rk5ODmxsbAAoT2v+9ddfGu2ePHmCJ0+ewMrKqlwmE61InGeJiIjMxuuvv45FixZhypQpOHLkCLy9vXH58mUcOnQIgwYNQkhIiKFD1OnLL7/EwYMH8dFHH+Ho0aOqeZZ2796NoKAg7N+/v1SFx4cffog9e/Zg/fr1uHHjBrp27YrExERs2rQJeXl5WL16NSpXrgxAOedT8+bN0bRpU/j7+6NmzZp4+PAh/vzzT8jlcsycORMAkJWVhVdeeQX16tXDSy+9BC8vL2RkZGD37t1ISEjAjBkz9LqzhjFjsURERGbDw8MDR48exYcffoiDBw8iLy8PLVq0QGhoKKKiooy+WPL09MSpU6fwv//9D6GhoTh69CheeuklhIaGYsuWLQC0DzrXl42NDQ4fPoxFixZh06ZN+Prrr2FnZ4eAgAB88sknaN++vaptrVq1MGfOHBw+fBgHDx7Ew4cP4ezsjBYtWmDatGkICgoCAFSqVAmLFi3CoUOHcPz4cSQmJqJq1aqoX78+PvvsM7X7tZoqiRDP3UOEiiUtLQ2Ojo5ITU0t1RtYLpdj79696NWrl9ndcoW5mR5zzQsw7tyys7Nx7949+Pj4qE5xFIdCoSjXe6gZirnmBRQvt/bt2+PUqVNITU2Fvb19BUVYcob8venzt1Sc72/zetcRERGZuLi4OI1lv/32G06ePInAwECTKJTMDU/DERERGZHGjRujefPmaNSoESwsLHDp0iWEh4ejcuXKWLJkiaHDeyGxWCIiIjIiEyZMwK5du3Du3Dk8efIELi4uGDlyJGbNmoUGDRoYOrwXEoslIiIiI/LFF1/giy++MHQY9AyOWSIiIiLSgcUSERERkQ4sloiIiIh0YLFEREREpAOLJSIiIiIdWCwRERER6cBiiYiIiEgHFktEREREOrBYIiKiF8K6desgkUiwbt06teW1atVCrVq1Sr2fsjRnzhxIJBKEh4eX2zGKw9jiqWgsloiIyOBGjhwJiUSC33//XWe7tLQ02NnZoUqVKsjKyqqg6MpeeHg4JBIJ5s6da+hQSA8sloiIyODGjh0LAPj55591tvv999+RlZWFESNGwNbWtkyOfejQIRw6dKhM9lVWJk+ejBs3bqB169aGDoXAe8MREZER6NKlC3x8fHD48GE8ePAAXl5eWtsVFFMFxVVZqFOnTpntq6w4OzvD2dnZ0GHQf9izREREBieRSPDmm29CoVBg7dq1Wtv8888/OHPmDPz9/dGyZUukpqZi0aJFCAgIgLu7O6ytreHu7o433ngDd+7c0fvYhY1ZevToESZMmABXV1fY2dmhVatW2L59e6H7+fnnn9G/f3/UqlULNjY2cHJyQo8ePXDkyBG1dnPmzEHnzp0BAPPmzUPVqlVhYWEBiUSCyMhIVZvCxgjt2rULnTt3hqOjI2xtbdG0aVMsXboUeXl5au0iIyMhkUgwZswYREREYODAgahatSoqVaqEwMBAXL58We/XSBd94wGAI0eOoGfPnnB3d4dMJoOrqys6dOiAVatWqbW7cOECBg8eDC8vL8hkMri4uKBVq1YGu8Ewe5aIiMgojBkzBnPmzMG6deswe/ZsSCQStfUFA6oLepVu3LiB2bNno3Pnzhg4cCAqVaqEmzdvYuPGjdizZw8uXLgAb2/vEsWSmZmJTp064erVq2jbti0CAgIQFRWFYcOGoXv37lq3effdd9G0aVMEBgbCxcUFMTEx2LFjBwIDAxESEoL+/fsDADp16oTIyEj88ssvCAgIQJs2bSCTySCRSFClShWdcS1duhQzZsyAk5MTRo4ciUqVKmHnzp2YMWMGjh8/jpCQEI3XLTIyEm3atIGfnx/eeust3LlzB3/++Sc6d+6MGzduwNXVtUSvUVHxHDt2TK3w3bNnD/r27YsqVaqgf//+cHNzQ1JSEi5fvoz169dj3LhxAIBLly6hXbt2sLCwQP/+/eHt7Y2UlBRcv34dq1atwqefflrieEtMUKmkpqYKACI1NbVU+8nNzRU7duwQubm5ZRSZ8WBupsdc8xLCuHPLysoS169fF1lZWZorFQohMjJ0PvLT0sTj6GiRn5ZWZNtyeygUpXoNgoKCBABx8OBB1bL8/HyRlJQkXF1dhUwmEw8fPhRCCJGSkqL6+VmHDx8WUqlUvP3222rL165dKwCItWvXqi339vYW3t7easuCg4MFAPHOO++oLd+/f78AoHU/d+/e1YglNjZWuLu7i7p166otP3LkiAAgZs+eLR4/fizy8/O1Hv/IkSOqZREREcLS0lJUr15dPHjwQLU8OztbtG/fXgAQv/76q2r5vXv3VLEuXLhQbf+fffaZACC+/PJLjZi1KWk8K1euVOU2aNAgAUBcunRJY//Jycmqn6dPny4AiB07duhsp4vOv6X/FOf7m6fhiIhMQWYmYG+v8yF1cEAVDw9IHRyKbFtuj8zMUqVZ2EDvAwcOICEhAf3794eTkxMAwNHRUfXzszp37gw/Pz8cPHiwxHH8+uuvsLa2xrx589SW9+jRA127dtW6jY+Pj8YyNzc3vPrqq7h9+zbu379f4ngAYOPGjcjLy8OMGTPg6empWi6TybBo0SIA0DqdgY+PDz744AO1ZQWv89mzZ8s1Hm1XN2obmF+tWrUSt6sILJaIiMho9O/fHy4uLti+fTtSU1NVy3/77TcAmgO7w8PDMWDAALi5ucHKygoSiQQSiQRXr15FbGxsiWJIS0vDvXv34Ovrixo1amis79Chg9bt7t69i3feeQd16tSBjY2NKpZly5YBQInjKXDx4kUAytN4z2vbti1sbGxw6dIljXXNmjWDVKr+de/h4QEASElJKdd4rl69qlo2fPhwAECbNm0wefJkbN++HcnJyRrbDh06FFKpFAMHDsRbb72F33//HTExMSWOsywYZbGUkZGB4OBgBAUFwcnJqdDJvwreiNoe3bp1K/I4tWrV0rrthAkTyiErIqJSsLMDMjJ0PhRpaUiJjoYiLa3ItuX2sLMrVZpWVlZ4/fXXkZWVhY0bNwIA4uPjcfDgQXh5eSEwMFDVdsuWLejSpQsOHz6M9u3b47333sPs2bMRHBwMb29v5ObmliiGtLQ0AED16tW1rtc2xiciIgItW7bE2rVrUbt2bUyYMAGzZs1CcHAwAgICAAA5OTkliuf5uLQdXyKRwNXVVdXmWQ4ODhrLLC2VQ5bz8/PLNZ709HTVsiFDhmDHjh1o0qQJfvjhBwwaNAjVq1dH165d1Yq8l19+GeHh4ejYsSM2btyIkSNHwsPDA61bt9YYLF9RjHKAd3JyMubNmwcvLy80bdq00BlD169fr7Hs3Llz+PbbbwsdgPe8Zs2aYcaMGWrL6tWrV+yYiYjKlUQCVKqku41CAeTnK9tJjfL/wnoZO3Ysli5dijVr1mDixIn47bffkJeXhzFjxqj1kMyZMwc2NjY4f/486tatq7aPP/74o8THLyguEhMTta5PSEjQWPb111/j8ePHWL9+PUaNGqW2bsKECTh69GiJ43k+roSEBI2B60IIJCQkaC2Myos+8VSuXFltef/+/dG/f3+kp6fj5MmTCAkJwZo1axAUFISbN2+qBrh36NAB+/btQ1ZWFk6fPo1du3ZhxYoV6N27N65du4batWtXSI4FjLJYcnNzQ1xcHGrUqIFz586hVatWWts9/4YEns6KOmLECL2OVbNmTa37ISIiw2jUqBHatGmDv//+G1euXFHdXmTMmDFq7e7cuQM/Pz+NQikuLg53794t8fEdHBzg4+ODiIgIxMfHa5yKO378uMY2BVMVFFzxVkAIgZMnT2q0t7CwAFC8np3mzZtj+/btCA8P15is8vTp08jOzka7du303l9p6RNPYZNqVq5cGUFBQQgKCkJ+fj5+/vlnnD59Gj169FBrZ2tri06dOqFTp06oUqUKZs+ejbCwMIwfP77c8tLGKP/rIZPJtJ4nLkpOTg62bduGgIAA1flYfeTm5uLJkyfFPh4REZWPgrFJkyZNwo0bN9CpUyeN3gtvb29ERESo9fRkZ2dj4sSJkMvlpTr+66+/jtzcXMyePVtteWhoqNbZvgtiO3HihNryhQsX4tq1axrtCwamR0VF6R3TyJEjYWlpiaVLl6qNf8rNzcX//vc/ANAoKMuTPvE823Fx7NgxrcVhQQ+ejY0NAODUqVPIzs7WaFfwey5oV5GMsmeppPbu3YuUlBS89tprem9z+PBh2NnZIT8/H97e3nj//fcxbdq0Qtvn5OSonXcuOGcrl8tL9cdZsG1p/8CNEXMzPeaaF2DcucnlcgghoFAooFAoir29EEL1b0m2NyZDhgzBe++9p+qVGTVqlEZekydPxtSpU9G8eXO8+uqryMvLw8GDByGEQNOmTXH58mW19gU/F/b6Prts5syZCAkJwerVq/HPP/+gQ4cOiIqKwpYtW9CrVy/s3btXbT/jxo3D2rVr8eqrr2LIkCGoVq0aTp8+jQsXLmhtX69ePbi7u2PTpk2QSCTw8fGBVCrF5MmT4ejoqPpdPruNj48PFi5ciJkzZ8Lf3x9DhgxBpUqVsHv3bvz777/o168fRo4cqZYnUPT7QZ/3SknjGTZsmOr4U6dORWxsLF555RXVmOGTJ0/izJkzaNOmDdq1aweFQoGFCxciPDwcHTp0gI+PD2xsbHDx4kUcOnQItWvXRv/+/YuMWaFQQAgBuVyu6sV7XnE+A8yqWNqwYQNkMhkGDx6sV3t/f3+0b98e9evXx8OHD7Fu3Tq89957iI2NVV32+Lwvv/xS640PQ0NDYVfKgY0AEBYWVup9GCvmZnrMNS/AOHOztLREjRo1kJGRUeLByQDUBtWasgEDBmDDhg2oWrUqevfurZHXqFGjkJeXh1WrVuGnn36Co6MjunfvjtmzZ6t6WJ4d8FzQW5Gdna22vOCL9/nB0Tt37sTcuXNVE1w2aNAAP//8M9LS0rB37161/dSpUwchISGYP38+tm/fDqlUitatW2P//v3Yt28f9u7di8zMTLVj/PLLL5gzZw5CQkJUufXv3x8SiUT1n/Lntxk7dizc3NywYsUKbNiwAbm5uahTpw7mz5+P8ePHq71GGRkZAJRFgbaB3wCQl5dX6LpnlTQeiUSiimnq1KnYvXs3Ll26hNDQUFhaWsLLywtz5szB2LFjVWd43njjDdjZ2eH8+fM4duwYhBDw8PDA9OnTMWnSJK2/q+fl5uYiKysLx44d0zqTeEEu+pKIgnLRSBWMWVq7dq3O7sW0tDS4urqiZ8+eCAkJKdGxhBDo2bMnDh06hHv37mk9laetZ8nT0xPJycmlGlgnl8sRFhaGbt26wcrKqsT7MUbMzfSYa16AceeWnZ2NqKgo1e0yiksIgfT0dFSuXFljFmdTZq55AcytvGRnZyMyMhKenp6F/i2lpaXB2dkZqampRX5/m03P0rZt25CdnV2sU3DPk0gkeP/993HgwAGEh4drHfgtk8kgk8k0lltZWZXJB29Z7ccYMTfTY655AcaZW35+PiQSCaRSqca8OPoo6CEp2Ie5MNe8AOZWXqRSKSQSic6/8+L8/ZvNb2bDhg1wdHREnz59SrWfgllIHz16VBZhERERkYkzi2IpLi4OR44cwauvvqq116c4Ci43dXFxKYvQiIiIyMSZRbH0xx9/QKFQFHoKTi6X4+bNm4iLi1Mte/TokcYljHK5HAsXLoS1tTU6d+5crjETERGRaTDaMUvLly9HSkqKau6GXbt2ITo6GgAwZcoUODo6qtpu2LAB7u7uWu9PAwAxMTFo2LAhRo8erbptys6dOzF//nwMHjwYPj4+ePToETZu3Ihr165hwYIFJZrniYiIiMyP0RZLS5YsUbtDc0hIiOoqt1GjRqmKpX///Rfnz5/H9OnTizWArEmTJmjUqBF+++03JCUlwdraGs2aNcPmzZsxZMiQsk2GiIiITJbRFkuRkZF6tatfvz6Kmv2gVq1aGm1eeukl7Ny5s6ThERGVGyOf0YXI6JX135BZjFkiIjIHBTMNG+Ps4kSmpOBvqLDZu4uLxRIRkZGwsrKCTCZDamoqe5eISkgIgdTUVMhksjKbS81oT8MREb2InJ2dERMTg+joaDg6OsLKykrv2Y8VCgVyc3ORnZ1tVhMcmmteAHMrSwX3gktNTUVGRgZq1qxZZvtmsUREZEQKbruQnJyMmJiYYm0rhEBWVhZsbW3N6tYZ5poXwNzKg0wmQ82aNUt1C7LnsVgiIjIyDg4OcHBwgFwu15gPThe5XI5jx46hY8eORncrl9Iw17wA5lbWLCwsyuVYLJaIiIxUce9fZ2Fhgby8PNjY2JjVF6+55gUwN1NhXidIiYiIiMoYiyUiIiIiHVgsEREREenAYomIiIhIBxZLRERERDqwWCIiIiLSgcUSERERkQ4sloiIiIh0YLFEREREpAOLJSIiIiIdWCwRERER6cBiiYiIiEgHFktEREREOrBYIiIiItKBxRIRERGRDiyWiIiIiHRgsURERESkA4slIiIiIh1YLBERERHpwGKJiIiISAcWS0REREQ6sFgiIiIi0oHFEhEREZEOLJaIiIiIdGCxRERERKQDiyUiIiIiHVgsEREREelglMVSRkYGgoODERQUBCcnJ0gkEqxbt06j3ZgxYyCRSDQeDRo00PtYO3fuRIsWLWBjYwMvLy8EBwcjLy+vDLMhIiIiU2Zp6AC0SU5Oxrx58+Dl5YWmTZsiPDy80LYymQw//fST2jJHR0e9jrNv3z4MGDAAnTp1wrJly3D16lXMnz8fiYmJWLlyZWlSICIiIjNhlMWSm5sb4uLiUKNGDZw7dw6tWrUqtK2lpSVGjRpVouPMnDkT/v7+CA0NhaWl8qVwcHDAggULMG3atGL1UBEREZF5MsrTcDKZDDVq1NC7fX5+PtLS0op1jOvXr+P69esYN26cqlACgEmTJkEIga1btxZrf0RERGSejLJnqTgyMzPh4OCAzMxMVK1aFSNGjMCiRYtgb2+vc7uLFy8CAFq2bKm23N3dHR4eHqr1z8vJyUFOTo7qeUGRJpfLIZfLS5xHwbal2YexYm6mx1zzApibKTLXvADmZkjFicukiyU3Nzd8+OGHaNGiBRQKBfbv348VK1bg8uXLCA8PV+sxel5cXJxqH9r2Gxsbq3W7L7/8EnPnztVYHhoaCjs7uxJm8lRYWFip92GsmJvpMde8AOZmisw1L4C5GUJmZqbebU26WPryyy/Vng8fPhz16tXDp59+iq1bt2L48OGFbpuVlQVAecrveTY2NoWe1vv4448xffp01fO0tDR4enqie/fucHBwKEkaAJQVblhYGLp16wYrK6sS78cYMTfTY655AczNFJlrXgBzM6TiDN8x6WJJm/fffx+zZs3CwYMHdRZLtra2AKB2Sq1Adna2av3zZDKZ1gLLysqqTN4MZbUfY8TcTI+55gUwN1NkrnkBzM0QihOTUQ7wLg1bW1tUq1YNjx490tmu4PRbwem4Z8XFxcHd3b1c4iMiIiLTYnbFUnp6OpKTk+Hi4qKzXbNmzQAA586dU1seGxuL6Oho1XoiIiJ6sZlssZSdnY309HSN5Z9//jmEEAgKClItk8vluHnzplovkp+fHxo0aIBVq1YhPz9ftXzlypWQSCQYPHhw+SZAREREJsFoxywtX74cKSkpqqvSdu3ahejoaADAlClT8PjxYzRv3hwjRoxQTR554MAB7N27F0FBQejfv79qXzExMWjYsCFGjx6tdtuUxYsXo1+/fujevTuGDx+Oa9euYfny5Xj77bfRsGHDikuWiIiIjJbRFktLlizB/fv3Vc9DQkIQEhICABg1ahSqVKmCPn36ICwsDL/88gvy8/Ph6+uLBQsWYObMmZBKi+4069OnD0JCQjB37lxMmTIFLi4u+OSTTzB79uxyy4uIiIhMi9EWS5GRkUW2Wb9+vV77qlWrFoQQWtcNGDAAAwYMKEZkRERE9CIx2TFLRERERBWBxRIRERGRDiyWiIiIiHRgsURERESkA4slIiIiIh1YLBERERHpwGKJiIiISAcWS0REREQ6sFgiIiIi0oHFEhEREZEOLJaIiIiIdGCxRERERKQDiyUiIiIiHVgsEREREenAYomIiIhIBxZLRERERDqwWCIiIiLSgcUSERERkQ4sloiIiIh0YLFEREREpAOLJSIiIiIdWCwRERER6cBiiYiIiEgHFktEREREOrBYIiIiItKBxRIRERGRDiyWiIiIiHRgsURERESkA4slIiIiIh1YLBERERHpwGKJiIiISAcWS0REREQ6sFgiIiIi0sHoiqWMjAwEBwcjKCgITk5OkEgkWLdunVobhUKBdevWoV+/fvD09ESlSpXQuHFjzJ8/H9nZ2Xodp1OnTpBIJBqPoKCgcsiKiIiITJWloQN4XnJyMubNmwcvLy80bdoU4eHhGm0yMzPx5ptvok2bNpgwYQKqV6+OU6dOITg4GIcOHcLhw4chkUiKPJaHhwe+/PJLtWXu7u5llQoRERGZAaMrltzc3BAXF4caNWrg3LlzaNWqlUYba2trnDx5Eu3atVMte+edd1CrVi1VwRQYGFjksRwdHTFq1KgyjZ+IiIjMi9GdhpPJZKhRo4bONtbW1mqFUoGBAwcCAG7cuKH38fLy8pCRkVG8IImIiOiFYXQ9S6URHx8PAHB2dtar/a1bt1CpUiXk5ubC1dUV77zzDmbPng0rK6tCt8nJyUFOTo7qeVpaGgBALpdDLpeXOPaCbUuzD2PF3EyPueYFMDdTZK55AczNkIoTl0QIIcoxllIpOA23du1ajBkzpsj23bp1w5kzZ3D//n1UqVJFZ9uxY8fCy8sLTZo0wZMnT7B161bs3LkTQ4cOxaZNmwrdbs6cOZg7d67G8o0bN8LOzq7IGImIiMjwMjMzMXLkSKSmpsLBwUFnW7MplhYsWIBPP/0UK1aswMSJE0t0vHHjxmH16tU4deoU2rRpo7WNtp4lT09PJCcnF/li6yKXyxEWFoZu3brp7NkyRczN9JhrXgBzM0XmmhfA3AwpLS0Nzs7OehVLZnEabtOmTfjss88wduzYEhdKADBjxgysXr0aBw8eLLRYkslkkMlkGsutrKzK5M1QVvsxRszN9JhrXgBzM0XmmhfA3AyhODEZ3QDv4goLC8Mbb7yB3r1744cffijVvjw9PQEAjx49KovQiIiIyAyYdLF0+vRpDBw4EC1btsTmzZthaVm6jrK7d+8CAFxcXMoiPCIiIjIDJlss3bhxA71790atWrWwe/du2NraFtr25s2bePDggep5Wlqa2rgjABBCYP78+QCAHj16lE/QREREZHKMcszS8uXLkZKSgtjYWADArl27EB0dDQCYMmUKpFIpevTogcePH+ODDz7Anj171LavU6cO2rZtq3resGFDBAQEqGYDv3DhAkaMGIERI0bA19cXWVlZ2L59O06ePIlx48ahRYsWFZMoERERGT2jLJaWLFmC+/fvq56HhIQgJCQEAFQzbkdFRQEAPvroI43tR48erVYsPc/b2xsdOnTA9u3bER8fD6lUioYNG+KHH37AuHHjyjIVIiIiMnFGWSxFRkYW2aY4Mx4839bHxwebN28ublhERET0AjLZMUtEREREFYHFEhEREZEOLJaIiIiIdGCxRERERKRDqYqlqKgoHD58GJmZmaplCoUCixYtwiuvvILAwECNy/qJiIiITEmproabNWsWdu3ahfj4eNWyL774AsHBwarnR48exV9//YVWrVqV5lBEREREBlGqnqWTJ08iMDBQdTM6IQSWL1+OBg0a4MGDBzhz5gwqVaqExYsXl0mwRERERBWtVMVSYmIivL29Vc8vXbqEpKQkTJkyBR4eHmjZsiUGDBiAs2fPljpQIiIiIkMoVbGkUCigUChUz8PDwyGRSNClSxfVspo1a6qdpiMiIiIyJaUqlry8vHDmzBnV8x07dsDNzQ3169dXLYuPj0eVKlVKcxgiIiIigylVsfTqq6/i5MmTGDx4MEaNGoUTJ07g1VdfVWtz/fp11K5du1RBEhERERlKqa6GmzlzJkJDQ1U3ufX398ecOXNU6+/fv48zZ85ovdktERERkSkoVbHk4OCAv//+G9euXQMANGzYEBYWFmptQkJC0LJly9IchoiIiMhgSlUsFWjcuLHW5d7e3mpXyxERERGZmlKNWUpPT8fdu3chl8vVlm/atAmvvfYa3n77bVy8eLFUARIREREZUql6lj788EP89ttvSEhIUE1MuXLlSkyePBlCCADA77//jvPnz6NBgwalj5aIiIiogpWqZ+no0aMIDAyEnZ2datnChQtRs2ZNHDt2DJs3b4YQgjN4ExERkckqVc9SXFwcgoKCVM9v3LiBqKgo/N///R/at28PANi6dSuOHTtWuiiJiIiIDKRUPUs5OTmwtrZWPT969CgkEgm6d++uWla7dm3ExMSU5jBEREREBlOqYsnDwwNXrlxRPd+9ezecnJzg7++vWvbw4UPY29uX5jBEREREBlOq03A9e/bE999/j5kzZ8LGxgb79+/HG2+8odbm1q1b8PLyKlWQRERERIZSqmLp448/xq5du7B06VIAgJubG+bNm6dan5iYiJMnT2Ly5Mmli5KIiIjIQEpVLNWoUQP//PMPDh06BADo2LEjHBwcVOuTk5OxePFi9OjRo3RREhERERlIqWfwtrW1RZ8+fbSua9SoERo1alTaQxAREREZTJnc7gQAYmJicOnSJaSlpcHBwQHNmjVDzZo1y2r3RERERAZR6mIpIiICEydOxOHDhzXWde3aFStWrICvr29pD0NERERkEKUqlqKiotC+fXskJiaiQYMG6NixI9zc3BAfH49jx47h4MGD6NChA86cOQNPT8+yipmIiIiowpSqWJo7dy4SExOxYsUKjB8/HhKJRG39jz/+iIkTJ2LevHlYvXp1qQIlAMnJQHQ0ULMm4OJi6GiIiIheCKWalPLAgQPo27cvJkyYoFEoAcD48ePRt29f7Nu3rzSHoQKjRwPNmwO7dhk6EiIiohdGqYqlxMRENG7cWGebxo0bIykpqTSHoQLu7sp/Y2MNGwcREdELpFTFkouLC65fv66zzfXr1+HCU0Zlg8USERFRhStVsdSjRw/s3LkTa9as0br+559/xq5duxAUFFSaw1ABFktEREQVrlQDvIODg7Fr1y6MGzcO33zzDQICAuDq6oqEhAQcO3YM//zzD6pVq4bg4OCyivfFxmKJiIiowpWqZ8nLywsnT55EQEAA/vnnH6xYsQLBwcFYsWIFrl27hk6dOuHkyZPFnjYgIyMDwcHBCAoKgpOTEyQSCdatW6e17Y0bNxAUFAR7e3s4OTnh9ddfL9YYqZ07d6JFixawsbGBl5cXgoODkZeXV6x4K4ybm/JfFktEREQVptSTUtatWxeHDx9GVFSUxgzenp6eWLRoEUJDQ1X3j9NHcnIy5s2bBy8vLzRt2hTh4eFa20VHR6Njx45wdHTEggULkJGRgSVLluDq1as4c+YMrK2tdR5n3759GDBgADp16oRly5bh6tWrmD9/PhITE7Fy5crivAwVo6BnKT4eyM8HLCwMGw8REdELoMxud+Lp6am1B+nmzZuFFjuFcXNzQ1xcHGrUqIFz586hVatWWtstWLAAT548wfnz5+Hl5QUAaN26Nbp164Z169Zh3LhxOo8zc+ZM+Pv7IzQ0FJaWypfCwcEBCxYswLRp09CgQYNixV3uqlcHpFJloZSUBNSoYeiIiIiIzF6pTsOVF5lMhhp6FALbtm1Dnz59VIUSAAQGBqJevXrYvHmzzm2vX7+O69evY9y4capCCQAmTZoEIQS2bt1a8gTKi6Ul4Oqq/Jmn4oiIiCpEmfUsVbSYmBgkJiaiZcuWGutat26NvXv36tz+4sWLAKCxvbu7Ozw8PFTrn5eTk4OcnBzV87S0NACAXC6HXC4vVg7PKti2qH1YuLlBGheHvAcPIJo0KfHxKpK+uZkic83NXPMCmJspMte8AOZmSMWJy2SLpbi4OADKU3bPc3Nzw6NHj5CTkwOZTFai7WML6bn58ssvMXfuXI3loaGhsLOz0zv+woSFhelc39rCAm4AroWG4r6WWdONWVG5mTJzzc1c8wKYmyky17wA5mYImZmZerc12WIpKysLALQWQzY2Nqo2hRVLRW1f0GP0vI8//hjTp09XPU9LS4Onpye6d+8OBweH4iXxDLlcjrCwMHTr1g1WVlaFtpPu2QOcPYsmzs7w69WrxMerSPrmZorMNTdzzQtgbqbIXPMCmJshFfY9r43JFku2trYAoHZKrEB2drZam5JsX9i2MplMa4FlZWVVJm+GIvfj4QEAsEhIgIURvvl0KavXyBiZa27mmhfA3EyRueYFMDdDKE5MxS6WehWzN+Pq1avFPYReCk6fFZxOe1ZcXBycnJwK7VV6fvvnr+KLi4tD69atyzDaMsSJKYmIiCpUsYul/fv3F/sgknIYW1OzZk24uLjg3LlzGuvOnDmDZs2a6dy+YP25c+fUCqPY2FhER0cXOe2AwbBYIiIiqlDFLpbu3btXHnGUyKuvvopffvkFUVFRqt6hQ4cO4datW3j//fdV7eRyOe7cuQNHR0dVj5Kfnx8aNGiAVatWYfz48bD4b4LHlStXQiKRYPDgwRWfkD44izcREVGFKnax5O3tXR5xaFi+fDlSUlJUV6Xt2rUL0dHRAIApU6bA0dERn3zyCbZs2YLOnTtj2rRpyMjIwOLFi9GkSRO8+eabqn3FxMSgYcOGGD16tNptUxYvXox+/fqhe/fuGD58OK5du4bly5fj7bffRsOGDSskz2Ir6FlKSADy8pRzLxEREVG5Mdpv2iVLluD+/fuq5yEhIQgJCQEAjBo1Co6OjvD09MTRo0cxffp0fPTRR7C2tkbv3r3x1Vdf6RyvVKBPnz4ICQnB3LlzMWXKFLi4uOCTTz7B7Nmzyy2vUnNxUd7mJD9fWTDVrGnoiIiIiMya0RZLkZGRerXz8/PDgQMHdLapVasWhBBa1w0YMAADBgwoZnQGJJUqT8VFRytPxbFYIiIiKldGebsTKgIHeRMREVUYFkumiMUSERFRhWGxZIpYLBEREVUYFkumiMUSERFRhWGxZIoKiiUts5cTERFR2WKxZIrYs0RERFRhWCyZIhZLREREFYbFkikquOVJUhKQm2vYWIiIiMwciyVTVK0aYGWl/Dk+3rCxEBERmTkWS6ZIIuGpOCIiogrCYslUsVgiIiKqECyWTBWLJSIiogrBYslUsVgiIiKqECyWTBWLJSIiogrBYslUsVgiIiKqECyWTBWLJSIiogrBYslU8f5wREREFYLFkqkqmMX70SMgO9uwsRAREZkxFkumqkoVwMZG+TN7l4iIiMoNiyVTxVm8iYiIKgSLJVPGYomIiKjcsVgyZSyWiIiIyh2LJVPGYomIiKjcsVgyZSyWiIiIyh2LJVPGYomIiKjcsVgyZSyWiIiIyh2LJVPGYomIiKjcsVgyZQWzeKelAU+eGDYWIiIiM8ViyZRVrgxUqqT8mbN4ExERlQsWS6aMs3gTERGVOxZLpo7FEhERUblisWTqWCwRERGVKxZLpo7FEhERUbky6WJpzJgxkEgkhT5iYmIK3XbOnDlat7GxsanADEovxU5ZLGVGsFgiIiIqD5aGDqA0xo8fj8DAQLVlQghMmDABtWrVQs2aNYvcx8qVK2Fvb696bmFhUeZxlpc1a4BD892xEcCZP2NxZw0wdqyhoyIiIjIvJl0stW3bFm3btlVbduLECWRmZuK1117Tax+DBw+Gs7NzeYRXrqKjgXHjgFeEsmfJHbEIHA/06AF4eBg4OCIiIjNi0qfhtNm4cSMkEglGjhypV3shBNLS0iCEKOfIytbt24BCAcTiabGUny8QEWHgwIiIiMyMSfcsPU8ul2Pz5s1o164datWqpdc2tWvXRkZGBipVqoQBAwbgq6++gqura6Htc3JykJOTo3qelpamOrZcLi9V7M/+W5RatQCp1BJxCuUs3vZ4girSNHh726EUYZSL4uZmSsw1N3PNC2Bupshc8wKYmyEVJy6JMLUuFR12796Nvn37YsWKFZg4caLOtt9++y0iIiLQtm1byGQyHD9+HN9//z18fHxw7tw5ODg4aN1uzpw5mDt3rsbyjRs3ws7Orkzy0FdYmBdWrmyKR4qqcEQaPh+5Df5DTWfMFRERkaFkZmZi5MiRSE1NLfQ7v4BZFUsjR47E1q1bERcXh2rVqhV7+40bN+K1117Dl19+iY8++khrG209S56enkhOTi7yxdZFLpcjLCwM3bp1g5WVld7bRUcD1QP8USnqJvIOHIDo3LnEMZSXkuZmCsw1N3PNC2Bupshc8wKYmyGlpaXB2dlZr2LJbE7DZWRk4M8//0SPHj1KVCgBymJrxowZOHjwYKHFkkwmg0wm01huZWVVJm+G4u7HxwdAXXcg6iYsk5IAI3xDFiir18gYmWtu5poXwNxMkbnmBTA3QyhOTGYzwHvHjh3FugquMJ6ennj06FEZRVVBODElERFRuTGbYmnDhg2wt7dHv379SrwPIQQiIyPh4uJShpFVABZLRERE5cYsiqWkpCQcPHgQAwcO1DrI+sGDB7h586bGNs9buXIlkpKSEBQUVG6xlgsWS0REROXGLMYsbdq0CXl5eYWegnvjjTdw9OhRtbmUvL29MWzYMDRp0gQ2NjY4ceIE/vjjDzRr1gzjx4+vqNDLBoslIiKicmMWxdKGDRtQvXp1jVuf6PLaa6/hr7/+wrZt25CdnQ1vb298+OGH+PTTTyt8CoBSY7FERERUbsyiWDp16pTO9eHh4RrLVq9eXU7RGMCzxZIQgERi2HiIiIjMiFmMWXrhuSln8UZ2NpCSYtBQiIiIzA2LJXNgYwNUrar8mafiiIiIyhSLJXPBcUtERETlgsWSuWCxREREVC5YLJkLFktERETlgsWSuSgoluLiDBsHERGRmWGxZC7Ys0RERFQuWCyZCxZLRERE5YLFkrlgsURERFQuWCyZi+dn8SYiIqIywWLJXNSoofxXLgcePjRsLERERGaExZK5sLYGnJ2VP/NUHBERUZlhsWROOG6JiIiozLFYMicsloiIiMociyVzwmKJiIiozLFYMicsloiIiMociyVzwmKJiIiozLFYMicsloiIiMociyVzwpvpEhERlTkWS+bk2WJJoTBsLERERGaCxZI5cXUFJBIgPx9ISjJ0NERERGaBxZI5sbQEqldX/sxxS0RERGWCxZK54SBvIiKiMsViydywWCIiIipTLJbMTUGxdPu2YeMgIiIyEyyWzE2XLsp/V68GHj82bCxERERmgMWSuRkyBGjcGEhJAZYsMXQ0REREJo/FkrmxsADmz1f+/M03QEKCQcMhIiIydSyWzFG/fsDLLwOZmcAXXxg6GiIiIpPGYskcSSTAggXKn3/4Abh/37DxEBERmTAWS+aqSxega1dALgfmzjV0NERERCaLxZI5KzgF98svwM2bho2FiIjIRLFYMmcvvwz07w8oFEgcPwvR0YYOiIiIyPSYdLEUHh4OiUSi9fH3338XuX1MTAyGDh2KKlWqwMHBAf3798fdu3crIPKKE9JiPhSQoPqxrRjodR5r1hg6IiIiItNiaegAysLUqVPRqlUrtWW+vr46t8nIyEDnzp2RmpqKTz75BFZWVvj6668REBCAS5cuoVq1auUZcoWIjgaGzG2MdXgNr+M3zBOfoe/4fejRA/DwMHR0REREpsEsiqUOHTpg8ODBxdpmxYoVuH37Ns6cOaMqtHr27InGjRvjq6++woKCq8lM2O3bgEIBzMEcDMcf6In9aJd/DBERHVksERER6cmkT8M9Kz09HXl5eXq337p1K1q1aqXWI9WgQQN07doVmzdvLo8QK1zduoBUCtxFHazGOwCAL/EJfOsIA0dGRERkOsyiZ+nNN99ERkYGLCws0KFDByxevBgtW7YstL1CocCVK1fw1ltvaaxr3bo1QkNDkZ6ejsqVK2usz8nJQU5Ojup5WloaAEAul0Mul5c4h4JtS7OP57m6AitXSjBpkgXm53+GN7EWr+Ak8i7ugrxGzzI7TlHKIzdjYa65mWteAHMzReaaF8DcDKk4cUmEECbbzfDXX39h6dKl6NWrF5ydnXH9+nUsWbIET548wV9//YXmzZtr3S45ORkuLi6YN28eZs2apbZuxYoVePfdd3Hz5k3Ur19fY9s5c+ZgrpZ5izZu3Ag7O7uySayMJSfbIC6uEvqd+Bb+B7YitVYthC9dqux2IiIiegFlZmZi5MiRSE1NhYODg862Jl0saRMREQF/f3907NgR+/fv19omKioKXl5eWLRoET788EO1dT///DPGjh2LixcvolmzZhrbautZ8vT0RHJycpEvti5yuRxhYWHo1q0brKysSrwfnR4+hGX9+pCkpSHvt98ghg4tn+M8p0JyMxBzzc1c8wKYmyky17wA5mZIaWlpcHZ21qtYMovTcM/y9fVF//79ERISgvz8fFhYWGi0sbW1BQC1oqdAdna2WpvnyWQyyGQyjeVWVlZl8mYoq/1oVaMGMHMmMHs2LOfOBYYNAywr7i1QrrkZmLnmZq55AczNFJlrXgBzM4TixGSW52E8PT2Rm5uLJ0+eaF3v5OQEmUyGuLg4jXUFy9zd3cs1RoN57z3A2Vl5qdxPPxk6GiIiIqNnlsXS3bt3YWNjA3t7e63rpVIpmjRpgnPnzmmsO336NGrXrq11cLdZqFwZ+Owz5c/vvw9cuGDYeIiIiIycSRdLSUlJGssuX76MnTt3onv37pD+N4D5wYMHuPncvdEGDx6Ms2fPqhVM//77Lw4fPowhQ4aUb+CGNnky0LMnkJ0NDBgAJCYiOho4cgS8JQoREdFzTHrM0rBhw2Bra4t27dqhevXquH79OlatWgU7OzssXLhQ1e6NN97A0aNH8exY9kmTJmH16tXo3bs3Zs6cCSsrKyxduhSurq6YMWOGIdKpOBYWwMaNQOvWwO3biOswBHVuH0SusIJUCqxaBYwda+ggiYiIjINJ9ywNGDAAycnJWLp0KSZNmoRNmzZh0KBBOHfuHBo2bKhz28qVKyM8PBwdO3bE/PnzMWvWLDRt2hRHjx6Fi4tLBWVgQFWqAH/+CYV9ZbjdOoavxPsAlDN+jx/PHiYiIqICJt2zNHXqVEydOrXIduHh4VqXe3h4YMuWLWUclQlp2BDX/vcb/Gf1x2R8j4tojp8xFvn5QEQE7x9HREQEmHjPEpWe05h+mC2ZBwBYiYlog1OwsACKuA8xERHRC4PF0gvOwwPw/vFThGAQrCFHCAZh/cIY9ioRERH9h8USYew7Urx88xdk+DSGG+IxYssg5ZVyRERExGKJlGrWt4d92A6galXgzBlg4kTAvO6EQ0REVCIsluipOnWAzZuVN9hdtw5YtszQERERERkciyVSFxgILF6s/Hn6dGD3btUqTlxJREQvIhZLpOn994FRo4D8fKBvX2DoUGz6v/vw9ga6dAG8vYE1awwdJBERUcVgsUSaJBJg9Wpg0iTlKbktW9Dvfw3wmWIubJHJiSuJiOiFwmKJtLOxAb7/HrhwAY+bBsAW2ZiLObiBhhiMLcjPF4iIMHSQRERE5Y/FEunWtCme7DqC4ZJNeABPeOMBtmAowtEZDeVXNJpzXBMREZkbFktUJA9PCbqtHgo/6U3MQTCyYIMAHIVrUHPlqbpr14CMDKxZA45rIiIis2PS94ajijN2LNCjhx0iIuYgxeZN2C79ANiyBVi5UvkAMBBV0QLeeAAvPFB44dY7XniY6w3HJu6wyMkxcAZEREQlw2KJ9ObhUXBzXW/lfEzh4cDs2cDVq0BKCpzwGE54jOa4pNxAAJik/DGwalVIKlUCevc2SOxEREQlxWKJSq5TJ+DYMQBAzI009PR7AA/xAF54AG/ch7fkAV5t+QDWkf/CJikJ6NMHeO89RL/7JW5H2aBuXeh/D7rISOCzz4DYWOCbbwB//3JKioiISB3HLFGZqNnQAdNWN0aoRS/8iAmYZfElslZvgOzMceRFROBur17Kht98g4d1X8bkLv/oN64pPR349FOgQQNgwwbl6PFWrZQTZ+bnl3teRERELJaozIwdq+wAOnJE+e/Ysf+tsLXF1XHjEL/mTySgOpriCs6hJSYqlmP8OKH9yjmFAli7FqhXD1iwAMjJATp3VvZO5eYCH36oHEkeGVlh+RER0YuJxRKVKQ8P5dk5bafXrnr2gj+uYC96whbZWI4p+FPRB/fPJKg3PH5c2Xv01ltAfLzynnU7dgCHDgE7dyonzKxUSXkK0N8f+PVX3vSXiIjKDYslqjC+vgLJUlf0xh5MxjJkQ4be2Is24/2BvXuBe/eAoUOBjh2BCxegqOyAiPGLEX3gH6B/f+XM4hIJ8PbbwOXLQNu2ytN0o0cDQ4YAycmGTpGIiMwQiyWqMB4ewKpVgIWFBN9jMl6WnsOjmk1gkZyovEquQQPldARSKW4EjId7xm3U/XEmvOvJNMc21akDHDuG1A+/gMLCEti2DWjSBNi3zyC5ERGR+WKxRBXq2XFNe+43hlPEGWDaNOXK3Fygc2ck7L+Ixsd/QIKoDgCF3otuzS+WcFryCVrmn8Z1NFSesuvVS3mQ/fuBx48rNjkiIjJLLJaowqmNa7KxUU4FcOqUckzSoUO4bukPhUJ9m/x8qN2LLjoaGDdOWUhdRAu8hPP4VvJf0fXzz0DPnoCTE9CokbJ4+ukn4J9/oLFjIiKiInCeJTIObdqofqxbF5BK1esaCwvA1/fp89u31ddnwxbviW8Q8PUANDu/Rll83bkD3LihfPz8s7KhgwPw8svKcVGTJwNVqpRvXkREZPLYs0RG5+nYJuVzCwvgxx/Vr7ArKKieZWEBOA/uBKxfr+yGSkgA/vwTae9+hMdNA6CwtQPS0oCwMGDWLOWVdOHhAHgDYCIiKhyLJTJKhc7Z9B99CipUr441Sf1QdeWXcLocDpvsVOyYfQFYvlw5QDwqCujSBVeCPkBdrxzeAJiIiLRisURGS9ecTUDRBdWz45oAQC4sMfiL5oju/y5w6ZJyCgIh4H9gCU6LVmiMq4UOJtcqNRWS0FBYZGWVOEciIjJ+LJbIpOkqqJ4f1wQ8M1Dc3h5YvRpXPv8TiXCBP67iHFpiOr6CIl+hNpi8QHQ0cPRANh6u2gYMHgy4usKyTx8EfPAB8O+/5ZEeEREZARZLZLYKG9f07EBxpzH90FRyFbvQBzLk4ivMxGF0RX3bB08b5eVh//RQHPIcg2ZBrqg2frByXqecHAhra1SOjoblK68Au3dXTGJEJfXPP8BLLwEzZwLsESXSG4slMlv6jGvy8ADmr3bFQOlOjMOPeAI7dEI43Lo3Ab77DpgyBfluNRH0dQ+Mxi9wRBoewBOLJR8i4cAl5N25g4cNG0KSlgb064fUD+bjyCEFB4qT8RECePdd4MIF4KuvgJYtgYsXDR0VkUlgsURmrahxTao29yUYeWQc0o5dVk4tkJamnCxz+XJYJCciGdWwAhPRHsdRC5H4UCzCDeumgKsrTs6bh/wJEwAh4LhkFh4FDoGfV3qhA8VN4sq76Gi4XL7Me+6Zk507gaNHlXObuboC168r3+tffqk8P01EhWKxRGavqIHiz7Zx6+ALnDgBzJsHeHkBo0Yh+Zc9qCmJw7tYgZNoDwGp2uk8YWWFBx9+h3GS1ciBNV5FCP4SbfB/4yI0Zx1fo7zizqivvDt+HJYtWqBdcDCkn39u6GioLMjlwIcfKn+ePh24dg0YOFC5/JNPgIAA5b0ZiUgrFktEz7O0VM7DdP8+sH49nN/ohRWrrXSezouIkGC1eBsBOIpYuMEP1/G3ohUebdyvavP81Xm6rrwzWO9TSAjQrRskKSkAAIv584HVqys4CCpzP/4I3LoFVK8O/O9/gLOzctzdunVA5crAyZPKecfWrmVvoikSApgwARgwAMjMNHQ0ZonFEpEeijqd5+srIJUCp9EGL+E8/kJbVEUKmnzUC1i4EEhPR+S5ZNRQxMAHd9EQ19EMF9Ey/28kbw0HQkOV40eePNG796nMC6oVK5RX+eXkQNG3L24PGqRcPmECsGtXGR2EKlxqKjBnjvLnuXOVs9gDgEQCjB4NXL4MtG8PZGQAb70FDBoEJCUZLFwqgbVrlQXxn38CwcGGjsYsmWyxdPbsWUyePBl+fn6oVKkSvLy8MHToUNy6davIbdetWweJRKL1ER8fXwHRkynSdTrv2cHk8XBDoPQIbnZ8BxIhgI8/Bhwc0H6gC2Lggbuog+vww0W0wN9oi2bvdwZ69ABatADs7dH9bU8cUATie0zCZMW3CBm3H3F/3VMbV1Kc03lFFlVCIG3Kp8rBv0IA48Yhf9MmXH/9dShGj1Z2gQ0bhsSdfxv/WCvStGAB8PAh0LChcm6x5/n4KGeyX7gQsLICduwAmjQBDh6s6EipJOLigBkznj5fuhQ4fdpw8Zgpk7033KJFi3Dy5EkMGTIE/v7+iI+Px/Lly9GiRQv8/fffaNy4cZH7mDdvHnx8fNSWVeG9wqiExo5V1jwREYCvrwweHquAH19SfpA9eQIAUFhYIjNfhhwoH/bONnBwlim/pGJjgYcP4YloeCIagTik3LECwCsAZDLglVeQPGIKJozrC4VQnhcsOJ3Xo4dmIbdmzdNTf1KpsqBT6xWTy3Gr83jUO7kWABAsmQuvVrPwhmUeIJEgf8UKSBMTgX37IO3fB+PxF+5I62nuh4xTZCTw7bfKnxcvVp5i1sbCQnl6rkcPYNQo5RQDvXsrexS7d6+wcE1KdrZysLyhTZkCpKQo/7NVrx7wxx/KHsILF5SfGVQ2hIk6efKkyMnJUVt269YtIZPJxGuvvaZz27Vr1woA4uzZs6WOIzU1VQAQqamppdpPbm6u2LFjh8jNzS11TMbmhc8tJ0eIJ0+EyMsTQggRFSXEkSPKf58XcyVZtJP8JUZjrViAj8RWDBJX4ScU1tZCKPt9hADEXdQSM7BYVMEj1eIjR9T3FRUlhFSqtpmwsHjmuBkZIrNLLyEAkQepGIvVqjZ37z7NK/pmujiDlkIA4g58hCvi1Pfz3DEPH9a+zli8UO/HESOUv/guXYRQKPTbSVaWEIMGKbezsdF8YxmA0f3Otm1TvjZDhwqRnV2qXZUqt5CQp3/YFy8KkZwsRPXqymWffVaquMqC0f3enlOc72+T7Vlq166dxrK6devCz88PN27c0Hs/6enpsLOzg0XB6F2ismZtrXz8x8Oj8Cvz3JtUw1ur22L8+LbIz386mLzxmP+mHl+3Dvk/rIJPSiSW4APMRTDW43V8L50KX99GavvSNYO5hywJ6NMHtmfOIBO2GIZN2I2+qjZ37khU29yKtccw7MFfaAdf3MEe9Ean/HBERFRWy6PIXiwhgIwMxP3zCNFXHqGW42O4WDwCHj9WjquxsFC+TjIZHmVYI+6hNVy9rOHsLlMut7VVTqhoawtAeTrw9m3l5KO6rnQsSlntx+icOQP8/rtybNJXXyn/1YeNjXK7V19VTrTapw9w4ADwyivlG6+piI5WvrGzs4HNm4FHj5SnLitVqtg4UlKUp84B4IMPgGbNlD9//z0wZIjytOqrrz5dTqVTAcVbhVEoFKJmzZqie/fuOtsV9CzZ29sLAMLa2lr07dtX3Lp1q9jHZM9S0Zhb8enqfRKZmeLYG6vFZTRR7zYKDBRi505lD1Z2toi+niqqSxJFTUSJ2ogQDfGPeEl6QSRuOixE3brKHqUqTqKd5C+N3qdne5YKeqjq4LZIgIsQgDiA7iLqbq5avM/2YtkjTQyShoiM4WOFaNhQCBcXISwt1eMtycPTU4g//hA/rVaojieVCvHTT/q/ts/+zn76SZR4P8ZIlVtOjhDt2ysTGz26ZDvLyhKiWzflPipXFuL06TKNtTiM5jMkP1/ZSwco39eVKil/bttWiEePSrTLEuf2zjvKY9etK0Rmpvq6V19VrmveXAgDvmZG83srxAvRs6TNhg0bEBMTg3nz5ulsZ2dnhzFjxqBz585wcHDA+fPnsXTpUrRr1w4XLlyAp6dnodvm5OQgJydH9TwtLQ0AIJfLIZfLSxx7wbal2YexYm7F5+qqfCj3/dxKS0u0+Wk0ooPfwPntx9Eg9DvYHdwNycGDaoNyawJIeH7HCgDDlD8Kb28odu3C6FMNcXqSQH6+BBYWAitW5MPV9Wlerq7AypUSTJpUB73z9yAcndAdoVDMfgvyNWsAiQQ3bkhQR3EXvbEHvbAXATgKa4Uc+EMzt2zI8AhOeIyqeAwnNO/qCFtXR0ChQFZqLg7ty4M1cmCNXFgjFzLkwL9BDqyT4yCJigKGD4cvVqAxvsMVNP1vzJZAly55Gj1D0dHKaR18fYVqXcHvKjIyD+PGWUIoBKogFc6KZPw8Lhm9RQKcJQ8Be3uIZs2UA6AlEq37el5ZtSmpgtwUISHAiRMQtrbICw7W8ibSg4UFsGULLPr1g/TYMYgePZAXGmqQngpj+QyRfvstLA4fhrCzQ96WLZCkpMCib19ITp2C6NQJeXv2PP3D1VNJcpMcPQrL/6b0yPvhBwhLS/Xf8ddfw/LIEUguXkT+woVQfPRRsWIqK0XmFh0N6ZIlEF26QPTtq3/vZxkp1msuhHlMqnHz5k28/PLL8PPzw/Hjx4t9Wu3EiRPo2LEjxo0bhx9++KHQdnPmzMHcuXM1lm/cuBF2dnbFjpuoLNglJKDWvn3wDguD9X+DyQvkW1giz8IKwtoKwtoSCisrpHt64vKkSch2cgIAJCfbIC6uEtzcnsDZOVvrMQratEoOR7dlwZAqFLjXowcUVlZwPnMBjomxau0jUAc5XRsjrW0TZDk742qMNz5a3APZsFVr9/nnJ9CkyUMAwNWrzpg1S/N0z+efn0CzerHw3b4ddbaGwCovF/mQ4keMxyx8jkeoprYfAAgL88KKFc0ghAQSicD0t09gmONOuJ4/j0rx8RBJmVAkZ6IaHsICCo1jFsitVAn3qjTEnpgOOI+XcBHN0XViJgJ7xKi1e/54kyZdQrduD4rd5ulrbQ83t4wifh+abSRyObpMnQr7uDj8O2QIbr72WqG56cMiKwtt585FtZs3kVO5Mk7On490b+9S7bNYhIDX4cNwvHsX/w4ZglwDXYRTOTISAR98AAu5HJcmTsT9Hj0AAA6RkWg7Zw5sUlKQ4e6Ov+bORZaLS7nFIc3JQef33oN9XBzu9eiBKxMnam3nER6Ol775BvmWljj69ddI19EJYAg2ycl45bPPYP/fFegJLVrg6jvv4ImbW4XFkJmZiZEjRyI1NRUOBVNqFMIsiqX4+Hi88sorkMvl+Pvvv+Hu7l6i/bRt2xZJSUmI0HbL+f9o61ny9PREcnJykS+2LnK5HGFhYejWrRusrKxKvB9jxNwqUG6ucgyQTKYce2JtrXk3YT0UlZfkl19g+c47asvyLawQnt8Ru9Eb+6W98P7KOnjzzacfL9HRgK+vJRSKp/97tLAQuH37aY+QPm3iT9/H3x0+wRBsAQA8QlXMlnyOGf++BY9almr7cVPEoB92oj/+RGccgTUK/59kOuyRDGe4N3aClVs14OFDSK5dgyQ3V6PtE9jBooU/rF5pBdG5M6LrdESd5k7Fyq027qCvZDe+fGU3bB7FQvHOO1CMG4e1v1lj4kQLKBQSSKUCK1fmq72OALB2rURrG7lcjjvTpqHJTz9BuLrifth13I53KH1PV2oqLIKCID1/HsLVFXkHDwL16xf6WpaZnBxYTJ0K6Vrl1ZqKGjWgWL8eIiCg/I/9XByWbdtCcu0aFL16IX/7dvVekNu3YdmzJyQPHkB4eiJv3z7llWl6KO5niPSTT2CxZAmEuzvyLl8GHB21NxQCFgMHQrp3LxStWyP/6NGnN8qsIIXmFhsLy8BASCIiIGrUAB49giQ3F8LaGoqZM6H43/9UYxPLU1paGpydnfUqlkx+zFJKSopo1qyZcHJyEv/880+p9jVkyBBRtWrVYm3DMUtFY26mR6+8vv5aiPr1hRg7VnlVTlqa7rFWQjkmyMLi6dgobWOE9G3TRXpEfdxWkybKg1+8KO6OmSvOoYXGmKcnHnVF3vTp4szMmUIeGiq2BV8WHtIYYY1s7cfKyRGnV18SY/Cz+A6TxQm0Exmw09hvvtRCnERbMRezRAccFVbI0bhC8UiYXHTAUbEIH4h/0FDrmKxcn7pioGS7ABTar2AUuq9yzE1IEDmVKwsBiOOv/1jkeCx9x2xFRQlxbMdDkdOoqbKxu7sQEREabfS5ElLvKybj4oRo104IQCikUvHExeVpoHPmiKjIvIq78nLmTOWxXVyEiI/X3ubBA+XfA6C8Iu3yZb12XazPkPPnn/5x7NhRdPuoKCEcHJTtv/pKr3jKktbcYmOFqFdPGVOtWkLcvy/Ev/8K0b370zd0rVrK8ZflrDjf3yZdLGVlZYkOHToIOzs78ddff5V6fy+99JKoV69esbZhsVQ05mZ6yjOvogqq4rQJPygXj+Z/L4STk9biIx8ScRyviA+wSDSS3lAWFM/lVtSxni9OpMgTjaQ3RPJ3vwkxYYIQvr4ax82AndiHIPH4syVC/PqrECNGiHzHKmpt5LAQR9BJ2ea775RfxP+tC0dH8RLOap0W4vBh7WPfjxwRIm/6dCEAkVO3obCSyAufNkJLXtraCKFeUFWXJIpH7o2UT7y8hIiM1Gijq+jSt1387rMiy8VD2dDRUch37xa7/vhD5I8erQr2EDqLGogt9cD8Iou3w4eFQiIRAhBJa/7UvbOEBCGaNVPGWKWKEIV9LykUQqSkCBERIeSnTol9a9cW/bcmlysHbANCDBlSZF4qq1c/nQaiBBcxlYbG50hcnBANGjx9/9y797SxQiHE1q1CeHg8fUP26SPEnTvlFt8LUSzl5eWJfv36CUtLS7Fnz55C28XGxoobN26ovRETExM12u3Zs0cAEFOnTi1WHCyWisbcTI/J5ZWcLMSkScpvYFtbIfr3F0fH/CxqSBM0eqhKkluRvV2RkeLomDVio2SE6opBbY+sSk5ivWSUGIo/hJP0sfp+UlNF6uRPRCZsVO3X4zVRS3pfZ5FjjWzRUnpePFq0SjUf1/n5uwotqAroKroKOxYghLs0TuT6KK+mFDKZyOzeX7wuWS8qI1Vn0aVvcXb4nQ2q1+A6GojN8/9V+509/OZXkQ7lVWgJcBHdcKDE834VWbw9eiTSqyq/vH/EO0X2vh0+LET0tceqHjFRqZIQY8YI0b+/EO3bi9y6DUVO1epCoeXKUEWTJkLMnCkSN4SK8P1ZmjEvXKhsW7WqEPHx+vfQKRRCdO2q3LZjR+UVfRVE7W8tIUGIRv8V2p6ehRdBGRlCfPSREFZWT4u8uXOVV2eWsReiWJo2bZoAIPr27SvWr1+v8SgwevRoAUDce6aC9fX1FUOGDBGLFi0SP/zwgxg3bpywtLQUnp6eIr6wLtZCsFgqGnMzPSabV1qa2mXU2nqNSpqb3j1ih/JFfOhlIZYuFaJXLyFatVJ++J84IUReXpH7+X3RfbFeMuppD5SlTLl9aqqyKDx0SPw99Cvxq+R1cRlNRC7Uv3gTmjYVd+/kFFmY6FO8FFZQ/bU56mkvx3+PbFiLP9FXjMKvwhGPNeayLLI4y8sTaRM/VK3Yhd7CASkaU1kcPixEfdwQl+Cv6j2cj09E+EG52vGKKoT0yf9Jf+WknrfgKyohXa/eN6lUiHXfZzyddkHXw9ZWKNzcNJZnwkbsRw/x99CvhLh2TdkjZPNfEf3zz8U6fXr4sBCxJ+8+nebg+++1tinqfV2SNqq/tZgYIfz8lP9hcK4pYo9HFLmfuCM3nhZ5gPLUXRkXTC9EsRQQECAAFPoooK1Y+vTTT0WzZs2Eo6OjsLKyEl5eXmLixInFLpSEYLGkD+Zmesw1LyFMI7eoKCHO/nBOZLcJePplIZMV/qVbtaoQnTuLvOnTxZ5ff1XNIVXa8WE6CwqFQojLl0XqtFniOhqoNcqBlcjs2luIdeuUY3mema9L674ePxaiZ0/Vii/wsZAiT9UuLEyuMe+XDTLFSox/Wqy1aq/6pi5NIagq3jZuVBarsBCt8Xexet8sLISIisgWYsUKIebPF48WrBRDJZtFZxwS/rgkaiJKVJJmqk4L7/3lF5Hwza9iLcaIaLhrBlXQyxIYKKIeKIp9+lQqFeLkyGVP99WunRATJ4rjr/8g2kpOCTtklGpcW2FtcnNzxd5ffxWKxo2FAEQ03IUvbum/n9UKITZtEqJmTSGmTdPcoJReiGLJWLBYKhpzMz3mmpcQJpabQiHEn38+HRALCFG7tvJ2JPPmKQfBPnigupVJccdj6dNGr6JrtUL4S6+KOZitffC6RCKEi4tI9vAXB9BdrMVosVDykfhr+LdC/PabamB0vo2tGCH5XaMQeLZn6fmYhkv+EDk2ykHtolIlIVq0EElt+4qVGC9mYa54Cz+JIOwV/rgkTuxIUr1WOguq+/eFcHQUAhBzEFy6oquINgW/s9DQgjFmCtEI18R7WCr2oYfIs/6vR8nOTog7d0p8+tRSmi8yA/to3TgfEvEv6ootGCxSPpivvGAjPFzEH7gkfCT3hCMeCwnyteav84KD+Hjx2MdHCEDEooaoh5uFvo46fx/p6cpe4zL2wk5KSURkViQSoF8/oGdP4N9/AU/Pwi8V10LXrXX0baN+g2jtbce+LUGPoMaIiGgMB9+5QNp1YMsWYNs24MYNIC8PSEpCNSShO64oNxJQTlpaMHGphwekf/6JrhdbYPN4qN3ux8MDuHKlsJiGwTr7JWD4cOD8eeDCBTjjAiZoS2YAlDetrlEDHjVq4G6TGgi9UgNxogYSJG4YOL4GPKJqAJ9+qrwFz8svw/PNT2HxrmY8BerWVc7O8eythSwslK9Vcdr4+or/2khwHX64Dj8ss3gfkf9kwyPqFODuDtSujbrWRe9L262O8hRSnP74T3T65gZw+TLu77qMG39cRlNchhviUQ+3UQ+3gcVbVdu4Arj7388KSJCOykjJr4IqAY6AuyNgawvZE1tsUNgiC8888m2RO8cWlue3osq9e8ip6orOj4/gFp5ON6G69ZJH4TGr2nSy1/bbrFAsloiIjJ2VFdC4scEOX/yiqxEQHKx8KBTAw4dAXFzhD29vYOlSwNUVY1toFmfaJlpWP54vcPo0cPWqcuKo2Fhc2B2LC7tj4CZi4Y5YNKgcA9v0JOXOoqKAqCh4A1DNFiYArPjvAQB2dsD69XirrhW69y68WPTwUN4HcbyWAk+fNgW5FdrG1wbw7Vys4xVanNWTAh5+gJ8fLDqORO/NyjYuSERTXEZzyWUED7yMSjG3gZQU5D9ORW5iCmyRDSkEHJEGR6QpK6j/qigXAMO1vSHWKP/JdnRE8h8HcLtnA6CUBaUhsVgiIqLyI5UCLi7Kh7+/XpvoU5xpsLBQ3orlv9uxtBgHVI9WFjkuvoCtB5STtsbHaz7i4tSfp6UB332n/AbXIx69et/KqI0+7YpbwCXlV8cRi24Y/mM3VHrm5tcWADauAaaMy4G9IhXVpClY+FEK+ndKVfa8ZWUBWVn4+0gWdm7KgkxkoZIkCz07Z8OvdhbyLS1xskkTdOzcqFQFpTFgsURERGZJo8ixtga8vJSP8j5WObbRp13ZFnAyRERUh69vda1t2owDPBZr7kchlyNj794yjcdQWCwRERGZoYos4Cq6WKxoxb9pFBEREdELhMUSERERkQ4sloiIiIh0YLFEREREpAOLJSIiIiIdWCwRERER6cBiiYiIiEgHFktEREREOrBYIiIiItKBxRIRERGRDiyWiIiIiHRgsURERESkA4slIiIiIh0sDR2AqRNCAADS0tJKtR+5XI7MzEykpaXBysqqLEIzGszN9JhrXgBzM0XmmhfA3Ayp4Hu74HtcFxZLpZSeng4A8PT0NHAkREREVFzp6elwdHTU2UYi9CmpqFAKhQKxsbGoXLkyJBJJifeTlpYGT09PREVFwcHBoQwjNDzmZnrMNS+AuZkic80LYG6GJIRAeno63N3dIZXqHpXEnqVSkkql8PDwKLP9OTg4GOWbqiwwN9NjrnkBzM0UmWteAHMzlKJ6lApwgDcRERGRDiyWiIiIiHRgsWQkZDIZgoODIZPJDB1KmWNupsdc8wKYmyky17wA5mYqOMCbiIiISAf2LBERERHpwGKJiIiISAcWS0REREQ6sFgiIiIi0oHFkoHl5OTgf//7H9zd3WFra4uXX34ZYWFhhg6rzFy4cAH9+vWDk5MT7Ozs0LhxY3z33XeGDktvGRkZCA4ORlBQEJycnCCRSLBu3Tq1NgqFAuvWrUO/fv3g6emJSpUqoXHjxpg/fz6ys7MNE7ge9MmtwObNm9GmTRtUqVIF1apVQ0BAAPbs2VOxAevp7NmzmDx5Mvz8/FCpUiV4eXlh6NChuHXrVqHbyOVyNGrUCBKJBEuWLKnAaPX3zz//YMiQIahduzbs7Ozg7OyMjh07YteuXRptb9y4gaCgINjb28PJyQmvv/46kpKSDBC1foqTm0KhwMqVK9GsWTPY2tqiWrVq6NKlCy5fvmyAyIvviy++gEQiQePGjVXLMjMz8f3336N79+5wc3ND5cqV0bx5c6xcuRL5+fkGjLZ4tOUGKH9nP/zwA5o1awZ7e3u4urqiZ8+e+OuvvwwUafGxWDKwMWPGYOnSpXjttdfw7bffwsLCAr169cKJEycMHVqphYaGom3btkhMTMSsWbPw7bffok+fPoiOjjZ0aHpLTk7GvHnzcOPGDTRt2lRrm8zMTLz55ptISkrChAkT8M0336B169YIDg5Gz5499bpJoyHokxsALFu2DMOGDYOzszMWLlyIWbNmITU1FX369EFISEgFRqyfRYsWYdu2bejatSu+/fZbjBs3DseOHUOLFi1w7do1rdssW7YMDx48qOBIi+f+/ftIT0/H6NGj8e2332LWrFkAgH79+mHVqlWqdtHR0ejYsSMiIiKwYMECzJw5E3v27EG3bt2Qm5trqPB10jc3AHjrrbcwdepUvPTSS1i2bBlmz54NLy8vJCYmGiL0YomOjsaCBQtQqVIlteV3797FlClTIITA9OnTsWTJEvj4+GDSpEl46623DBRt8RSWGwB88MEHmDhxIpo0aYKlS5dixowZuHXrFgICAnDmzBkDRFsCggzm9OnTAoBYvHixallWVpaoU6eOaNu2rQEjK73U1FTh6uoqBg4cKPLz8w0dTollZ2eLuLg4IYQQZ8+eFQDE2rVr1drk5OSIkydPamw7d+5cAUCEhYVVRKjFpk9uQghRt25d0apVK6FQKFTLUlNThb29vejXr19Fhau3kydPipycHLVlt27dEjKZTLz22msa7RMSEoSjo6OYN2+ext+jscvLyxNNmzYV9evXVy2bOHGisLW1Fffv31ctCwsLEwDEjz/+aIgwS0Rbbps2bRIAREhIiAEjK7lhw4aJLl26iICAAOHn56danpSUJK5du6bR/s033xQAxO3btysyzBIpLDe5XC5sbW3F4MGD1drfvXtXABBTp06t6FBLhD1LBrR161ZYWFhg3LhxqmU2NjYYO3YsTp06haioKANGVzobN25EQkICvvjiC0ilUjx58gQKhcLQYRWbTCZDjRo1dLaxtrZGu3btNJYPHDgQgPKUiDHSJzdAeTPM6tWrq90o2sHBAfb29rC1tS3PEEukXbt2sLa2VltWt25d+Pn5af1dfPTRR6hfvz5GjRpVUSGWGQsLC3h6eiIlJUW1bNu2bejTpw+8vLxUywIDA1GvXj1s3rzZAFGWjLbcli5ditatW2PgwIFQKBR48uSJ4QIspmPHjmHr1q345ptvNNY5OzvDz89PY7mxf4YU0JWbXC5HVlYWXF1d1ZZXr14dUqnUKD9DtGGxZEAXL15EvXr1NG4w2Lp1awDApUuXDBBV2Th48CAcHBwQExOD+vXrw97eHg4ODpg4caJRj+MpS/Hx8QCUH4SmrFOnTti/fz+WLVuGyMhI3Lx5E++++y5SU1Mxbdo0Q4enFyEEEhISNH4XZ86cwS+//IJvvvlGrRg0Zk+ePEFycjLu3LmDr7/+Gvv27UPXrl0BADExMUhMTETLli01tmvdujUuXrxY0eEWi67c0tLScObMGbRq1QqffPIJHB0dYW9vj9q1axt9EZifn48pU6bg7bffRpMmTfTezhQ+Q4rKrWAs7rp167BhwwY8ePAAV65cwZgxY1C1alW1zgKjZuiurReZn5+f6NKli8byf/75RwAQP/zwgwGiKhv+/v7Czs5O2NnZiSlTpoht27aJKVOmCABi+PDhhg6vRHSdqtImMDBQODg4iMePH5drXGVBV24JCQmia9euAoDq4ezsLP7666+KD7SE1q9fLwCINWvWqJYpFArRunVrMWLECCGEEPfu3TOJ03Djx49X/R6kUqkYPHiwePTokRDi6e/x119/1djugw8+EABEdnZ2RYesN125XbhwQQAQ1apVE66urmLFihViw4YNonXr1kIikYh9+/YZOPrCLV++XDg6OorExEQhhNA4VaVNTk6OaNSokfDx8RFyubwiwiwRfXK7ffu2aNGihdpnSO3atcXNmzcNEXKJWFZwbUbPyMrK0nrPHBsbG9V6U5WRkYHMzExMmDBBdfXboEGDkJubix9//BHz5s1D3bp1DRxl+VmwYAEOHjyIFStWoEqVKoYOp1Ts7OxQv359eHh4oE+fPkhPT8fXX3+NQYMG4fjx4/D19TV0iDoV9IS1bdsWo0ePVi1ft24drl69iq1btxowuuJ77733MHjwYMTGxmLz5s3Iz89XDdwu+Mwo6nPFWO/VpSu3jIwMAMDDhw/x999/4+WXXwagHATu4+OD+fPnIygoyGCxF+bhw4eYPXs2Zs2aBRcXF723mzx5Mq5fv449e/bA0tI4v6r1za1y5crw8/ND27Zt0bVrV8THx2PhwoUYMGAAjh8/btQ9ZyqGrtZeZObcs+Tn5ycAiKNHj6otP3r0qAAgfvnlFwNFVnL69iz98ccfQiKRiLFjx1ZMYGVAV25BQUGiT58+assePnwonJycxNChQysowpKJi4sTtWvXFp6eniImJka1vOAChNmzZ6uWmUrP0vO6deumGoBv6j1Lz9OWm4+Pj0a7N998U1hZWRllD8yECROEr6+v2kUHRfUs/d///Z8AID7//POKCLHE9MlNLpeLxo0bi8mTJ6tte+vWLWFlZSU+/PDDCou3NDhmyYDc3NwQFxensbxgmbu7e0WHVGYKYtc2qA8AHj9+XOExVYSwsDC88cYb6N27N3744QdDh1Nqd+/exf79+9GvXz+15U5OTmjfvj1OnjxpoMiKlpqaip49eyIlJQX79+9X+3tasmQJcnNzMWzYMERGRiIyMlI1pcXjx48RGRlptJfZP2/w4ME4e/Ysbt26BTc3NwAo9HPFycnJaHuVtHk2t8I+UwDl54pcLje6Ad+3b9/GqlWrMHXqVMTGxqrea9nZ2ZDL5YiMjMSjR4/Utlm3bh3+97//YcKECfjss88MFHnR9M3t2LFjuHbtmsZnSN26ddGwYUOj/gx5FoslA2rWrBlu3bqFtLQ0teWnT59WrTdVL730EgDlgNNnxcbGAkCxuqNNxenTpzFw4EC0bNkSmzdvNtqu8+JISEgAAK0T48nlcuTl5VV0SHrJzs5G3759cevWLezevRuNGjVSW//gwQM8fvwYfn5+8PHxgY+PDzp06ABAeQrVx8cH169fN0ToxVZw6i01NRU1a9aEi4sLzp07p9HuzJkzJveZ8mxu7u7uqFGjhsZnCqD8XLGxsUHlypUrOkSdYmJioFAoMHXqVNX7zMfHB6dPn8atW7fg4+ODefPmqdr/+eefePvttzFo0CB8//33Boy8aPrmZqqfIRoM3bX1Ivv77781uv2zs7OFr6+vePnllw0YWekVDMYcOXKk2vIRI0YIS0tLtVMipkLXqarr16+LatWqCT8/P9WAVFNSWG6JiYlCKpWKTp06qc2zFBUVJezt7UVQUFAFR1q0vLw80a9fP2FpaSn27Nmjtc358+fF9u3b1R4//vijACDGjBkjtm/fLlJSUio4ct0SEhI0luXm5ooWLVoIW1tbkZ6eLoRQnhqxtbUVDx48ULU7ePCgACBWrlxZYfEWh765TZs2TQAQoaGhqnZJSUnCwcFB9OrVq8Li1VdSUpLG+2z79u3Cz89PeHl5ie3bt4srV64IIZRDFGxsbETnzp1N4lSpvrmdO3dOABCjR49W2/78+fNCKpWKCRMmGCaBYpIIYaTTC78ghg4diu3bt+P999+Hr68vfvnlF5w5cwaHDh1Cx44dDR1eqYwdOxY///wzhg4dioCAAISHh2PLli34+OOPsWDBAkOHp7fly5cjJSUFsbGxWLlyJQYNGoTmzZsDAKZMmQKpVAo/Pz/ExMRgwYIFqFmzptr2derUQdu2bQ0RepGKys3R0RHvvPMOfvrpJ3Tu3BmDBg1Ceno6VqxYgbi4OBw+fNjo3qfvvfcevv32W/Tt2xdDhw7VWF/YfEqRkZHw8fHB4sWLMXPmzPIOs9gGDhyItLQ0dOzYETVr1kR8fDw2bNiAmzdv4quvvsL06dMBAFFRUWjevDmqVKmCadOmISMjA4sXL4aHhwfOnj1rlKfh9M0tISEBzZs3R0ZGBqZPnw5HR0f88MMPiIqKwqlTp3TORG9MOnXqhOTkZNWM8vfv30fTpk2Rm5uLJUuWaEwn4+/vD39/f0OEWmzP5wYA3bt3R1hYGAYOHIju3bsjLi4Oy5YtQ25uLs6fP4/69esbMGI9Gbpae9FlZWWJmTNniho1agiZTCZatWol9u/fb+iwykRubq6YM2eO8Pb2FlZWVsLX11d8/fXXhg6r2Ly9vdUueX32ce/ePdXA4MIez/+PypgUlZsQygGay5YtE82aNRP29vbC3t5edO7cWRw+fNiwwRciICBA5++jMMY+wPv3338XgYGBwtXVVVhaWoqqVauKwMBA8eeff2q0vXbtmujevbuws7MTVapUEa+99pqIj483QNT6KU5ud+7cEQMHDhQODg7C1tZWdOnSRZw5c8YAUZfc84Ogjxw5ovM9GxwcbLhgi0nb4PXMzEwxb9480ahRI2FrayscHR1Fnz59xMWLFw0TZAmwZ4mIiIhIBw7wJiIiItKBxRIRERGRDiyWiIiIiHRgsURERESkA4slIiIiIh1YLBERERHpwGKJiIiISAcWS0REREQ6sFgiIiIi0oHFEhFROahVqxZq1apl6DCIqAywWCIioxUZGQmJRKLzwYKEiMqbpaEDICIqSp06dTBq1Cit66pUqVKxwRDRC4fFEhEZPV9fX8yZM8fQYRDRC4qn4YjIbEgkEnTq1AnR0dEYMWIEnJ2dYWdnh1deeQUHDx7Uuk1ycjLee+89+Pj4QCaToXr16hg6dCiuXbumtX1ubi6+/vprtGrVCpUrV4a9vT0aNWqE6dOn4/HjxxrtMzIyMG3aNLi7u0Mmk8Hf3x9bt27VaJeamorZs2ejUaNGsLe3h4ODA3x9fTF69Gjcv3+/dC8MEZWKRAghDB0EEZE2kZGR8PHxQY8ePbB///4i20skEvj7+yMlJQUuLi4IDAxEUlISNm3ahOzsbGzduhUDBgxQtU9KSkLbtm1x584ddOrUCW3atMG9e/ewdetWyGQyHDhwAO3bt1e1z8rKQrdu3XDy5EnUrVsXQUFBkMlkuH37NsLCwnDy5Ek0a9YMgHKAt1wuh7e3Nx4/fozAwEBkZmbijz/+QFZWFvbv34/u3bsDAIQQaNu2LU6fPo1XXnkFrVu3hlQqxf3793Hw4EFs2bIFgYGBZfraEpH+WCwRkdEqKJZ0jVlq06YNgoKCACiLJQAYOXIkfvvtN9XzK1euoFWrVnB0dMT9+/dha2sLAHjrrbewdu1afPzxx1iwYIFqn3v37kXv3r3h6+uLf//9F1KpshN+5syZ+Oqrr/D6669j7dq1sLCwUG2TmpoKCwsL2NvbA1AWS/fv30f//v2xefNmWFtbAwAOHTqEwMBAtQLw6tWr8Pf3x4ABA7B9+3a1/HJyciCXy1X7JSIDEERERurevXsCgM7HtGnTVO0BCAsLCxEZGamxr7FjxwoAYuvWrUIIIXJycoSNjY2oVq2aePLkiUb7bt26CQDi2LFjQggh5HK5qFy5snB0dBSPHj0qMnZvb28BQNy9e1frOicnJ9XzK1euCABixIgRRe6XiCoexywRkdHr0aMHhBBaH998841aWy8vL3h7e2vso0OHDgCAixcvAgBu3ryJ7OxstG7dGnZ2dhrtO3fuDAC4dOmSqn16ejpatWqFqlWr6hV3lSpV4OPjo7Hcw8MDKSkpqucNGzaEv78/fv/9d3Ts2BFLly7FhQsXoFAo9DoOEZUvFktEZFZcXV11Lk9NTQUApKWl6Wzv5uam1q5gu5o1a+odi6Ojo9bllpaWaoWQpaUlDh8+jMmTJyMiIgIzZszASy+9hBo1amDevHnIz8/X+5hEVPZYLBGRWUlISNC5vKCAcXBw0Nk+Pj5erV3BfE4xMTFlFuuzqlWrhmXLliEmJgbXr1/H8uXL4eTkhODgYPzf//1fuRyTiPTDYomIzMqDBw+0Xmp//PhxAEDz5s0BAA0aNICNjQ3Onj2LzMxMjfbh4eEAoLq6rX79+nBwcMDZs2e1ThFQViQSCRo2bIh3330XYWFhAICdO3eW2/GIqGgslojIrOTn5+OTTz6BeOZC3ytXrmD9+vVwcXFBr169AADW1tYYMWIEkpOT8eWXX6rtY//+/Thw4AB8fX3xyiuvAFCeKhs/fjxSU1Mxbdo0jVNjqampyMjIKFHMkZGRiIyM1Fhe0OtlY2NTov0SUdng1AFEZLT0mToAAD766CPY2NjonGcpKysL27Zt05hnqU2bNrh79y66dOmCl19+GZGRkdiyZQusra015lnKzs5G9+7dcfz4cdStWxc9e/aETCbD3bt3sX//fpw4cUJtnqWCHJ7XqVMnHD16VFXQ7dixA4MGDULr1q3RqFEj1KhRAzExMdixYwcyMjKwfft29OvXr9SvJxGVkKEuwyMiKoo+UwcAEI8fPxZCKKcOCAgIEFFRUWLYsGHCyclJ2NjYiLZt24rQ0FCtx0hKShJTp04V3t7ewsrKSjg7O4vBgweLq1evam2fnZ0tlixZIpo1ayZsbW2Fvb29aNSokZgxY4YqDiGU0wN4e3tr3UdAQIB49uM3KipKfPTRR6JNmzaievXqwtraWnh5eYlBgwaJU6dOlei1I6Kyw54lIjIbEokEAQEBqvFGRERlgWOWiIiIiHRgsURERESkA4slIiIiIh0sDR0AEVFZ4RBMIioP7FkiIiIi0oHFEhEREZEOLJaIiIiIdGCxRERERKQDiyUiIiIiHVgsEREREenAYomIiIhIBxZLRERERDr8PzMATZSj24tHAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optuna (https://optuna.org/): Is an open source hyperparameter optimization framework to automate hyperparameter search. The default algorithm is based on a Tree-structured Parzen Estimator (TPE). TPE is a Bayesian optimization algorithm that efficiently explores the search space by modeling the relationship between hyperparameters and the objective function."
      ],
      "metadata": {
        "id": "Xt8Aw_LC_rrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTi2sgMw2oZc",
        "outputId": "5cf43c3a-7550-47c5-979d-5234bd1d4c8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.2.0-py3-none-any.whl (390 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.6/390.6 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.11.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cmaes>=0.9.1 (from optuna)\n",
            "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.16)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.65.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.6.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
            "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.11.1 cmaes-0.9.1 colorlog-6.7.0 optuna-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Optuna trials to find the best number of units and dropout for our LSTM model\n",
        "import optuna\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "def objective(trial):\n",
        "    # Define the search space for the number of units and the dropout\n",
        "    n_units = trial.suggest_int('n_units', 10, 100)\n",
        "    dropout_rate = trial.suggest_uniform('dropout_rate', 0.0, 0.4)\n",
        "\n",
        "    # Build the LSTM model with the specified number of units and dropout rate as hyperparameter\n",
        "    model_optuna = keras.models.Sequential([\n",
        "        keras.layers.LSTM(n_units, return_sequences=True, input_shape=[None, 2]),\n",
        "        keras.layers.Dropout(dropout_rate),\n",
        "        keras.layers.TimeDistributed(keras.layers.Dense(1))\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model_optuna.compile(loss='mape', optimizer='adam')\n",
        "\n",
        "    # Train the model and return the metric to optimize (e.g., validation loss)\n",
        "    history_LSTM_optuna = model_optuna.fit(X_train, Y_train, epochs=100,\n",
        "                          validation_data=(X_val, Y_val), callbacks=[es])\n",
        "    val_loss = history_LSTM_optuna.history['val_loss'][-1]\n",
        "    return val_loss\n",
        "\n",
        "# Configure Optuna study: Tree-structured Parzen Estimator (TPE) algorithm\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "best_params = study.best_params\n",
        "best_value = study.best_value\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "print('Best Objective Value:', best_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXBgTicl2uBO",
        "outputId": "0ad26490-d695-42a4-d2ac-87418159e070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:32:21,635] A new study created in memory with name: no-name-404ef807-de96-41f4-b4a3-55b330dd1df1\n",
            "<ipython-input-33-f239d9d46070>:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.0, 0.4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 10ms/step - loss: 24.3677 - val_loss: 8.6809\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 9.6445 - val_loss: 5.3871\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.8256 - val_loss: 4.8526\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.1090 - val_loss: 4.3231\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 6.6708 - val_loss: 3.7418\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 6.3834 - val_loss: 3.8278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:32:54,204] Trial 0 finished with value: 3.8278005123138428 and parameters: {'n_units': 32, 'dropout_rate': 0.058309081699874414}. Best is trial 0 with value: 3.8278005123138428.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 13ms/step - loss: 16.3378 - val_loss: 6.9528\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.0232 - val_loss: 4.9346\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.6940 - val_loss: 4.0839\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 5.0322 - val_loss: 3.9944\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 4.5618 - val_loss: 4.1076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:33:21,307] Trial 1 finished with value: 4.107555389404297 and parameters: {'n_units': 65, 'dropout_rate': 0.015369676985375414}. Best is trial 0 with value: 3.8278005123138428.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 13ms/step - loss: 32.4070 - val_loss: 12.6259\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 15.1020 - val_loss: 8.5613\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 11.6605 - val_loss: 6.2543\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 10.5984 - val_loss: 5.4975\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 10.0655 - val_loss: 5.5453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:34:03,297] Trial 2 finished with value: 5.545263767242432 and parameters: {'n_units': 17, 'dropout_rate': 0.09631667718210486}. Best is trial 0 with value: 3.8278005123138428.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 9s 14ms/step - loss: 17.5109 - val_loss: 6.0258\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 8.9509 - val_loss: 4.7606\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.0489 - val_loss: 4.3437\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 7.5511 - val_loss: 3.6840\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 7.2583 - val_loss: 3.5255\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.0762 - val_loss: 3.6161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:34:35,672] Trial 3 finished with value: 3.616140365600586 and parameters: {'n_units': 98, 'dropout_rate': 0.24016050069340925}. Best is trial 3 with value: 3.616140365600586.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 9s 10ms/step - loss: 23.7165 - val_loss: 7.8276\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 12.8139 - val_loss: 5.9533\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 11.9044 - val_loss: 4.7816\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 11.4551 - val_loss: 4.8400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:34:58,701] Trial 4 finished with value: 4.8400068283081055 and parameters: {'n_units': 52, 'dropout_rate': 0.3663569420659671}. Best is trial 3 with value: 3.616140365600586.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 12ms/step - loss: 21.6442 - val_loss: 7.3038\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 11.4557 - val_loss: 5.7289\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 10.5420 - val_loss: 5.1517\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 9.9707 - val_loss: 4.3857\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 9.5996 - val_loss: 5.3352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:35:25,837] Trial 5 finished with value: 5.335230350494385 and parameters: {'n_units': 60, 'dropout_rate': 0.2979196744390014}. Best is trial 3 with value: 3.616140365600586.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 9s 14ms/step - loss: 16.2505 - val_loss: 5.4933\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 9s 20ms/step - loss: 7.4252 - val_loss: 4.4841\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 8s 17ms/step - loss: 6.3126 - val_loss: 3.7246\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.8542 - val_loss: 3.8758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:36:12,949] Trial 6 finished with value: 3.8757550716400146 and parameters: {'n_units': 90, 'dropout_rate': 0.09539022390773583}. Best is trial 3 with value: 3.616140365600586.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 9s 12ms/step - loss: 22.5084 - val_loss: 7.1167\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 12.3674 - val_loss: 6.0712\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 11.4777 - val_loss: 4.7285\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 11.0768 - val_loss: 4.4946\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 10.7904 - val_loss: 4.7152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:36:40,444] Trial 7 finished with value: 4.715219974517822 and parameters: {'n_units': 62, 'dropout_rate': 0.3777318639781096}. Best is trial 3 with value: 3.616140365600586.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 12ms/step - loss: 21.0787 - val_loss: 7.4752\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 9.9908 - val_loss: 6.2222\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 9.0132 - val_loss: 5.4546\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 8.5252 - val_loss: 4.5844\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.1932 - val_loss: 3.7559\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.9758 - val_loss: 4.5148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:37:11,662] Trial 8 finished with value: 4.514807224273682 and parameters: {'n_units': 51, 'dropout_rate': 0.180988156647594}. Best is trial 3 with value: 3.616140365600586.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 10ms/step - loss: 21.3701 - val_loss: 6.4499\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 11.3683 - val_loss: 5.2068\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 10.6125 - val_loss: 5.1519\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 10.1106 - val_loss: 4.3091\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 9.7614 - val_loss: 5.0264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:37:50,643] Trial 9 finished with value: 5.026352405548096 and parameters: {'n_units': 67, 'dropout_rate': 0.33267292790629976}. Best is trial 3 with value: 3.616140365600586.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 11ms/step - loss: 17.8600 - val_loss: 5.8244\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 9.0906 - val_loss: 5.2466\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 8.0689 - val_loss: 4.9593\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.7107 - val_loss: 3.9938\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 7.2860 - val_loss: 3.2893\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.0779 - val_loss: 3.4822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:38:39,753] Trial 10 finished with value: 3.4822003841400146 and parameters: {'n_units': 100, 'dropout_rate': 0.24921456900630065}. Best is trial 10 with value: 3.4822003841400146.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 13ms/step - loss: 18.8421 - val_loss: 7.7037\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 9.2634 - val_loss: 5.3243\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.3076 - val_loss: 4.3771\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 7.8207 - val_loss: 4.3346\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.4423 - val_loss: 3.3906\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.2170 - val_loss: 3.3271\n",
            "Epoch 7/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 7.0433 - val_loss: 3.3521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:39:16,753] Trial 11 finished with value: 3.3521134853363037 and parameters: {'n_units': 98, 'dropout_rate': 0.25946671217897116}. Best is trial 11 with value: 3.3521134853363037.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 10s 14ms/step - loss: 19.6266 - val_loss: 7.0491\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 9.6911 - val_loss: 5.0684\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.7738 - val_loss: 5.3994\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:39:40,990] Trial 12 finished with value: 5.399361610412598 and parameters: {'n_units': 83, 'dropout_rate': 0.2567087357868055}. Best is trial 11 with value: 3.3521134853363037.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 11ms/step - loss: 17.9662 - val_loss: 6.4598\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.8493 - val_loss: 5.0487\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 7.9640 - val_loss: 5.5906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:39:59,417] Trial 13 finished with value: 5.590575695037842 and parameters: {'n_units': 82, 'dropout_rate': 0.18930354695020593}. Best is trial 11 with value: 3.3521134853363037.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 11ms/step - loss: 18.4272 - val_loss: 5.9963\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 9.1747 - val_loss: 4.5382\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 8.2369 - val_loss: 4.8915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:40:17,822] Trial 14 finished with value: 4.891514778137207 and parameters: {'n_units': 99, 'dropout_rate': 0.26771925046313133}. Best is trial 11 with value: 3.3521134853363037.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 12ms/step - loss: 18.3461 - val_loss: 5.8970\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 9.1509 - val_loss: 5.0713\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.3180 - val_loss: 4.3943\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 7.8107 - val_loss: 4.5098\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:40:40,314] Trial 15 finished with value: 4.509838581085205 and parameters: {'n_units': 78, 'dropout_rate': 0.21435304024093615}. Best is trial 11 with value: 3.3521134853363037.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 11ms/step - loss: 18.8513 - val_loss: 6.6700\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 6s 13ms/step - loss: 9.6144 - val_loss: 5.3453\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 8.6652 - val_loss: 4.1286\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 8.2766 - val_loss: 4.2673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:41:04,797] Trial 16 finished with value: 4.267319679260254 and parameters: {'n_units': 100, 'dropout_rate': 0.3050834490404263}. Best is trial 11 with value: 3.3521134853363037.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 11ms/step - loss: 24.5537 - val_loss: 8.0992\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 6s 13ms/step - loss: 11.3560 - val_loss: 6.2300\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 9.9246 - val_loss: 5.2184\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 9.3505 - val_loss: 5.2646\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:41:46,662] Trial 17 finished with value: 5.264561653137207 and parameters: {'n_units': 38, 'dropout_rate': 0.1595040897902232}. Best is trial 11 with value: 3.3521134853363037.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 9s 14ms/step - loss: 20.7606 - val_loss: 6.2427\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 9.7607 - val_loss: 5.3090\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 8.8488 - val_loss: 5.1673\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 8.2590 - val_loss: 4.0816\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.8705 - val_loss: 4.1550\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:42:34,884] Trial 18 finished with value: 4.1549973487854 and parameters: {'n_units': 73, 'dropout_rate': 0.21678795601857243}. Best is trial 11 with value: 3.3521134853363037.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 11s 16ms/step - loss: 19.4528 - val_loss: 6.4431\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 10.1102 - val_loss: 5.6327\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 9.2501 - val_loss: 5.0558\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 8.7357 - val_loss: 5.2290\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:43:15,962] Trial 19 finished with value: 5.228975296020508 and parameters: {'n_units': 90, 'dropout_rate': 0.3008554220507559}. Best is trial 11 with value: 3.3521134853363037.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 9s 12ms/step - loss: 18.4512 - val_loss: 6.2166\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 8.4405 - val_loss: 4.8788\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 7.4133 - val_loss: 4.7035\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 6.8709 - val_loss: 3.7339\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 6.4800 - val_loss: 3.4339\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 6.2186 - val_loss: 3.5020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:44:06,590] Trial 20 finished with value: 3.501967668533325 and parameters: {'n_units': 89, 'dropout_rate': 0.15903650861851387}. Best is trial 11 with value: 3.3521134853363037.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 7s 10ms/step - loss: 16.6893 - val_loss: 6.3298\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 8.1526 - val_loss: 5.1088\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 7.2758 - val_loss: 4.2850\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 6.8352 - val_loss: 3.7896\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 6.4585 - val_loss: 3.8741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:44:33,202] Trial 21 finished with value: 3.8740522861480713 and parameters: {'n_units': 89, 'dropout_rate': 0.15049118398351663}. Best is trial 11 with value: 3.3521134853363037.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 11ms/step - loss: 18.2577 - val_loss: 6.5966\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 9.1174 - val_loss: 4.9248\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 8.1990 - val_loss: 4.2275\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.7928 - val_loss: 3.9176\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.4083 - val_loss: 3.6964\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 7.1488 - val_loss: 3.4200\n",
            "Epoch 7/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.0429 - val_loss: 3.1462\n",
            "Epoch 8/100\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 6.8708 - val_loss: 3.1920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:45:14,610] Trial 22 finished with value: 3.1919944286346436 and parameters: {'n_units': 91, 'dropout_rate': 0.241076671120839}. Best is trial 22 with value: 3.1919944286346436.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 10ms/step - loss: 18.3246 - val_loss: 5.8039\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.9957 - val_loss: 5.2543\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 8.1163 - val_loss: 4.5092\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.6715 - val_loss: 4.7109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:45:37,037] Trial 23 finished with value: 4.710912227630615 and parameters: {'n_units': 95, 'dropout_rate': 0.24946463477806732}. Best is trial 22 with value: 3.1919944286346436.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 12ms/step - loss: 21.4510 - val_loss: 7.7078\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 10.7240 - val_loss: 5.9759\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 9.6748 - val_loss: 4.8930\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 9.1179 - val_loss: 4.6497\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 8.7826 - val_loss: 4.0816\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.5910 - val_loss: 3.8871\n",
            "Epoch 7/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 8.3942 - val_loss: 3.5764\n",
            "Epoch 8/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 8.2467 - val_loss: 3.4883\n",
            "Epoch 9/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 8.0938 - val_loss: 3.8714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:46:23,762] Trial 24 finished with value: 3.8713772296905518 and parameters: {'n_units': 74, 'dropout_rate': 0.2794366988086325}. Best is trial 22 with value: 3.1919944286346436.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 9s 10ms/step - loss: 19.0000 - val_loss: 5.9205\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 9.2011 - val_loss: 4.8129\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 8.2456 - val_loss: 4.5878\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.7591 - val_loss: 4.2535\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.4017 - val_loss: 3.9450\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 7.2064 - val_loss: 3.2732\n",
            "Epoch 7/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.0309 - val_loss: 3.4802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:47:01,512] Trial 25 finished with value: 3.4802496433258057 and parameters: {'n_units': 84, 'dropout_rate': 0.21833421678443032}. Best is trial 22 with value: 3.1919944286346436.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 13ms/step - loss: 18.5126 - val_loss: 6.2684\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 9.5954 - val_loss: 5.3355\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.6321 - val_loss: 4.5931\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 8.1696 - val_loss: 4.0883\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.7681 - val_loss: 4.4734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:47:28,719] Trial 26 finished with value: 4.47335147857666 and parameters: {'n_units': 81, 'dropout_rate': 0.2346970330751359}. Best is trial 22 with value: 3.1919944286346436.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 12ms/step - loss: 18.4251 - val_loss: 6.8544\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 9.3907 - val_loss: 5.3516\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.5294 - val_loss: 4.7822\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 7.9544 - val_loss: 3.7457\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.6695 - val_loss: 3.8195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:47:55,696] Trial 27 finished with value: 3.8195276260375977 and parameters: {'n_units': 72, 'dropout_rate': 0.20979210335155044}. Best is trial 22 with value: 3.1919944286346436.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 7s 11ms/step - loss: 27.9865 - val_loss: 7.3506\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 13.3606 - val_loss: 6.0735\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 12.3282 - val_loss: 5.3710\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 11.7842 - val_loss: 4.9760\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 11.4729 - val_loss: 4.9662\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 11.2480 - val_loss: 4.8369\n",
            "Epoch 7/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 11.0691 - val_loss: 4.6706\n",
            "Epoch 8/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 10.9384 - val_loss: 3.8246\n",
            "Epoch 9/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 10.7969 - val_loss: 4.2353\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:48:40,284] Trial 28 finished with value: 4.235311985015869 and parameters: {'n_units': 44, 'dropout_rate': 0.3298603374405167}. Best is trial 22 with value: 3.1919944286346436.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 12ms/step - loss: 37.5124 - val_loss: 13.1846\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 18.1374 - val_loss: 8.2878\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 15.8188 - val_loss: 7.2667\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 14.9658 - val_loss: 6.4023\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 14.6185 - val_loss: 6.4903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:49:06,528] Trial 29 finished with value: 6.490286827087402 and parameters: {'n_units': 19, 'dropout_rate': 0.2729024029502266}. Best is trial 22 with value: 3.1919944286346436.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 9s 12ms/step - loss: 18.7458 - val_loss: 5.7486\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 9.1260 - val_loss: 4.9064\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.2614 - val_loss: 4.8350\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 7.7550 - val_loss: 3.9044\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 7.3371 - val_loss: 3.6409\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.0787 - val_loss: 3.3351\n",
            "Epoch 7/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 6.9486 - val_loss: 3.2762\n",
            "Epoch 8/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 6.7550 - val_loss: 3.1396\n",
            "Epoch 9/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 6.6039 - val_loss: 2.8280\n",
            "Epoch 10/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 6.5245 - val_loss: 2.4992\n",
            "Epoch 11/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 6.4391 - val_loss: 2.8309\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:50:04,280] Trial 30 finished with value: 2.8309476375579834 and parameters: {'n_units': 85, 'dropout_rate': 0.22534758805513347}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 13ms/step - loss: 18.9593 - val_loss: 6.7916\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 9.0687 - val_loss: 4.8062\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.1482 - val_loss: 4.4984\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 7.7008 - val_loss: 4.0859\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.3344 - val_loss: 3.8419\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.1103 - val_loss: 4.6232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:50:35,727] Trial 31 finished with value: 4.623234272003174 and parameters: {'n_units': 86, 'dropout_rate': 0.22642890773997454}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 12ms/step - loss: 18.4960 - val_loss: 5.7792\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.4617 - val_loss: 5.8427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:50:48,724] Trial 32 finished with value: 5.842678070068359 and parameters: {'n_units': 93, 'dropout_rate': 0.18547061168675222}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 12ms/step - loss: 19.1972 - val_loss: 7.0235\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 9.2883 - val_loss: 5.2450\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.3782 - val_loss: 4.3624\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 7.8845 - val_loss: 3.8538\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.5262 - val_loss: 3.5450\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.2698 - val_loss: 3.4682\n",
            "Epoch 7/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 7.1263 - val_loss: 3.0398\n",
            "Epoch 8/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 6.9952 - val_loss: 3.0688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:51:39,676] Trial 33 finished with value: 3.068833351135254 and parameters: {'n_units': 77, 'dropout_rate': 0.22581219439730196}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 7s 11ms/step - loss: 20.0165 - val_loss: 6.1679\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 9.7546 - val_loss: 5.7486\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.9412 - val_loss: 4.7233\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 8.3847 - val_loss: 4.0839\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 8.1168 - val_loss: 3.9326\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.9001 - val_loss: 4.1774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:52:11,264] Trial 34 finished with value: 4.177361488342285 and parameters: {'n_units': 78, 'dropout_rate': 0.2516906854106154}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 9s 13ms/step - loss: 20.2975 - val_loss: 7.2086\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 10.2033 - val_loss: 5.5718\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 9.1767 - val_loss: 4.6603\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 8.6821 - val_loss: 3.9739\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.2531 - val_loss: 3.8811\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.0353 - val_loss: 4.1367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:52:54,871] Trial 35 finished with value: 4.136663913726807 and parameters: {'n_units': 68, 'dropout_rate': 0.23571291522553903}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 12ms/step - loss: 17.4510 - val_loss: 6.1411\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 8.5415 - val_loss: 5.1307\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 7.5391 - val_loss: 4.3136\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 7.0729 - val_loss: 4.0762\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 6.7434 - val_loss: 3.8837\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 6.5020 - val_loss: 3.3463\n",
            "Epoch 7/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 6.3995 - val_loss: 3.1356\n",
            "Epoch 8/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 6.1770 - val_loss: 3.3595\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:53:48,467] Trial 36 finished with value: 3.3594512939453125 and parameters: {'n_units': 96, 'dropout_rate': 0.19743910473886184}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 12ms/step - loss: 65.6124 - val_loss: 16.4401\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 26.4506 - val_loss: 13.2589\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 21.7310 - val_loss: 10.5961\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 19.7408 - val_loss: 8.7949\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 18.7666 - val_loss: 8.3471\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 18.2393 - val_loss: 7.4148\n",
            "Epoch 7/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 17.9415 - val_loss: 7.4683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:54:24,610] Trial 37 finished with value: 7.46831750869751 and parameters: {'n_units': 11, 'dropout_rate': 0.2855484304380929}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 11ms/step - loss: 18.9768 - val_loss: 6.3886\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 9.6346 - val_loss: 6.1394\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 8.6259 - val_loss: 4.4726\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 8.0689 - val_loss: 4.0172\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.6788 - val_loss: 3.4416\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 7.4361 - val_loss: 3.3769\n",
            "Epoch 7/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.2039 - val_loss: 3.0902\n",
            "Epoch 8/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.0884 - val_loss: 3.2201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:55:12,602] Trial 38 finished with value: 3.2200536727905273 and parameters: {'n_units': 93, 'dropout_rate': 0.2586486117513251}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 10ms/step - loss: 21.1509 - val_loss: 7.4416\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 10.7970 - val_loss: 5.2914\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 9.8193 - val_loss: 4.7745\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 9.2860 - val_loss: 4.2981\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 9.0247 - val_loss: 4.4728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:55:41,299] Trial 39 finished with value: 4.472795486450195 and parameters: {'n_units': 55, 'dropout_rate': 0.23825206746510574}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 11ms/step - loss: 22.6907 - val_loss: 7.0920\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 13.0075 - val_loss: 6.0519\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 12.1139 - val_loss: 5.5499\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 11.5839 - val_loss: 4.9881\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 11.2294 - val_loss: 4.8243\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 11.0596 - val_loss: 4.3079\n",
            "Epoch 7/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 10.8994 - val_loss: 4.0558\n",
            "Epoch 8/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 10.7430 - val_loss: 4.4795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:56:21,165] Trial 40 finished with value: 4.479501247406006 and parameters: {'n_units': 60, 'dropout_rate': 0.3987748114259373}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 13ms/step - loss: 18.8427 - val_loss: 6.2147\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 9.4650 - val_loss: 4.6654\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 8.4733 - val_loss: 4.8254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:56:39,338] Trial 41 finished with value: 4.825417518615723 and parameters: {'n_units': 92, 'dropout_rate': 0.26449194701957873}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 9s 12ms/step - loss: 18.6973 - val_loss: 5.7558\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 9.1901 - val_loss: 5.2521\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 8.2469 - val_loss: 4.9813\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.7723 - val_loss: 3.8597\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.4710 - val_loss: 3.9101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:57:07,152] Trial 42 finished with value: 3.9101083278656006 and parameters: {'n_units': 86, 'dropout_rate': 0.23281292737918668}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 7s 10ms/step - loss: 19.9580 - val_loss: 7.4394\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 9.6199 - val_loss: 5.2912\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 8.6582 - val_loss: 4.6701\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.1553 - val_loss: 3.7544\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 7.8472 - val_loss: 4.7188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:57:49,264] Trial 43 finished with value: 4.718760013580322 and parameters: {'n_units': 95, 'dropout_rate': 0.2858777162811127}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 7s 10ms/step - loss: 20.5502 - val_loss: 6.2115\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 10.0861 - val_loss: 6.1305\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 9.1208 - val_loss: 4.9808\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.6591 - val_loss: 4.4365\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 8.3663 - val_loss: 3.9892\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 8.1421 - val_loss: 4.0317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:58:20,994] Trial 44 finished with value: 4.0317182540893555 and parameters: {'n_units': 77, 'dropout_rate': 0.26162509311514065}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 7s 11ms/step - loss: 17.6256 - val_loss: 5.9741\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 8.6301 - val_loss: 4.9209\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.6634 - val_loss: 4.3032\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.2004 - val_loss: 4.2551\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 6.8958 - val_loss: 3.8086\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 6.6838 - val_loss: 3.4199\n",
            "Epoch 7/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 6.5300 - val_loss: 3.4742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:58:56,582] Trial 45 finished with value: 3.4741830825805664 and parameters: {'n_units': 87, 'dropout_rate': 0.19449143896673216}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 9s 11ms/step - loss: 18.5141 - val_loss: 6.6020\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 9.1632 - val_loss: 5.2399\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 8.2855 - val_loss: 5.1068\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.7502 - val_loss: 4.3474\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.4551 - val_loss: 3.9801\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 7.2232 - val_loss: 3.8938\n",
            "Epoch 7/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.0469 - val_loss: 3.2115\n",
            "Epoch 8/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 6.9198 - val_loss: 3.6776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 19:59:38,565] Trial 46 finished with value: 3.6776270866394043 and parameters: {'n_units': 94, 'dropout_rate': 0.2444395984418931}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 11ms/step - loss: 18.4861 - val_loss: 6.0827\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.9308 - val_loss: 4.9012\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 8.0896 - val_loss: 4.5594\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.6578 - val_loss: 4.0168\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.3109 - val_loss: 4.3037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:00:05,426] Trial 47 finished with value: 4.303666114807129 and parameters: {'n_units': 82, 'dropout_rate': 0.2071414167876296}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 7s 11ms/step - loss: 19.0564 - val_loss: 6.2647\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 9.8019 - val_loss: 5.3588\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 8.8669 - val_loss: 4.4633\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.4262 - val_loss: 4.0210\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 8.1820 - val_loss: 3.6242\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 7.9628 - val_loss: 3.8277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:00:54,189] Trial 48 finished with value: 3.8277156352996826 and parameters: {'n_units': 100, 'dropout_rate': 0.31808889958623876}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 7s 10ms/step - loss: 19.9413 - val_loss: 6.0237\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 9.7876 - val_loss: 5.1949\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 8.9162 - val_loss: 4.3724\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.3876 - val_loss: 4.0104\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 8.0858 - val_loss: 3.6162\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.8466 - val_loss: 3.9239\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:01:36,374] Trial 49 finished with value: 3.923877239227295 and parameters: {'n_units': 91, 'dropout_rate': 0.29010826564859826}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 7s 11ms/step - loss: 22.0551 - val_loss: 7.1694\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 10.8522 - val_loss: 4.8876\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 9.8900 - val_loss: 4.5914\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 9.3847 - val_loss: 4.2638\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 9.0560 - val_loss: 3.9932\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.8412 - val_loss: 3.6386\n",
            "Epoch 7/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 8.6639 - val_loss: 3.5205\n",
            "Epoch 8/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 8.4524 - val_loss: 3.2292\n",
            "Epoch 9/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.3928 - val_loss: 3.3141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:02:20,946] Trial 50 finished with value: 3.314143180847168 and parameters: {'n_units': 70, 'dropout_rate': 0.30450605546788345}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 12ms/step - loss: 23.4077 - val_loss: 8.3146\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 10.9149 - val_loss: 5.4047\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 10.0284 - val_loss: 4.9506\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 9.4808 - val_loss: 4.5623\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 9.0835 - val_loss: 4.5576\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.8815 - val_loss: 4.1849\n",
            "Epoch 7/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 8.6908 - val_loss: 3.7061\n",
            "Epoch 8/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 8.5248 - val_loss: 3.6111\n",
            "Epoch 9/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.3458 - val_loss: 3.2962\n",
            "Epoch 10/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 8.2882 - val_loss: 3.6479\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:03:10,315] Trial 51 finished with value: 3.6479153633117676 and parameters: {'n_units': 64, 'dropout_rate': 0.26782092465757695}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 10ms/step - loss: 19.9075 - val_loss: 7.8627\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 10.0692 - val_loss: 4.9258\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 6s 13ms/step - loss: 9.1921 - val_loss: 4.8135\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.7262 - val_loss: 4.5391\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.3953 - val_loss: 4.5073\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 8.1749 - val_loss: 3.7006\n",
            "Epoch 7/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.0600 - val_loss: 3.5505\n",
            "Epoch 8/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.9281 - val_loss: 3.9524\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:04:26,606] Trial 52 finished with value: 3.9524381160736084 and parameters: {'n_units': 69, 'dropout_rate': 0.25228085426224406}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 7s 10ms/step - loss: 20.4078 - val_loss: 7.5100\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 10.5553 - val_loss: 5.6600\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 9.6708 - val_loss: 5.5815\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 9.1592 - val_loss: 4.1604\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 8.7801 - val_loss: 3.9754\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 8.4825 - val_loss: 4.0520\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:05:00,996] Trial 53 finished with value: 4.052010536193848 and parameters: {'n_units': 79, 'dropout_rate': 0.2948500651445641}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 7s 10ms/step - loss: 19.1047 - val_loss: 6.5911\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 9.8513 - val_loss: 5.5960\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 9.0051 - val_loss: 4.6686\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.5218 - val_loss: 4.4146\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 8.1715 - val_loss: 3.7258\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.0032 - val_loss: 4.0262\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:05:43,956] Trial 54 finished with value: 4.02615213394165 and parameters: {'n_units': 97, 'dropout_rate': 0.3099787636132996}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 7s 12ms/step - loss: 20.5369 - val_loss: 6.9773\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 11.2315 - val_loss: 6.1741\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 10.3699 - val_loss: 5.5073\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 9.9652 - val_loss: 4.3251\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 9.5668 - val_loss: 4.0148\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 9.3524 - val_loss: 4.3815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:06:14,617] Trial 55 finished with value: 4.381526947021484 and parameters: {'n_units': 74, 'dropout_rate': 0.3416893209872496}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 13ms/step - loss: 18.2822 - val_loss: 5.7414\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 9.0485 - val_loss: 5.7137\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.2078 - val_loss: 4.3862\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 7.6904 - val_loss: 4.0879\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.3760 - val_loss: 3.6173\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 7.1568 - val_loss: 3.7465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:06:59,847] Trial 56 finished with value: 3.746467351913452 and parameters: {'n_units': 88, 'dropout_rate': 0.22606939456609287}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 9s 11ms/step - loss: 19.1539 - val_loss: 7.6464\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 9.9480 - val_loss: 5.7361\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 9.0325 - val_loss: 4.1495\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.4826 - val_loss: 4.3799\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:07:32,883] Trial 57 finished with value: 4.379886627197266 and parameters: {'n_units': 84, 'dropout_rate': 0.27682189109923144}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 7s 11ms/step - loss: 19.1936 - val_loss: 6.4170\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 9.7117 - val_loss: 4.7941\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.8344 - val_loss: 4.3734\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 8.2619 - val_loss: 4.1080\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.9888 - val_loss: 3.7628\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.7710 - val_loss: 4.1459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:08:03,857] Trial 58 finished with value: 4.145920276641846 and parameters: {'n_units': 80, 'dropout_rate': 0.2580357429514057}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 13ms/step - loss: 24.2160 - val_loss: 8.7351\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 10.3711 - val_loss: 5.9475\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.9965 - val_loss: 4.6768\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 8.4087 - val_loss: 4.1739\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.0185 - val_loss: 3.9463\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.7543 - val_loss: 4.0556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:08:34,769] Trial 59 finished with value: 4.055584907531738 and parameters: {'n_units': 58, 'dropout_rate': 0.1718456586497117}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 11ms/step - loss: 19.7778 - val_loss: 5.9980\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 9.4117 - val_loss: 4.9737\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 8.5533 - val_loss: 4.6399\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 8.1062 - val_loss: 4.1319\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.8525 - val_loss: 3.9123\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 7.6361 - val_loss: 3.7973\n",
            "Epoch 7/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.5080 - val_loss: 3.4707\n",
            "Epoch 8/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.3153 - val_loss: 3.5759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:09:27,186] Trial 60 finished with value: 3.575918197631836 and parameters: {'n_units': 70, 'dropout_rate': 0.21834544798298383}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 13ms/step - loss: 18.4916 - val_loss: 7.1257\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.6057 - val_loss: 5.0401\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.6345 - val_loss: 4.1515\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 7.1691 - val_loss: 4.3906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:09:49,858] Trial 61 finished with value: 4.390635967254639 and parameters: {'n_units': 97, 'dropout_rate': 0.20020902766377807}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 10s 15ms/step - loss: 17.9409 - val_loss: 7.0020\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 8.7007 - val_loss: 5.6702\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 7.7743 - val_loss: 3.9244\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.3148 - val_loss: 4.7535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:10:34,476] Trial 62 finished with value: 4.753495693206787 and parameters: {'n_units': 91, 'dropout_rate': 0.20601729731028665}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 7s 11ms/step - loss: 18.2169 - val_loss: 5.6887\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 9.0265 - val_loss: 5.3934\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 8.0657 - val_loss: 4.4243\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.6549 - val_loss: 4.3738\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 7.3269 - val_loss: 3.8291\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.1750 - val_loss: 4.3803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:11:25,293] Trial 63 finished with value: 4.380268096923828 and parameters: {'n_units': 97, 'dropout_rate': 0.24010322040507692}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 12ms/step - loss: 18.5548 - val_loss: 5.8796\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 9.5793 - val_loss: 4.6844\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.7343 - val_loss: 4.9405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:11:53,719] Trial 64 finished with value: 4.940542221069336 and parameters: {'n_units': 76, 'dropout_rate': 0.22332692247176528}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 13ms/step - loss: 18.5109 - val_loss: 6.6172\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 9.5943 - val_loss: 5.0779\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.7105 - val_loss: 4.3149\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 8.1863 - val_loss: 3.6961\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.9136 - val_loss: 3.4307\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 7.7142 - val_loss: 3.5180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:12:26,397] Trial 65 finished with value: 3.518040895462036 and parameters: {'n_units': 84, 'dropout_rate': 0.2695586874844131}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 11ms/step - loss: 18.0728 - val_loss: 6.3566\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 8.4871 - val_loss: 5.0280\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 6s 13ms/step - loss: 7.5014 - val_loss: 4.7072\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.0172 - val_loss: 3.5794\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 6.7498 - val_loss: 4.1492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:12:56,138] Trial 66 finished with value: 4.149226188659668 and parameters: {'n_units': 94, 'dropout_rate': 0.19624718001458666}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 11ms/step - loss: 18.2368 - val_loss: 6.9079\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 9.5541 - val_loss: 5.1458\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 8.7287 - val_loss: 4.6387\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 8.2596 - val_loss: 4.2027\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.9245 - val_loss: 3.5507\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 7.6969 - val_loss: 3.3691\n",
            "Epoch 7/100\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 7.5463 - val_loss: 3.1900\n",
            "Epoch 8/100\n",
            "466/466 [==============================] - 6s 13ms/step - loss: 7.4198 - val_loss: 3.3609\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:13:39,423] Trial 67 finished with value: 3.3608739376068115 and parameters: {'n_units': 89, 'dropout_rate': 0.2773007525166359}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 9s 11ms/step - loss: 18.0522 - val_loss: 5.6635\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 9.1539 - val_loss: 5.4481\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 8.2283 - val_loss: 4.0315\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.7621 - val_loss: 3.7953\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 7.4300 - val_loss: 3.6450\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 7.1931 - val_loss: 4.2357\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:14:14,513] Trial 68 finished with value: 4.23568868637085 and parameters: {'n_units': 97, 'dropout_rate': 0.2501420703362685}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 7s 11ms/step - loss: 18.0856 - val_loss: 6.5674\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 8.4799 - val_loss: 4.8282\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.6656 - val_loss: 4.6462\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.2109 - val_loss: 3.7700\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 6.8708 - val_loss: 3.6890\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 6.6807 - val_loss: 3.7896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:14:46,287] Trial 69 finished with value: 3.789607048034668 and parameters: {'n_units': 86, 'dropout_rate': 0.18613302370458665}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 13ms/step - loss: 28.4942 - val_loss: 9.9496\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 14.3778 - val_loss: 6.4993\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 12.6575 - val_loss: 5.8015\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 12.0633 - val_loss: 5.5305\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 11.7196 - val_loss: 4.8222\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 11.5070 - val_loss: 5.0542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:15:18,056] Trial 70 finished with value: 5.05421257019043 and parameters: {'n_units': 25, 'dropout_rate': 0.22179721520237416}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 12ms/step - loss: 18.0609 - val_loss: 6.5170\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 9.4981 - val_loss: 5.0513\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 8.5877 - val_loss: 4.1442\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 8.1615 - val_loss: 4.0423\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.8367 - val_loss: 3.7608\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 7.6173 - val_loss: 3.6834\n",
            "Epoch 7/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 7.4328 - val_loss: 3.2820\n",
            "Epoch 8/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.3415 - val_loss: 3.0105\n",
            "Epoch 9/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 7.1516 - val_loss: 2.8981\n",
            "Epoch 10/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 7.0760 - val_loss: 2.9762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:16:21,528] Trial 71 finished with value: 2.9761579036712646 and parameters: {'n_units': 90, 'dropout_rate': 0.27706862018181705}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 10s 13ms/step - loss: 19.2492 - val_loss: 6.8173\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 9.8258 - val_loss: 4.9267\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 8.8764 - val_loss: 4.4894\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 8.3915 - val_loss: 3.9934\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.1120 - val_loss: 3.4377\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 7.9479 - val_loss: 3.7318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:17:28,117] Trial 72 finished with value: 3.731835126876831 and parameters: {'n_units': 92, 'dropout_rate': 0.30065313165187346}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 11ms/step - loss: 17.4901 - val_loss: 7.2328\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 6s 13ms/step - loss: 9.0699 - val_loss: 5.2530\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 8.2523 - val_loss: 4.1040\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.7746 - val_loss: 3.8533\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 7.4866 - val_loss: 3.4453\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.2629 - val_loss: 3.1514\n",
            "Epoch 7/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.1642 - val_loss: 3.2009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:18:07,414] Trial 73 finished with value: 3.2008719444274902 and parameters: {'n_units': 95, 'dropout_rate': 0.25816650885795844}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 11ms/step - loss: 22.8082 - val_loss: 7.4924\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 11.5856 - val_loss: 5.8717\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 10.6248 - val_loss: 5.1073\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 10.1523 - val_loss: 4.3923\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 9.8127 - val_loss: 4.6442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:18:35,306] Trial 74 finished with value: 4.644157886505127 and parameters: {'n_units': 47, 'dropout_rate': 0.2579451320007779}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 11ms/step - loss: 19.5394 - val_loss: 5.8921\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 10.0341 - val_loss: 5.0711\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 9.1384 - val_loss: 4.2767\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.6485 - val_loss: 4.3441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:18:58,458] Trial 75 finished with value: 4.344069957733154 and parameters: {'n_units': 81, 'dropout_rate': 0.2828362691090136}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 13ms/step - loss: 18.3972 - val_loss: 7.0778\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 9.0375 - val_loss: 5.4312\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 8.0439 - val_loss: 4.6503\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 7.6498 - val_loss: 4.1278\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.2648 - val_loss: 3.5396\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.0575 - val_loss: 3.6652\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:19:31,197] Trial 76 finished with value: 3.6651690006256104 and parameters: {'n_units': 100, 'dropout_rate': 0.24668910257419197}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 14ms/step - loss: 19.0106 - val_loss: 6.2611\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 9.1500 - val_loss: 5.1300\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 8.1980 - val_loss: 4.7487\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 7.7069 - val_loss: 4.1967\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.4581 - val_loss: 3.5679\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 7.1575 - val_loss: 3.3996\n",
            "Epoch 7/100\n",
            "466/466 [==============================] - 7s 15ms/step - loss: 7.0378 - val_loss: 3.1376\n",
            "Epoch 8/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 6.8333 - val_loss: 3.0269\n",
            "Epoch 9/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 6.6613 - val_loss: 3.0460\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:20:31,130] Trial 77 finished with value: 3.0460140705108643 and parameters: {'n_units': 89, 'dropout_rate': 0.23237660056676923}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 9s 13ms/step - loss: 19.5582 - val_loss: 6.1630\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 9.3702 - val_loss: 5.1133\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 6s 13ms/step - loss: 8.5610 - val_loss: 5.3177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:20:50,926] Trial 78 finished with value: 5.317654132843018 and parameters: {'n_units': 84, 'dropout_rate': 0.2352919693143796}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 7s 11ms/step - loss: 19.9227 - val_loss: 6.3789\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 9.6896 - val_loss: 5.4043\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 8.6777 - val_loss: 4.1117\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 8.2144 - val_loss: 4.0699\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 6s 13ms/step - loss: 7.9301 - val_loss: 3.8431\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.6763 - val_loss: 4.4667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:21:23,991] Trial 79 finished with value: 4.466650009155273 and parameters: {'n_units': 88, 'dropout_rate': 0.26772511750318173}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 9s 14ms/step - loss: 18.8875 - val_loss: 5.9247\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 9.4564 - val_loss: 4.7783\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 8.6280 - val_loss: 4.5556\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 6s 13ms/step - loss: 8.1838 - val_loss: 4.5799\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:21:47,874] Trial 80 finished with value: 4.5799479484558105 and parameters: {'n_units': 76, 'dropout_rate': 0.2300682983180208}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 7s 11ms/step - loss: 18.4012 - val_loss: 6.4141\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 9.3449 - val_loss: 4.7591\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 8.4155 - val_loss: 4.2830\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.9666 - val_loss: 4.5443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:22:10,272] Trial 81 finished with value: 4.544332027435303 and parameters: {'n_units': 93, 'dropout_rate': 0.26012041991314233}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 9s 12ms/step - loss: 18.6104 - val_loss: 6.0812\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 9.2698 - val_loss: 4.9644\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 8.4970 - val_loss: 5.2751\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:22:29,358] Trial 82 finished with value: 5.275130748748779 and parameters: {'n_units': 90, 'dropout_rate': 0.24487918263923172}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 12ms/step - loss: 18.5876 - val_loss: 6.4119\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 9.6769 - val_loss: 4.8087\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 8.8181 - val_loss: 4.5859\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 8.3216 - val_loss: 3.9666\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 7.9917 - val_loss: 4.0597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:23:01,046] Trial 83 finished with value: 4.059733867645264 and parameters: {'n_units': 95, 'dropout_rate': 0.2907734374767938}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 9s 12ms/step - loss: 18.8727 - val_loss: 6.3612\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 9.0140 - val_loss: 4.7499\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 8.1347 - val_loss: 4.3927\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 7.6567 - val_loss: 4.0827\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 7.2893 - val_loss: 3.7688\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 7.0830 - val_loss: 4.0970\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:23:35,505] Trial 84 finished with value: 4.096972465515137 and parameters: {'n_units': 87, 'dropout_rate': 0.21107231524912104}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 13ms/step - loss: 20.3509 - val_loss: 8.0002\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 10.7032 - val_loss: 5.2244\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 9.9336 - val_loss: 5.2303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:24:02,462] Trial 85 finished with value: 5.230323791503906 and parameters: {'n_units': 66, 'dropout_rate': 0.27549978736533165}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 9s 12ms/step - loss: 18.1869 - val_loss: 7.4391\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 9.2178 - val_loss: 5.0420\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 8.1942 - val_loss: 4.3522\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.7754 - val_loss: 3.5291\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 7.4326 - val_loss: 3.3734\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 7.1537 - val_loss: 4.2199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:24:36,071] Trial 86 finished with value: 4.219949722290039 and parameters: {'n_units': 92, 'dropout_rate': 0.2422019918048522}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 7s 11ms/step - loss: 17.8796 - val_loss: 6.3526\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 8.7861 - val_loss: 4.6700\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 7.8585 - val_loss: 4.1213\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.4109 - val_loss: 4.1658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:24:58,780] Trial 87 finished with value: 4.165802955627441 and parameters: {'n_units': 98, 'dropout_rate': 0.23006014096604888}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 12ms/step - loss: 19.9582 - val_loss: 6.3814\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 10.0233 - val_loss: 4.9020\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 9.2176 - val_loss: 4.7004\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 8.7273 - val_loss: 4.1535\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 8.3982 - val_loss: 4.2810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:25:46,399] Trial 88 finished with value: 4.281034469604492 and parameters: {'n_units': 72, 'dropout_rate': 0.2612811625141671}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 12ms/step - loss: 21.5488 - val_loss: 6.6730\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 9.6379 - val_loss: 4.7789\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.6600 - val_loss: 5.0038\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:26:04,536] Trial 89 finished with value: 5.00380802154541 and parameters: {'n_units': 83, 'dropout_rate': 0.2536670639695563}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 13ms/step - loss: 17.6518 - val_loss: 6.3106\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 8.8294 - val_loss: 5.3480\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.9219 - val_loss: 4.1637\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 7.4125 - val_loss: 3.4696\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 7.0343 - val_loss: 3.5860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:26:32,443] Trial 90 finished with value: 3.5860204696655273 and parameters: {'n_units': 90, 'dropout_rate': 0.2166651344269287}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 13ms/step - loss: 18.7226 - val_loss: 6.1585\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 9.0520 - val_loss: 5.3610\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 8.2151 - val_loss: 4.8645\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 8s 16ms/step - loss: 7.7405 - val_loss: 4.0698\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.4147 - val_loss: 3.6909\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.1696 - val_loss: 4.7432\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:27:06,817] Trial 91 finished with value: 4.743156909942627 and parameters: {'n_units': 96, 'dropout_rate': 0.2405937841614373}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 13ms/step - loss: 18.6526 - val_loss: 6.5297\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 8.7372 - val_loss: 4.9144\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.7756 - val_loss: 4.2509\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 7.2715 - val_loss: 4.2830\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:27:38,716] Trial 92 finished with value: 4.283019542694092 and parameters: {'n_units': 94, 'dropout_rate': 0.20388779071124258}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 13ms/step - loss: 19.5412 - val_loss: 7.0719\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 9.5022 - val_loss: 5.8073\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 8.6031 - val_loss: 4.3722\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 8.0966 - val_loss: 3.8275\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.7398 - val_loss: 3.3996\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.5554 - val_loss: 4.2603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:28:30,747] Trial 93 finished with value: 4.26029109954834 and parameters: {'n_units': 99, 'dropout_rate': 0.2855278679013076}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 12ms/step - loss: 18.0533 - val_loss: 6.4051\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 9.2118 - val_loss: 4.8800\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 8.3018 - val_loss: 4.9114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:28:59,258] Trial 94 finished with value: 4.911394119262695 and parameters: {'n_units': 85, 'dropout_rate': 0.22898278435649266}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 11ms/step - loss: 17.9249 - val_loss: 7.2827\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 8.9239 - val_loss: 5.1078\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 8.0660 - val_loss: 4.8677\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.5365 - val_loss: 4.0277\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 7.2261 - val_loss: 3.5195\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 6.9643 - val_loss: 3.4182\n",
            "Epoch 7/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 6.8645 - val_loss: 2.9837\n",
            "Epoch 8/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 6.6371 - val_loss: 3.0873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:29:42,790] Trial 95 finished with value: 3.0873007774353027 and parameters: {'n_units': 89, 'dropout_rate': 0.21355134773832946}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 7s 11ms/step - loss: 20.5022 - val_loss: 6.3624\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 10.1521 - val_loss: 5.4294\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 9.1930 - val_loss: 4.2897\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 8.6529 - val_loss: 4.1611\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 8.3197 - val_loss: 3.7975\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 8.0139 - val_loss: 3.8075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:30:16,609] Trial 96 finished with value: 3.8074629306793213 and parameters: {'n_units': 79, 'dropout_rate': 0.27288218665719766}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 12ms/step - loss: 18.3545 - val_loss: 5.8654\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 8.9187 - val_loss: 4.7671\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 8.0529 - val_loss: 4.0602\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 7.5176 - val_loss: 3.9904\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.2035 - val_loss: 3.2993\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 6.9322 - val_loss: 3.6588\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:30:48,596] Trial 97 finished with value: 3.6587657928466797 and parameters: {'n_units': 82, 'dropout_rate': 0.21102619143223483}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 13ms/step - loss: 19.3622 - val_loss: 6.1831\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 9.5655 - val_loss: 5.3340\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 8.6439 - val_loss: 4.8375\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 8.1584 - val_loss: 3.8764\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.7621 - val_loss: 4.0178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:31:27,067] Trial 98 finished with value: 4.0177788734436035 and parameters: {'n_units': 88, 'dropout_rate': 0.25087683760209756}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "466/466 [==============================] - 8s 13ms/step - loss: 18.5944 - val_loss: 6.1899\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 9.7936 - val_loss: 5.3008\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 8.8866 - val_loss: 4.5130\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 8.3975 - val_loss: 3.7553\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 8.0473 - val_loss: 3.9465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-28 20:31:54,880] Trial 99 finished with value: 3.946481943130493 and parameters: {'n_units': 91, 'dropout_rate': 0.2973960245078686}. Best is trial 30 with value: 2.8309476375579834.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'n_units': 85, 'dropout_rate': 0.22534758805513347}\n",
            "Best Objective Value: 2.8309476375579834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Expanded Long-Short Term Memory Model with the hyperparameters from Optuna\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "number_of_LSTM_units = 85 #best hyperparameter value from optuna\n",
        "dropout_rate = 0.22 #best hyperparameter value from optuna\n",
        "model_LSTM_85_units_22_dropout_500_epochs = keras.models.Sequential([\n",
        "    keras.layers.LSTM(number_of_LSTM_units, return_sequences=True, input_shape=[None, 2]),\n",
        "    keras.layers.Dropout(dropout_rate),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(1))\n",
        "])\n",
        "\n",
        "model_LSTM_85_units_22_dropout_500_epochs.compile(loss=\"mape\", optimizer=\"adam\")\n",
        "history_model_LSTM_85_units_22_dropout_500_epochs = model_LSTM_85_units_22_dropout_500_epochs.fit(X_train, Y_train, epochs=500,\n",
        "                    validation_data=(X_val, Y_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90wXRO_E23kW",
        "outputId": "3cf42767-3a1e-4cac-ddbc-6444b11d97b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "466/466 [==============================] - 8s 13ms/step - loss: 18.4053 - val_loss: 6.6236\n",
            "Epoch 2/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 9.0713 - val_loss: 4.6867\n",
            "Epoch 3/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 8.2640 - val_loss: 4.1767\n",
            "Epoch 4/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.7740 - val_loss: 3.7154\n",
            "Epoch 5/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.4418 - val_loss: 3.9720\n",
            "Epoch 6/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 7.1953 - val_loss: 3.6438\n",
            "Epoch 7/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 7.0516 - val_loss: 3.0464\n",
            "Epoch 8/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 6.8674 - val_loss: 3.0546\n",
            "Epoch 9/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 6.6807 - val_loss: 3.5153\n",
            "Epoch 10/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 6.5863 - val_loss: 2.7996\n",
            "Epoch 11/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 6.4830 - val_loss: 2.5708\n",
            "Epoch 12/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 6.3937 - val_loss: 3.0324\n",
            "Epoch 13/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 6.3463 - val_loss: 3.2843\n",
            "Epoch 14/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 6.2517 - val_loss: 3.2892\n",
            "Epoch 15/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 6.1738 - val_loss: 2.3210\n",
            "Epoch 16/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 6.1886 - val_loss: 2.5226\n",
            "Epoch 17/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 6.0808 - val_loss: 2.7284\n",
            "Epoch 18/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 6.0944 - val_loss: 2.5983\n",
            "Epoch 19/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 6.0314 - val_loss: 2.5622\n",
            "Epoch 20/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.9898 - val_loss: 1.9580\n",
            "Epoch 21/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.9819 - val_loss: 2.1604\n",
            "Epoch 22/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.9542 - val_loss: 3.0026\n",
            "Epoch 23/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.9776 - val_loss: 2.5798\n",
            "Epoch 24/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.9072 - val_loss: 2.1484\n",
            "Epoch 25/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.8720 - val_loss: 2.3069\n",
            "Epoch 26/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.9465 - val_loss: 2.8682\n",
            "Epoch 27/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.8404 - val_loss: 2.4141\n",
            "Epoch 28/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.8699 - val_loss: 2.9822\n",
            "Epoch 29/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.8552 - val_loss: 1.8962\n",
            "Epoch 30/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.8138 - val_loss: 2.1166\n",
            "Epoch 31/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.8033 - val_loss: 2.2786\n",
            "Epoch 32/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.8206 - val_loss: 3.1011\n",
            "Epoch 33/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.7592 - val_loss: 2.5354\n",
            "Epoch 34/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.7851 - val_loss: 1.9092\n",
            "Epoch 35/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.7537 - val_loss: 2.2707\n",
            "Epoch 36/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.7558 - val_loss: 1.9321\n",
            "Epoch 37/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.7399 - val_loss: 1.8224\n",
            "Epoch 38/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.7298 - val_loss: 1.7590\n",
            "Epoch 39/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.6833 - val_loss: 2.3601\n",
            "Epoch 40/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.7202 - val_loss: 2.3447\n",
            "Epoch 41/500\n",
            "466/466 [==============================] - 6s 13ms/step - loss: 5.6860 - val_loss: 1.9570\n",
            "Epoch 42/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.6881 - val_loss: 1.9721\n",
            "Epoch 43/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.6624 - val_loss: 3.0129\n",
            "Epoch 44/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.6956 - val_loss: 2.1755\n",
            "Epoch 45/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.6328 - val_loss: 2.4060\n",
            "Epoch 46/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.6921 - val_loss: 2.1758\n",
            "Epoch 47/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.6421 - val_loss: 2.4002\n",
            "Epoch 48/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.6334 - val_loss: 2.2541\n",
            "Epoch 49/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.6399 - val_loss: 2.4141\n",
            "Epoch 50/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.6425 - val_loss: 1.9929\n",
            "Epoch 51/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.6388 - val_loss: 2.1538\n",
            "Epoch 52/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.6125 - val_loss: 2.4822\n",
            "Epoch 53/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.6021 - val_loss: 1.9658\n",
            "Epoch 54/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.6065 - val_loss: 1.9116\n",
            "Epoch 55/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.6178 - val_loss: 1.9191\n",
            "Epoch 56/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.6095 - val_loss: 2.0536\n",
            "Epoch 57/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.5977 - val_loss: 2.2374\n",
            "Epoch 58/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.5975 - val_loss: 1.9278\n",
            "Epoch 59/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.5741 - val_loss: 1.8742\n",
            "Epoch 60/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.6078 - val_loss: 1.8673\n",
            "Epoch 61/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.6035 - val_loss: 1.6973\n",
            "Epoch 62/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.5692 - val_loss: 2.3571\n",
            "Epoch 63/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.5861 - val_loss: 1.7941\n",
            "Epoch 64/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.5703 - val_loss: 1.7500\n",
            "Epoch 65/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.5535 - val_loss: 2.1199\n",
            "Epoch 66/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.5606 - val_loss: 1.9463\n",
            "Epoch 67/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.5502 - val_loss: 1.8797\n",
            "Epoch 68/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.5368 - val_loss: 2.2077\n",
            "Epoch 69/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.5401 - val_loss: 2.2671\n",
            "Epoch 70/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.5534 - val_loss: 1.8998\n",
            "Epoch 71/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.5476 - val_loss: 2.4672\n",
            "Epoch 72/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.5156 - val_loss: 1.9758\n",
            "Epoch 73/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.5292 - val_loss: 1.9206\n",
            "Epoch 74/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.5495 - val_loss: 1.9317\n",
            "Epoch 75/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.5173 - val_loss: 1.6646\n",
            "Epoch 76/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.5179 - val_loss: 2.1914\n",
            "Epoch 77/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.5322 - val_loss: 1.8710\n",
            "Epoch 78/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.5093 - val_loss: 2.2789\n",
            "Epoch 79/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.5027 - val_loss: 2.3179\n",
            "Epoch 80/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.5251 - val_loss: 2.1512\n",
            "Epoch 81/500\n",
            "466/466 [==============================] - 6s 13ms/step - loss: 5.5177 - val_loss: 2.0928\n",
            "Epoch 82/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.4898 - val_loss: 2.4131\n",
            "Epoch 83/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.5117 - val_loss: 1.6999\n",
            "Epoch 84/500\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 5.4879 - val_loss: 1.6457\n",
            "Epoch 85/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.5007 - val_loss: 1.7574\n",
            "Epoch 86/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.4969 - val_loss: 2.0156\n",
            "Epoch 87/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.4950 - val_loss: 1.6736\n",
            "Epoch 88/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.5065 - val_loss: 1.9788\n",
            "Epoch 89/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.4749 - val_loss: 1.9695\n",
            "Epoch 90/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.4664 - val_loss: 1.7056\n",
            "Epoch 91/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.4756 - val_loss: 2.0125\n",
            "Epoch 92/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.4704 - val_loss: 1.7927\n",
            "Epoch 93/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.5140 - val_loss: 1.8456\n",
            "Epoch 94/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.4692 - val_loss: 1.9461\n",
            "Epoch 95/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.5024 - val_loss: 1.7372\n",
            "Epoch 96/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.4695 - val_loss: 1.6686\n",
            "Epoch 97/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.4560 - val_loss: 1.7910\n",
            "Epoch 98/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.4797 - val_loss: 1.6312\n",
            "Epoch 99/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.4674 - val_loss: 1.7479\n",
            "Epoch 100/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.4460 - val_loss: 1.9532\n",
            "Epoch 101/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.4395 - val_loss: 1.7727\n",
            "Epoch 102/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.4676 - val_loss: 1.9792\n",
            "Epoch 103/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.4649 - val_loss: 1.6047\n",
            "Epoch 104/500\n",
            "466/466 [==============================] - 6s 13ms/step - loss: 5.4608 - val_loss: 1.8327\n",
            "Epoch 105/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.4478 - val_loss: 1.5920\n",
            "Epoch 106/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.4671 - val_loss: 2.0409\n",
            "Epoch 107/500\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 5.4458 - val_loss: 1.9382\n",
            "Epoch 108/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.4441 - val_loss: 1.9978\n",
            "Epoch 109/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.4439 - val_loss: 1.8655\n",
            "Epoch 110/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.4453 - val_loss: 2.1341\n",
            "Epoch 111/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.4387 - val_loss: 1.6217\n",
            "Epoch 112/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.4424 - val_loss: 2.2967\n",
            "Epoch 113/500\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 5.4354 - val_loss: 2.4678\n",
            "Epoch 114/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.4287 - val_loss: 2.1862\n",
            "Epoch 115/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.4443 - val_loss: 1.7639\n",
            "Epoch 116/500\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 5.4435 - val_loss: 2.1355\n",
            "Epoch 117/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.4241 - val_loss: 1.5789\n",
            "Epoch 118/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.4242 - val_loss: 2.0564\n",
            "Epoch 119/500\n",
            "466/466 [==============================] - 7s 14ms/step - loss: 5.4396 - val_loss: 1.7873\n",
            "Epoch 120/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.4316 - val_loss: 1.6419\n",
            "Epoch 121/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.4127 - val_loss: 1.6416\n",
            "Epoch 122/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.4244 - val_loss: 1.9667\n",
            "Epoch 123/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.4433 - val_loss: 1.8677\n",
            "Epoch 124/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.4201 - val_loss: 1.8714\n",
            "Epoch 125/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.4425 - val_loss: 1.7452\n",
            "Epoch 126/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.4301 - val_loss: 2.1301\n",
            "Epoch 127/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.4308 - val_loss: 1.9488\n",
            "Epoch 128/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.4095 - val_loss: 2.0224\n",
            "Epoch 129/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.4399 - val_loss: 1.6892\n",
            "Epoch 130/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.4077 - val_loss: 1.6970\n",
            "Epoch 131/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.3944 - val_loss: 1.8879\n",
            "Epoch 132/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.4103 - val_loss: 2.2982\n",
            "Epoch 133/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.4043 - val_loss: 1.7444\n",
            "Epoch 134/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.4163 - val_loss: 1.7521\n",
            "Epoch 135/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.4254 - val_loss: 1.8614\n",
            "Epoch 136/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.4146 - val_loss: 1.9624\n",
            "Epoch 137/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.3973 - val_loss: 1.6249\n",
            "Epoch 138/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.4006 - val_loss: 1.7594\n",
            "Epoch 139/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.3959 - val_loss: 1.8590\n",
            "Epoch 140/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.4144 - val_loss: 1.8907\n",
            "Epoch 141/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.4077 - val_loss: 1.9224\n",
            "Epoch 142/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.4041 - val_loss: 1.6927\n",
            "Epoch 143/500\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 5.3776 - val_loss: 1.9097\n",
            "Epoch 144/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.3726 - val_loss: 1.6444\n",
            "Epoch 145/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.4071 - val_loss: 1.7724\n",
            "Epoch 146/500\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 5.4164 - val_loss: 1.8645\n",
            "Epoch 147/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3863 - val_loss: 1.9999\n",
            "Epoch 148/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.3893 - val_loss: 1.7350\n",
            "Epoch 149/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.3882 - val_loss: 1.8105\n",
            "Epoch 150/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3895 - val_loss: 1.5664\n",
            "Epoch 151/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.3751 - val_loss: 1.5547\n",
            "Epoch 152/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.4010 - val_loss: 1.6827\n",
            "Epoch 153/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3647 - val_loss: 2.0508\n",
            "Epoch 154/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.3935 - val_loss: 2.0807\n",
            "Epoch 155/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.4248 - val_loss: 1.7719\n",
            "Epoch 156/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.3854 - val_loss: 1.5755\n",
            "Epoch 157/500\n",
            "466/466 [==============================] - 6s 13ms/step - loss: 5.3793 - val_loss: 1.6431\n",
            "Epoch 158/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3953 - val_loss: 1.9471\n",
            "Epoch 159/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3789 - val_loss: 2.1667\n",
            "Epoch 160/500\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 5.3785 - val_loss: 2.5847\n",
            "Epoch 161/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3704 - val_loss: 1.7434\n",
            "Epoch 162/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3749 - val_loss: 1.8756\n",
            "Epoch 163/500\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 5.3965 - val_loss: 1.9868\n",
            "Epoch 164/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3589 - val_loss: 1.8973\n",
            "Epoch 165/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3694 - val_loss: 1.5256\n",
            "Epoch 166/500\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 5.3672 - val_loss: 1.7078\n",
            "Epoch 167/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3942 - val_loss: 1.6285\n",
            "Epoch 168/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3596 - val_loss: 1.6995\n",
            "Epoch 169/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.3717 - val_loss: 1.7120\n",
            "Epoch 170/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.3654 - val_loss: 1.7313\n",
            "Epoch 171/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3728 - val_loss: 1.7186\n",
            "Epoch 172/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.3671 - val_loss: 1.8148\n",
            "Epoch 173/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3517 - val_loss: 2.0468\n",
            "Epoch 174/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3880 - val_loss: 1.9758\n",
            "Epoch 175/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.3687 - val_loss: 1.5910\n",
            "Epoch 176/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3439 - val_loss: 1.8782\n",
            "Epoch 177/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3537 - val_loss: 1.9323\n",
            "Epoch 178/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.3771 - val_loss: 1.6868\n",
            "Epoch 179/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3718 - val_loss: 1.6776\n",
            "Epoch 180/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3690 - val_loss: 1.6009\n",
            "Epoch 181/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.3484 - val_loss: 1.6709\n",
            "Epoch 182/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3726 - val_loss: 1.5512\n",
            "Epoch 183/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3588 - val_loss: 1.9414\n",
            "Epoch 184/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.3760 - val_loss: 1.5902\n",
            "Epoch 185/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.3441 - val_loss: 1.7444\n",
            "Epoch 186/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.3489 - val_loss: 2.2872\n",
            "Epoch 187/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.3677 - val_loss: 1.5973\n",
            "Epoch 188/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.3759 - val_loss: 1.5844\n",
            "Epoch 189/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.3614 - val_loss: 2.0680\n",
            "Epoch 190/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.3323 - val_loss: 1.9363\n",
            "Epoch 191/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3585 - val_loss: 1.9338\n",
            "Epoch 192/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.3864 - val_loss: 1.7351\n",
            "Epoch 193/500\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 5.3444 - val_loss: 1.8984\n",
            "Epoch 194/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.3434 - val_loss: 1.6530\n",
            "Epoch 195/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.4482 - val_loss: 1.5673\n",
            "Epoch 196/500\n",
            "466/466 [==============================] - 7s 15ms/step - loss: 5.3491 - val_loss: 1.5100\n",
            "Epoch 197/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3431 - val_loss: 2.1428\n",
            "Epoch 198/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.3384 - val_loss: 1.8693\n",
            "Epoch 199/500\n",
            "466/466 [==============================] - 6s 13ms/step - loss: 5.3362 - val_loss: 1.5823\n",
            "Epoch 200/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.3399 - val_loss: 1.7857\n",
            "Epoch 201/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3388 - val_loss: 1.7129\n",
            "Epoch 202/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.3638 - val_loss: 1.5739\n",
            "Epoch 203/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3332 - val_loss: 2.4669\n",
            "Epoch 204/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3324 - val_loss: 1.5485\n",
            "Epoch 205/500\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 5.3512 - val_loss: 2.3167\n",
            "Epoch 206/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3359 - val_loss: 1.5855\n",
            "Epoch 207/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.3340 - val_loss: 1.8346\n",
            "Epoch 208/500\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 5.3417 - val_loss: 2.0082\n",
            "Epoch 209/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3376 - val_loss: 1.5500\n",
            "Epoch 210/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3467 - val_loss: 1.6047\n",
            "Epoch 211/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.3353 - val_loss: 1.9367\n",
            "Epoch 212/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3403 - val_loss: 1.8035\n",
            "Epoch 213/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3216 - val_loss: 1.7090\n",
            "Epoch 214/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.3213 - val_loss: 1.7995\n",
            "Epoch 215/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3338 - val_loss: 1.7581\n",
            "Epoch 216/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3471 - val_loss: 1.6373\n",
            "Epoch 217/500\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 5.3103 - val_loss: 1.4061\n",
            "Epoch 218/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.3559 - val_loss: 1.5909\n",
            "Epoch 219/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.3522 - val_loss: 1.5007\n",
            "Epoch 220/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.3307 - val_loss: 1.9731\n",
            "Epoch 221/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.3311 - val_loss: 1.7377\n",
            "Epoch 222/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.3121 - val_loss: 1.5720\n",
            "Epoch 223/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.3047 - val_loss: 1.6974\n",
            "Epoch 224/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3210 - val_loss: 1.6583\n",
            "Epoch 225/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.3358 - val_loss: 1.6411\n",
            "Epoch 226/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.3119 - val_loss: 1.5965\n",
            "Epoch 227/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.3438 - val_loss: 1.6888\n",
            "Epoch 228/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.3046 - val_loss: 1.5162\n",
            "Epoch 229/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.3353 - val_loss: 1.7097\n",
            "Epoch 230/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.3221 - val_loss: 2.0431\n",
            "Epoch 231/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.3217 - val_loss: 1.5116\n",
            "Epoch 232/500\n",
            "466/466 [==============================] - 6s 13ms/step - loss: 5.3144 - val_loss: 1.6989\n",
            "Epoch 233/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.3275 - val_loss: 1.7763\n",
            "Epoch 234/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.3286 - val_loss: 1.4758\n",
            "Epoch 235/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.3111 - val_loss: 1.8948\n",
            "Epoch 236/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2952 - val_loss: 2.1572\n",
            "Epoch 237/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.3067 - val_loss: 1.8509\n",
            "Epoch 238/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.3001 - val_loss: 1.9240\n",
            "Epoch 239/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.3435 - val_loss: 1.6155\n",
            "Epoch 240/500\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 5.3199 - val_loss: 1.7334\n",
            "Epoch 241/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.3034 - val_loss: 1.9086\n",
            "Epoch 242/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3170 - val_loss: 1.5031\n",
            "Epoch 243/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.3320 - val_loss: 2.4314\n",
            "Epoch 244/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.3195 - val_loss: 1.6406\n",
            "Epoch 245/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.3358 - val_loss: 1.9781\n",
            "Epoch 246/500\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 5.3069 - val_loss: 1.5555\n",
            "Epoch 247/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.3081 - val_loss: 1.6037\n",
            "Epoch 248/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.2933 - val_loss: 1.8491\n",
            "Epoch 249/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.3083 - val_loss: 1.5846\n",
            "Epoch 250/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.3539 - val_loss: 1.5838\n",
            "Epoch 251/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.2890 - val_loss: 1.8108\n",
            "Epoch 252/500\n",
            "466/466 [==============================] - 6s 13ms/step - loss: 5.2906 - val_loss: 1.5959\n",
            "Epoch 253/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2977 - val_loss: 1.4335\n",
            "Epoch 254/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3013 - val_loss: 1.5076\n",
            "Epoch 255/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.3072 - val_loss: 2.3427\n",
            "Epoch 256/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2941 - val_loss: 1.7839\n",
            "Epoch 257/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3161 - val_loss: 1.5939\n",
            "Epoch 258/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.2934 - val_loss: 1.7693\n",
            "Epoch 259/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3010 - val_loss: 1.6151\n",
            "Epoch 260/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2928 - val_loss: 1.6987\n",
            "Epoch 261/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.2988 - val_loss: 1.4757\n",
            "Epoch 262/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.3075 - val_loss: 1.5111\n",
            "Epoch 263/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.2884 - val_loss: 1.8691\n",
            "Epoch 264/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.3070 - val_loss: 1.5070\n",
            "Epoch 265/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3032 - val_loss: 2.0530\n",
            "Epoch 266/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.3142 - val_loss: 1.6573\n",
            "Epoch 267/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.2904 - val_loss: 1.8492\n",
            "Epoch 268/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.2958 - val_loss: 1.6823\n",
            "Epoch 269/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2967 - val_loss: 2.4289\n",
            "Epoch 270/500\n",
            "466/466 [==============================] - 6s 13ms/step - loss: 5.3120 - val_loss: 1.4732\n",
            "Epoch 271/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.2905 - val_loss: 1.8602\n",
            "Epoch 272/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2933 - val_loss: 1.6479\n",
            "Epoch 273/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.2906 - val_loss: 1.6304\n",
            "Epoch 274/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.2938 - val_loss: 1.5737\n",
            "Epoch 275/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.2987 - val_loss: 1.7515\n",
            "Epoch 276/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.2917 - val_loss: 1.4956\n",
            "Epoch 277/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2774 - val_loss: 1.6247\n",
            "Epoch 278/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.2745 - val_loss: 1.7405\n",
            "Epoch 279/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.3124 - val_loss: 1.5205\n",
            "Epoch 280/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.2965 - val_loss: 1.7806\n",
            "Epoch 281/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.2851 - val_loss: 1.4729\n",
            "Epoch 282/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.2837 - val_loss: 2.3014\n",
            "Epoch 283/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.2928 - val_loss: 1.5578\n",
            "Epoch 284/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2792 - val_loss: 1.8247\n",
            "Epoch 285/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.2927 - val_loss: 1.7688\n",
            "Epoch 286/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.2918 - val_loss: 1.7195\n",
            "Epoch 287/500\n",
            "466/466 [==============================] - 9s 20ms/step - loss: 5.3001 - val_loss: 1.7082\n",
            "Epoch 288/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2893 - val_loss: 1.8081\n",
            "Epoch 289/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2748 - val_loss: 1.6502\n",
            "Epoch 290/500\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 5.2782 - val_loss: 1.4431\n",
            "Epoch 291/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.2852 - val_loss: 2.0180\n",
            "Epoch 292/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.3048 - val_loss: 1.8782\n",
            "Epoch 293/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2679 - val_loss: 1.5836\n",
            "Epoch 294/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.2807 - val_loss: 1.8173\n",
            "Epoch 295/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2930 - val_loss: 2.0705\n",
            "Epoch 296/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2837 - val_loss: 1.6473\n",
            "Epoch 297/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.2830 - val_loss: 1.6103\n",
            "Epoch 298/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2932 - val_loss: 1.7688\n",
            "Epoch 299/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.3226 - val_loss: 1.4347\n",
            "Epoch 300/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.2894 - val_loss: 1.7204\n",
            "Epoch 301/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2853 - val_loss: 1.5247\n",
            "Epoch 302/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2827 - val_loss: 1.5508\n",
            "Epoch 303/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.2693 - val_loss: 1.8238\n",
            "Epoch 304/500\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 5.2894 - val_loss: 1.9151\n",
            "Epoch 305/500\n",
            "466/466 [==============================] - 7s 14ms/step - loss: 5.2547 - val_loss: 1.9381\n",
            "Epoch 306/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2896 - val_loss: 1.5126\n",
            "Epoch 307/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2677 - val_loss: 1.6911\n",
            "Epoch 308/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2744 - val_loss: 1.7419\n",
            "Epoch 309/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.2795 - val_loss: 1.9778\n",
            "Epoch 310/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2954 - val_loss: 1.9150\n",
            "Epoch 311/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2544 - val_loss: 1.4065\n",
            "Epoch 312/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.2644 - val_loss: 1.6604\n",
            "Epoch 313/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2914 - val_loss: 1.5344\n",
            "Epoch 314/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2783 - val_loss: 1.5953\n",
            "Epoch 315/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.2753 - val_loss: 1.4258\n",
            "Epoch 316/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2743 - val_loss: 1.9128\n",
            "Epoch 317/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2702 - val_loss: 1.8094\n",
            "Epoch 318/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2762 - val_loss: 1.4828\n",
            "Epoch 319/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2657 - val_loss: 1.4796\n",
            "Epoch 320/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2850 - val_loss: 1.6212\n",
            "Epoch 321/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.2754 - val_loss: 1.5558\n",
            "Epoch 322/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2745 - val_loss: 1.5301\n",
            "Epoch 323/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2706 - val_loss: 1.5117\n",
            "Epoch 324/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.2725 - val_loss: 1.4357\n",
            "Epoch 325/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2591 - val_loss: 1.4540\n",
            "Epoch 326/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2543 - val_loss: 1.5857\n",
            "Epoch 327/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.2911 - val_loss: 2.0510\n",
            "Epoch 328/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2674 - val_loss: 1.6685\n",
            "Epoch 329/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2594 - val_loss: 1.5183\n",
            "Epoch 330/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.2655 - val_loss: 1.9594\n",
            "Epoch 331/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2761 - val_loss: 1.6130\n",
            "Epoch 332/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2740 - val_loss: 1.4577\n",
            "Epoch 333/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.2958 - val_loss: 1.4361\n",
            "Epoch 334/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2540 - val_loss: 1.6892\n",
            "Epoch 335/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2813 - val_loss: 1.7476\n",
            "Epoch 336/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.2599 - val_loss: 1.5849\n",
            "Epoch 337/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2580 - val_loss: 1.6773\n",
            "Epoch 338/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2693 - val_loss: 1.6126\n",
            "Epoch 339/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.2697 - val_loss: 1.4364\n",
            "Epoch 340/500\n",
            "466/466 [==============================] - 6s 13ms/step - loss: 5.2804 - val_loss: 1.7105\n",
            "Epoch 341/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.2595 - val_loss: 1.9555\n",
            "Epoch 342/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.2898 - val_loss: 1.5854\n",
            "Epoch 343/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2541 - val_loss: 1.7361\n",
            "Epoch 344/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2557 - val_loss: 1.6617\n",
            "Epoch 345/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.2689 - val_loss: 1.7933\n",
            "Epoch 346/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2590 - val_loss: 1.9183\n",
            "Epoch 347/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2609 - val_loss: 1.6092\n",
            "Epoch 348/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.3124 - val_loss: 1.4425\n",
            "Epoch 349/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2707 - val_loss: 1.4380\n",
            "Epoch 350/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2592 - val_loss: 1.6813\n",
            "Epoch 351/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2441 - val_loss: 1.5792\n",
            "Epoch 352/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2619 - val_loss: 1.7706\n",
            "Epoch 353/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2808 - val_loss: 1.7019\n",
            "Epoch 354/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.2662 - val_loss: 1.8789\n",
            "Epoch 355/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2492 - val_loss: 1.5205\n",
            "Epoch 356/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2372 - val_loss: 1.8274\n",
            "Epoch 357/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.2584 - val_loss: 1.8672\n",
            "Epoch 358/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2876 - val_loss: 1.5573\n",
            "Epoch 359/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2581 - val_loss: 1.6284\n",
            "Epoch 360/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.2650 - val_loss: 1.8759\n",
            "Epoch 361/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2592 - val_loss: 1.6034\n",
            "Epoch 362/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2556 - val_loss: 1.4972\n",
            "Epoch 363/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2712 - val_loss: 1.7552\n",
            "Epoch 364/500\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 5.2837 - val_loss: 1.6011\n",
            "Epoch 365/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2576 - val_loss: 1.7145\n",
            "Epoch 366/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2467 - val_loss: 1.3721\n",
            "Epoch 367/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.2531 - val_loss: 1.7277\n",
            "Epoch 368/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2694 - val_loss: 1.5725\n",
            "Epoch 369/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2680 - val_loss: 1.4056\n",
            "Epoch 370/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.2824 - val_loss: 1.4906\n",
            "Epoch 371/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.2454 - val_loss: 1.6263\n",
            "Epoch 372/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.2397 - val_loss: 1.5854\n",
            "Epoch 373/500\n",
            "466/466 [==============================] - 6s 13ms/step - loss: 5.2626 - val_loss: 1.5033\n",
            "Epoch 374/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2560 - val_loss: 1.5357\n",
            "Epoch 375/500\n",
            "466/466 [==============================] - 6s 13ms/step - loss: 5.2415 - val_loss: 1.9297\n",
            "Epoch 376/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.2573 - val_loss: 1.8152\n",
            "Epoch 377/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2693 - val_loss: 1.4705\n",
            "Epoch 378/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2516 - val_loss: 1.6647\n",
            "Epoch 379/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2854 - val_loss: 1.7861\n",
            "Epoch 380/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.2616 - val_loss: 1.8759\n",
            "Epoch 381/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2424 - val_loss: 1.6719\n",
            "Epoch 382/500\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 5.2493 - val_loss: 1.5484\n",
            "Epoch 383/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.2601 - val_loss: 1.5032\n",
            "Epoch 384/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2526 - val_loss: 2.1956\n",
            "Epoch 385/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2389 - val_loss: 1.4158\n",
            "Epoch 386/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.2536 - val_loss: 1.4286\n",
            "Epoch 387/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2618 - val_loss: 1.4160\n",
            "Epoch 388/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2578 - val_loss: 2.1392\n",
            "Epoch 389/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.2581 - val_loss: 1.6078\n",
            "Epoch 390/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2743 - val_loss: 1.5923\n",
            "Epoch 391/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2470 - val_loss: 1.5444\n",
            "Epoch 392/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.2427 - val_loss: 1.6387\n",
            "Epoch 393/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2580 - val_loss: 1.8917\n",
            "Epoch 394/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2818 - val_loss: 1.7467\n",
            "Epoch 395/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.2473 - val_loss: 1.6621\n",
            "Epoch 396/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.2399 - val_loss: 1.6135\n",
            "Epoch 397/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2525 - val_loss: 1.7537\n",
            "Epoch 398/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2470 - val_loss: 1.8720\n",
            "Epoch 399/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.2577 - val_loss: 1.5790\n",
            "Epoch 400/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.2542 - val_loss: 1.5300\n",
            "Epoch 401/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2329 - val_loss: 1.5358\n",
            "Epoch 402/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.2572 - val_loss: 1.3420\n",
            "Epoch 403/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.2422 - val_loss: 1.3965\n",
            "Epoch 404/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2656 - val_loss: 1.8327\n",
            "Epoch 405/500\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 5.2444 - val_loss: 1.5144\n",
            "Epoch 406/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2457 - val_loss: 1.4465\n",
            "Epoch 407/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2516 - val_loss: 1.8300\n",
            "Epoch 408/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.2417 - val_loss: 1.6558\n",
            "Epoch 409/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2419 - val_loss: 1.7253\n",
            "Epoch 410/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.2540 - val_loss: 1.5030\n",
            "Epoch 411/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2472 - val_loss: 1.5191\n",
            "Epoch 412/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.2469 - val_loss: 1.4617\n",
            "Epoch 413/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2495 - val_loss: 1.5938\n",
            "Epoch 414/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2767 - val_loss: 1.7558\n",
            "Epoch 415/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2455 - val_loss: 1.5516\n",
            "Epoch 416/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2644 - val_loss: 1.9344\n",
            "Epoch 417/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2509 - val_loss: 1.4064\n",
            "Epoch 418/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2399 - val_loss: 1.6347\n",
            "Epoch 419/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2425 - val_loss: 1.6759\n",
            "Epoch 420/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2494 - val_loss: 1.4569\n",
            "Epoch 421/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.2338 - val_loss: 1.6176\n",
            "Epoch 422/500\n",
            "466/466 [==============================] - 7s 15ms/step - loss: 5.2567 - val_loss: 1.5360\n",
            "Epoch 423/500\n",
            "466/466 [==============================] - 7s 14ms/step - loss: 5.2355 - val_loss: 1.5545\n",
            "Epoch 424/500\n",
            "466/466 [==============================] - 7s 15ms/step - loss: 5.2527 - val_loss: 1.4642\n",
            "Epoch 425/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2516 - val_loss: 1.4113\n",
            "Epoch 426/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2302 - val_loss: 1.5110\n",
            "Epoch 427/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.2358 - val_loss: 1.6492\n",
            "Epoch 428/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.2562 - val_loss: 1.6070\n",
            "Epoch 429/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2478 - val_loss: 1.5867\n",
            "Epoch 430/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.2566 - val_loss: 1.7100\n",
            "Epoch 431/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2328 - val_loss: 1.9347\n",
            "Epoch 432/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2427 - val_loss: 1.8166\n",
            "Epoch 433/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.2669 - val_loss: 1.5039\n",
            "Epoch 434/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2311 - val_loss: 1.5190\n",
            "Epoch 435/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2672 - val_loss: 1.5501\n",
            "Epoch 436/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.2309 - val_loss: 1.5803\n",
            "Epoch 437/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2258 - val_loss: 2.4124\n",
            "Epoch 438/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2397 - val_loss: 1.8920\n",
            "Epoch 439/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.2525 - val_loss: 1.5568\n",
            "Epoch 440/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2501 - val_loss: 1.8592\n",
            "Epoch 441/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2397 - val_loss: 1.7707\n",
            "Epoch 442/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.2314 - val_loss: 1.5139\n",
            "Epoch 443/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.2213 - val_loss: 1.6646\n",
            "Epoch 444/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2426 - val_loss: 1.5148\n",
            "Epoch 445/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2191 - val_loss: 1.9942\n",
            "Epoch 446/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2360 - val_loss: 2.2169\n",
            "Epoch 447/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2487 - val_loss: 1.5320\n",
            "Epoch 448/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2460 - val_loss: 1.3576\n",
            "Epoch 449/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2266 - val_loss: 1.4416\n",
            "Epoch 450/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2324 - val_loss: 1.7094\n",
            "Epoch 451/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2409 - val_loss: 1.6530\n",
            "Epoch 452/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2203 - val_loss: 1.6087\n",
            "Epoch 453/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.2327 - val_loss: 1.6415\n",
            "Epoch 454/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2349 - val_loss: 1.5639\n",
            "Epoch 455/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2259 - val_loss: 2.1016\n",
            "Epoch 456/500\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 5.2445 - val_loss: 1.5430\n",
            "Epoch 457/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2323 - val_loss: 1.8261\n",
            "Epoch 458/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.2250 - val_loss: 1.4880\n",
            "Epoch 459/500\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 5.2287 - val_loss: 1.4063\n",
            "Epoch 460/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2359 - val_loss: 1.8983\n",
            "Epoch 461/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.2550 - val_loss: 1.7894\n",
            "Epoch 462/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.2510 - val_loss: 2.0493\n",
            "Epoch 463/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.2337 - val_loss: 1.4382\n",
            "Epoch 464/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2360 - val_loss: 1.7136\n",
            "Epoch 465/500\n",
            "466/466 [==============================] - 5s 12ms/step - loss: 5.2396 - val_loss: 1.9693\n",
            "Epoch 466/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2374 - val_loss: 1.4849\n",
            "Epoch 467/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2337 - val_loss: 1.5028\n",
            "Epoch 468/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.2519 - val_loss: 1.5583\n",
            "Epoch 469/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.2414 - val_loss: 1.4955\n",
            "Epoch 470/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.2288 - val_loss: 1.8557\n",
            "Epoch 471/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.2321 - val_loss: 1.7523\n",
            "Epoch 472/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2173 - val_loss: 1.4603\n",
            "Epoch 473/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2197 - val_loss: 1.5941\n",
            "Epoch 474/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.2321 - val_loss: 1.7204\n",
            "Epoch 475/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2284 - val_loss: 1.9351\n",
            "Epoch 476/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.2406 - val_loss: 1.5566\n",
            "Epoch 477/500\n",
            "466/466 [==============================] - 6s 14ms/step - loss: 5.2331 - val_loss: 1.4782\n",
            "Epoch 478/500\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 5.2406 - val_loss: 1.5593\n",
            "Epoch 479/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.2280 - val_loss: 1.3565\n",
            "Epoch 480/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.2312 - val_loss: 1.6309\n",
            "Epoch 481/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.2452 - val_loss: 1.7940\n",
            "Epoch 482/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.2203 - val_loss: 1.6182\n",
            "Epoch 483/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.2378 - val_loss: 1.6863\n",
            "Epoch 484/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2344 - val_loss: 1.5560\n",
            "Epoch 485/500\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 5.2382 - val_loss: 1.5999\n",
            "Epoch 486/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.2247 - val_loss: 1.3921\n",
            "Epoch 487/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2406 - val_loss: 1.3543\n",
            "Epoch 488/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2322 - val_loss: 1.6182\n",
            "Epoch 489/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.2113 - val_loss: 1.5721\n",
            "Epoch 490/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2324 - val_loss: 1.4420\n",
            "Epoch 491/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2273 - val_loss: 1.8572\n",
            "Epoch 492/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.2233 - val_loss: 1.8220\n",
            "Epoch 493/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2341 - val_loss: 1.4343\n",
            "Epoch 494/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.2158 - val_loss: 1.8382\n",
            "Epoch 495/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.2288 - val_loss: 1.8154\n",
            "Epoch 496/500\n",
            "466/466 [==============================] - 4s 10ms/step - loss: 5.2306 - val_loss: 1.4833\n",
            "Epoch 497/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2225 - val_loss: 1.5891\n",
            "Epoch 498/500\n",
            "466/466 [==============================] - 6s 12ms/step - loss: 5.2124 - val_loss: 1.8265\n",
            "Epoch 499/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2260 - val_loss: 1.4671\n",
            "Epoch 500/500\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 5.2320 - val_loss: 1.9002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#The curves show that there is underfitting\n",
        "\n",
        "plot_learning_curves(history_model_LSTM_85_units_22_dropout_500_epochs.history[\"loss\"], history_model_LSTM_85_units_22_dropout_500_epochs.history[\"val_loss\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "rdK2a7CL5Vb2",
        "outputId": "56967174-f981-45b9-9d8d-3ba0413bcc8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 4: Model evaluation where we tested the model on different performance measures on the test set.\n",
        "\n",
        "Mean Absolute Error (MAE): This metric measures the average absolute difference between the predicted and actual exposure.\n",
        "\n",
        "Mean Squared Error (MSE): This metric calculates the average of the squared differences between the predicted and actual values.\n",
        "\n",
        "Root Mean Squared Error (RMSE): I a common metric for evaluating regression models. The RMSE is  the square root of the MSE nd provides a measure of the average magnitude of the prediction errors.\n",
        "\n",
        "R-squared (R^2 Score: This metric indicates the proportion of the variance in the dependent variable (actual values that can be explained by the independent variable (predictions). For R^2, a value closer to 1 indicates a better fit of the model to the data.\n"
      ],
      "metadata": {
        "id": "LzGYXFXnA-gC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "#Inference of the model to the test set\n",
        "Y_pred = model_LSTM_85_units_22_dropout_500_epochs.predict(X_test)\n",
        "\n",
        "# Flatten the predictions and labels\n",
        "Y_pred_flat = Y_pred.reshape(-1)\n",
        "Y_test_flat = Y_test.reshape(-1)\n",
        "\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "mae = mean_absolute_error(Y_test_flat, Y_pred_flat)\n",
        "mse = mean_squared_error(Y_test_flat, Y_pred_flat)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(Y_test_flat, Y_pred_flat)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print('Mean Absolute Error (MAE):', mae)\n",
        "print('Mean Squared Error (MSE):', mse)\n",
        "print('Root Mean Squared Error (RMSE):', rmse)\n",
        "print('R^2 Score:', r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wmy8Ur897tk",
        "outputId": "f817b1e8-2536-4c85-c9b3-22fb09c24ab2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "156/156 [==============================] - 1s 4ms/step\n",
            "Mean Absolute Error (MAE): 0.011164688845477411\n",
            "Mean Squared Error (MSE): 0.00556037021411348\n",
            "Root Mean Squared Error (RMSE): 0.07456788996688507\n",
            "R^2 Score: 0.9942696357615447\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 5: Model and scaler saving"
      ],
      "metadata": {
        "id": "Bugvg_vlD8Sq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the model and the Scaler for inference\n",
        "from pickle import dump\n",
        "\n",
        "# save the scaler object to a file\n",
        "dump(scaler, open('/content/drive/MyDrive/scaler.pkl', 'wb'))\n",
        "\n",
        "# save the model\n",
        "model_LSTM_24_units_30_dropout_300_epochs.save('/content/drive/MyDrive/model_LSTM_85_units_22_dropout_500_epochs.h5')"
      ],
      "metadata": {
        "id": "oTqixvNKZCbe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}